---
title: Introduction à la modélisation statistique bayésienne
subtitle: Un cours en R et Stan avec brms
author: Ladislas Nalborczyk (LPC, LNC, CNRS, Aix-Marseille Univ)
from: markdown+emoji
format:
  revealjs:
    incremental: true
    theme: [default, ../custom.scss]
    transition: none # fade
    background-transition: none # fade
    transition-speed: default # default, fast, or slow
    slide-number: c/t
    show-slide-number: all
    preview-links: true
    self-contained: true # when sharing slides
    # chalkboard: true
    csl: ../../files/bib/apa7.csl
    logo: ../../files/cover.png
    footer: "Ladislas Nalborczyk - IMSB2022"
    # width: 1200 # defaults to 1050
    # height: 900 # default to 700
    margin: 0.15 # defaults to 0.1
    scrollable: true
    hide-inactive-cursor: true
    pdf-separate-fragments: false
    highlight-style: zenburn
    code-copy: true
    code-link: false
    code-fold: false
    code-summary: "Voir le code"
    numbers: true
    progress: false
title-slide-attributes:
    data-background-color: "#1c5253"
bibliography: ../../files/bib/references.bib
---

## Planning

```{r setup, eval = TRUE, include = FALSE, cache = FALSE}
library(tidyverse)
library(patchwork)
library(brms)
library(imsb)

# setting up knitr options
knitr::opts_chunk$set(
  cache = TRUE, echo = TRUE,
  warning = FALSE, message = FALSE,
  fig.align = "center", dev = "svg"
  )

# setting up ggplot theme
theme_set(theme_bw(base_size = 16, base_family = "Open Sans") )
```

Cours n°01 : Introduction à l'inférence bayésienne <br> Cours n°02 :
Modèle Beta-Binomial <br> Cours n°03 : Introduction à brms, modèle de
régression linéaire <br> Cours n°04 : Modèle de régression linéaire
(suite) <br> Cours n°05 : Markov Chain Monte Carlo <br> Cours n°06 :
Modèle linéaire généralisé <br> Cours n°07 : Comparaison de modèles <br>
Cours n°08 : Modèles multi-niveaux <br> Cours n°09 : Modèles
multi-niveaux généralisés <br> **Cours n°10 : Data Hackathon** <br>

$$\newcommand\given[1][]{\:#1\vert\:}$$

## Introduction

Cinq problèmes, cinq jeux de données. Le but est de comprendre et
d'analyser ces données pour répondre à une (ou plusieurs) question(s)
théorique(s).

Vous devrez écrire le modèle mathématique, puis fitter ce modèle en
utilisant `brms`.

Ensuite, vous devrez évaluer le modèle, interpréter les résultats, et
écrire un paragraphe de résultats (de type article) pour décrire vos
analyses et vos conclusions.

Les problèmes sont classés par ordre croissant de difficulté. Vous
pouvez travailler individuellement ou par groupe, et des propositions de
correction sont disponibles à la suite des énoncés.

## Problème n°1

Peut-on prédire la taille d'un individu par la taille de ses parents ?

```{r parents, eval = TRUE, echo = TRUE}
library(tidyverse)
library(imsb)

d1 <- open_data(parents)
head(d1, 10)
```

## Problème n°2

Les données suivantes documentent le naufrage du titanic. La colonne
`pclass` indique la classe dans laquelle chaque passager voyageait (un
proxy pour le statut socio-économique), tandis que la colonne `parch`
indique le nombre de parents et enfants à bord.

Peut-on prédire la survie d'un passager grâce à ces informations ?

```{r titanic, eval = TRUE, echo = TRUE}
d2 <- open_data(titanic)
head(d2, 10)
```

## Problème n°3

Ce jeu de données recense des informations sur le diamètre (colonne
`diam`) de 80 pommes (chaque pomme étant identifiée par la colonne
`id`), poussant sur 10 arbres différents (colonne `tree`). On a mesuré
ce diamètre pendant 6 semaines successives (colonne `time`).

Que peut-on dire de la pousse de ces pommes, tout en considérant les
structures de dépendance existant dans les données (i.e., chaque pomme
poussait sur un arbre différent) ?

```{r apples, eval = TRUE, echo = TRUE}
d3 <- open_data(apples)
head(d3, 10)
```

## Problème n°4

Ces données recensent le nombre de candidatures pour 6 départements
(colonne `dept`) à Berkeley (données disponibles dans le paquet
`rethinking`). La colonne `admit` indique le nombre de candidatures
acceptées et la colonne `reject` le nombre de candidatures rejetées (la
colonne `applications` est simplement la somme des deux), en fonction du
sexe des candidats (`applicant.gender`).

On veut savoir s'il existe un biais lié au sexe dans l'admission des
étudiants à Berkeley.

```{r berkeley, eval = TRUE, echo = TRUE}
d4 <- open_data(admission)
head(d4, 10)
```

## Problème n°5

Le dilemme du tramway (trolley problem) est une expérience de pensée qui
permet d'étudier les déterminants des jugements de moralité (i.e.,
qu'est-ce qui fait qu'on juge une action comme morale, ou pas ?).

. . .

Sous une forme générale, ce dilemme consiste à poser la question
suivante : si une personne peut effectuer un geste qui bénéficiera à un
groupe de personnes A, mais, ce faisant, nuira à une personne B (seule);
est-il moral pour la personne d'effectuer ce geste ?

Voir [ce lien](https://fr.wikipedia.org/wiki/Dilemme_du_tramway) pour
plus d'informations.

```{r echo = FALSE, fig.align = "center", out.width = "1000px"}
knitr::include_graphics("figures/trolley.png")
```

## Problème n°5

Généralement, on fait lire des scénarios aux participants de l'étude,
dans lesquels un individu doit prendre une décision dans une situation
similaire à celle décrite à la slide précédente. Par exemple, imaginons
que Denis ait le choix entre ne rien faire et laisser un train tuer cinq
personnes, ou faire dérailler ce train mais tuer une personne. Ensuite,
on demande aux participants de juger de la moralité de l'action choisie
par Denis, sur une échelle de 1 à 7.

. . .

Des études antérieures ont montré que ces jugements de moralité sont
grandement influencés par trois mécanismes de raisonnement inconscients
:

-   Le **principe d'action** : un préjudice causé par une action est
    jugé moralement moins acceptable qu'un préjudice causé par omission.
-   Le **principe d'intention** : un préjudice causé comme étant le
    moyen vers un but est jugé moralement moins acceptable qu'un
    préjudice étant un effet secondaire (non désiré) d'un but.
-   Le **principe de contact** : un préjudice causé via contact physique
    est jugé moralement moins acceptable qu'un préjudice causé sans
    contact physique.

## Problème n°5

Ce jeu de données comprend 12 colonnes et 9930 lignes, pour 331
individus. L'outcome qui nous intéresse est `response`, un entier
pouvant aller de 1 à 7, qui indique à quel point il est permis
(moralement) de réaliser l'action décrite dans le scénario
correspondant, en fonction de l'âge (`age`) et genre (`male`) du
participant (`id`).

On se demande comment les jugements d'acceptabilité sont influencés par
les trois principes décrits slide précédente. Ces trois principes
correspondent aux trois variables, `action`, `intention`, et `contact`
(dummy-coded).

```{r morale, eval = TRUE, echo = TRUE}
d5 <- open_data(morale)
head(d5)
```

# Propositions de réponses

## Réponse possible problème n°1

La taille de la mère a l'air "plus" prédictive de la taille d'un
individu, et ce d'autant plus si cet individu est une femme...

```{r plot-parents, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
d1 %>%
    gather(parent, parent.height, 3:4) %>%
    ggplot(aes(x = parent.height, y = height, colour = parent, fill = parent) ) +
    geom_point(pch = 21, size = 4, color = "white", alpha = 1) +
    stat_smooth(method = "lm", fullrange = TRUE) +
    facet_wrap(~ gender)
```

## Réponse possible problème n°1

On peut fitter plusieurs modèles avec `brms::brm()`, et les comparer en
utilisant le WAIC.

```{r models-parents-1, eval = TRUE, echo = TRUE, results = "hide"}
library(brms)

d1$gender <- ifelse(d1$gender == "F", -0.5, 0.5)
d1$mother <- scale(d1$mother) %>% as.numeric
d1$father <- scale(d1$father) %>% as.numeric

p1 <- c(
    prior(normal(70, 10), class = Intercept),
    prior(cauchy(0, 10), class = sigma)
    )

m1 <- brm(
    height ~ 1 + gender,
    prior = p1,
    data = d1
    )

p2 <- c(
    prior(normal(70, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma)
    )

m2 <- brm(
    height ~ 1 + gender + mother + father,
    prior = p2,
    data = d1
    )
```

## Réponse possible problème n°1

```{r models-parents-2, eval = TRUE, echo = TRUE, results = "hide"}
p3 <- c(
    prior(normal(70, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma)
    )

m3 <- brm(
    height ~ 1 + gender + mother + father + gender:mother,
    prior = p3,
    data = d1
    )

p4 <- c(
    prior(normal(70, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma)
    )

m4 <- brm(
    height ~ 1 + gender + mother + father + gender:father,
    prior = p4,
    data = d1
    )
```

## Réponse possible problème n°1

```{r WAIC-parents, eval = TRUE, echo = TRUE}
m1 <- add_criterion(m1, "waic")
m2 <- add_criterion(m2, "waic")
m3 <- add_criterion(m3, "waic")
m4 <- add_criterion(m4, "waic")

model_comparison_table <- loo_compare(m1, m2, m3, m4, criterion = "waic") %>%
  data.frame %>%
  rownames_to_column(var = "model")

weights <- data.frame(weight = model_weights(m1, m2, m3, m4, weights = "waic") ) %>%
  round(digits = 3) %>%
  rownames_to_column(var = "model")

left_join(model_comparison_table, weights, by = "model")
```

## Réponse possible problème n°1

```{r summary-parents, eval = TRUE, echo = TRUE}
summary(m3)
```

## Réponse possible problème n°1

```{r plot-m3-parents, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
m3 %>%
    plot(
        pars = "^b_",
        combo = c("dens_overlay", "trace"), widths = c(1, 1.5),
        theme = theme_bw(base_size = 14, base_family = "Open Sans")
        )
```

## Réponse possible problème n°1

```{r ppc-m3-parents, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(m3, nsamples = 1e2) + theme_bw(base_size = 20)
```

## Réponse possible problème n°2

Cette situation revient à essayer de prédire un outcome dichotomique à
l'aide de prédicteurs continus et / ou catégoriels. On peut utiliser un
modèle de **régression logistique** (cf. Cours n°06).

```{r reshape-titanic, eval = TRUE, echo = TRUE}
# centering and standardising predictors

d2 <-
    d2 %>%
    mutate(
        pclass = ifelse(pclass == "lower", -0.5, 0.5),
        gender = ifelse(gender == "female", -0.5, 0.5),
        age = scale(age) %>% as.numeric,
        parch = scale(parch) %>% as.numeric
        )
```

## Réponse possible problème n°2

```{r plot-titanic, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 6}
d2 %>%
    group_by(pclass, gender) %>%
    summarise(p = mean(survival) ) %>%
    ggplot(aes(x = as.factor(pclass), y = p, fill = as.factor(gender) ) ) +
    geom_bar(position = position_dodge(0.5), stat = "identity", alpha = 0.8) +
    xlab("class") + ylab("p(survival)")
```

## Réponse possible problème n°2

On peut fitter plusieurs modèles avec `brms::brm()`, et les comparer en
utilisant le WAIC.

```{r models-titanic-1, eval = TRUE, echo = TRUE, results = "hide"}
prior0 <- prior(normal(0, 10), class = Intercept)

m0 <- brm(
    survival ~ 1,
    family = binomial(link = "logit"),
    prior = prior0,
    data = d2,
    cores = parallel::detectCores()
    )

prior1 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b)
    )

m1 <- brm(
    # using the dot is equivalent to say "all predictors" (all columns)
    survival ~ .,
    family = binomial(link = "logit"),
    prior = prior1,
    data = d2,
    cores = parallel::detectCores()
    )
```

## Réponse possible problème n°2

```{r models-titanic-2, eval = TRUE, echo = TRUE, results = "hide"}
m2 <- brm(
    survival ~ 1 + pclass + gender + pclass:gender,
    family = binomial(link = "logit"),
    prior = prior1,
    data = d2,
    cores = parallel::detectCores()
    )

m3 <- brm(
    survival ~ 1 + pclass + gender + pclass:gender + age,
    family = binomial(link = "logit"),
    prior = prior1,
    data = d2,
    cores = parallel::detectCores()
    )
```

## Réponse possible problème n°2

```{r WAIC-titanic, eval = TRUE, echo = TRUE, message = FALSE}
m1 <- add_criterion(m1, "waic")
m2 <- add_criterion(m2, "waic")
m3 <- add_criterion(m3, "waic")

model_comparison_table <- loo_compare(m1, m2, m3, criterion = "waic") %>%
  data.frame %>%
  rownames_to_column(var = "model")

weights <- data.frame(weight = model_weights(m1, m2, m3, weights = "waic") ) %>%
  round(digits = 3) %>%
  rownames_to_column(var = "model")

left_join(model_comparison_table, weights, by = "model")
```

## Réponse possible problème n°2

```{r ppc-titanic, eval = TRUE, echo = TRUE, message = FALSE, fig.width = 12, fig.height = 6}
pp_check(m3, nsamples = 1e2)
```

## Réponse possible problème n°2

```{r summary-titanic, eval = TRUE, echo = TRUE}
summary(m3)
```

## Réponse possible problème n°2

```{r plot-titanic-m3, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
m3 %>%
    plot(
        pars = "^b_",
        combo = c("dens_overlay", "trace"), widths = c(1, 1.5),
        theme = theme_bw(base_size = 14, base_family = "Open Sans")
        )
```

## Réponse possible problème n°3

Cette situation revient à essayer de prédire une variable continue (le
diamètre) à l'aide de prédicteurs continus ordonnés (le temps), en
sachant que le diamètre d'une pomme dépend de l'arbre sur lequel cette
pomme pousse. On peut utiliser un modèle multi-niveaux (ou modèle mixte,
cf. Cours n°08).

```{r, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
d3 <- d3 %>% filter(diam != 0) # removing null data
```

```{r, eval = TRUE, echo = FALSE, fig.width = 10, fig.height = 5}
d3 %>%
    ggplot(aes(x = time, y = diam, colour = as.factor(apple) ) ) +
    geom_point(show.legend = FALSE) +
    geom_line(show.legend = FALSE) +
    facet_wrap(~tree, ncol = 5)
```

## Réponse possible problème n°3

On peut fitter plusieurs modèles avec `brms::brm()` et les comparer
ensuite en utilisant le WAIC.

```{r, eval = TRUE, echo = TRUE, results = "hide"}
p1 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(cauchy(0, 10), class = sigma)
    )

m1 <- brm(
    diam ~ 1,
    prior = p1,
    data = d3,
    cores = parallel::detectCores(),
    backend = "cmdstanr"
    )

p2 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sigma)
    )

m2 <- brm(
    diam ~ 1 + time,
    prior = p2,
    data = d3,
    cores = parallel::detectCores(),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE, results = "hide"}
p3 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sd),
    prior(cauchy(0, 10), class = sigma)
    )

m3 <- brm(
    diam ~ 1 + time + (1 | tree),
    prior = p3,
    data = d3,
    cores = parallel::detectCores(),
    backend = "cmdstanr"
    )

p4 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sd),
    prior(cauchy(0, 10), class = sigma),
    prior(lkj(2), class = cor)
    )

m4 <- brm(
    diam ~ 1 + time + (1 + time | tree),
    prior = p4,
    data = d3,
    cores = parallel::detectCores(),
    control = list(adapt_delta = 0.99),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE, results = "hide"}
p5 <- c(
    prior(normal(0, 10), class = Intercept),
    prior(normal(0, 10), class = b),
    prior(cauchy(0, 10), class = sd),
    prior(cauchy(0, 10), class = sigma),
    prior(lkj(2), class = cor)
    )

m5 <- brm(
    diam ~ 1 + time + (1 + time | tree / apple),
    prior = p5,
    data = d3,
    cores = parallel::detectCores(),
    control = list(adapt_delta = 0.99),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE}
m1 <- add_criterion(m1, "waic")
m2 <- add_criterion(m2, "waic")
m3 <- add_criterion(m3, "waic")
m4 <- add_criterion(m4, "waic")
m5 <- add_criterion(m5, "waic")

model_comparison_table <- loo_compare(m1, m2, m3, m4, m5, criterion = "waic") %>%
  data.frame %>%
  rownames_to_column(var = "model")

weights <- data.frame(weight = model_weights(m1, m2, m3, m4, m5, weights = "waic") ) %>%
  round(digits = 3) %>%
  rownames_to_column(var = "model")

left_join(model_comparison_table, weights, by = "model")
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE}
posterior_summary(m5, pars = c("^b", "sigma") )
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
post <- posterior_samples(m5, "b") # extracts posterior samples

ggplot(data = d3, aes(x = time, y = diam) ) +
    geom_point(alpha = 0.5, shape = 1) +
    geom_abline(
        data = post, aes(intercept = b_Intercept, slope = b_time),
        alpha = 0.01, size = 0.5) +
    labs(x = "Temps", y = "Diamètre")
```

## Réponse possible problème n°3

```{r, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
library(tidybayes)
library(modelr)

d3 %>%
    group_by(tree, apple) %>%
    data_grid(time = seq_range(time, n = 1e2) ) %>%
    add_fitted_samples(m5, n = 1e2) %>%
    ggplot(aes(x = time, y = diam, colour = factor(apple) ) ) +
    geom_line(
        aes(y = estimate, group = paste(apple, .iteration) ),
        alpha = 0.2, show.legend = FALSE) +
    facet_wrap(~tree, ncol = 5) +
    labs(x = "Temps", y = "Diamètre")
```

## Réponse possible problème n°3

Quelques notes sur la proposition de réponse concernant ce problème. Les
modèles proposés ici pourraient être améliorés sur plusieurs aspects...
est-ce que vous avez des idées ?

Premièrement, notre prédicteur (temps) est mesuré en utilisant une
échelle discrète (i.e., le nombre de semaines). Il s'agit d'un
prédicteur ordinal (i.e., un prédicteur avec différentes catégories
entre elles) et un meilleur modèle pour ce genre de données est présenté
dans @bürkner2020.

Deuxièmement, on pourrait affiner le modèle d'observation postulé pour
le phénomène mesuré. Plus précisément, nous avons des informations sur
la nature de la variable mesurée (le diamètre). En l'occurrence, on sait
par exemple que le diamètre d'une pomme ne peut pas être négatif. On
pourrait donc remplacer la fonction de vraisemblance Gaussienne par une
fonction de vraisemblance Log-Normale ou Ex-Gaussienne (par exemple).

## Réponse possible problème n°4

Cette situation revient à essayer de prédire un outcome dichotomique
(admit, reject) à l'aide de prédicteurs continus et/ou catégoriels.

```{r plot-berkeley, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
d4 %>%
    ggplot(aes(x = dept, y = admit / applications) ) +
    geom_bar(stat = "identity") +
    facet_wrap(~ applicant.gender) +
    labs(x = "Département", y = "Probabilité d'admission")
```

## Réponse possible problème n°4

On peut fitter plusieurs modèles avec `brms::brm()` et les comparer
ensuite en utilisant le WAIC.

```{r models-berkeley-1, eval = TRUE, echo = TRUE, results = "hide"}
# centering gender predictor
d4$gender <- ifelse(d4$applicant.gender == "female", -0.5, 0.5)

# creating an index for department
d4$dept_id <- as.integer(as.factor(d4$dept) )

p1 <- c(
    prior(normal(0, 10), class = "Intercept"),
    prior(cauchy(0, 2), class = "sd")
    )

m1 <- brm(
    admit | trials(applications) ~ 1 + (1 | dept_id),
    data = d4, family = binomial,
    prior = p1,
    warmup = 1000, iter = 5000,
    control = list(adapt_delta = 0.99, max_treedepth = 12),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°4

```{r models-berkeley-2, eval = TRUE, echo = TRUE, results = "hide"}
p2 <- c(
    prior(normal(0, 10), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(cauchy(0, 2), class = "sd")
    )

m2 <- brm(
    admit | trials(applications) ~ 1 + gender + (1 | dept_id),
    data = d4, family = binomial,
    prior = p2,
    warmup = 1000, iter = 5000,
    control = list(adapt_delta = 0.99, max_treedepth = 12),
    backend = "cmdstanr"
    )

p3 <- c(
    prior(normal(0, 10), class = "Intercept"),
    prior(normal(0, 1), class = "b"),
    prior(cauchy(0, 2), class = "sd"),
    prior(lkj(2), class = "cor")
    )

m3 <- brm(
    admit | trials(applications) ~ 1 + gender + (1 + gender | dept_id),
    data = d4, family = binomial,
    prior = p3,
    warmup = 1000, iter = 5000,
    control = list(adapt_delta = 0.99, max_treedepth = 12),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°4

```{r WAIC-berkeley, eval = TRUE, echo = TRUE}
m1 <- add_criterion(m1, "waic")
m2 <- add_criterion(m2, "waic")
m3 <- add_criterion(m3, "waic")

model_comparison_table <- loo_compare(m1, m2, m3, criterion = "waic") %>%
  data.frame %>%
  rownames_to_column(var = "model")

weights <- data.frame(weight = model_weights(m1, m2, m3, weights = "waic") ) %>%
  round(digits = 3) %>%
  rownames_to_column(var = "model")

left_join(model_comparison_table, weights, by = "model")
```

## Réponse possible problème n°4

```{r summary-berkeley, eval = TRUE, echo = TRUE}
summary(m3)
```

## Réponse possible problème n°4

```{r predict-berkeley, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
library(tidybayes)
library(modelr)

d4 %>%
    group_by(dept_id, applications) %>%
    data_grid(gender = seq_range(gender, n = 1e2) ) %>%
    add_fitted_samples(m3, newdata = ., n = 100, scale = "linear") %>%
    mutate(estimate = plogis(estimate) ) %>%
    ggplot(aes(x = gender, y = estimate, group = .iteration) ) +
    geom_hline(yintercept = 0.5, lty = 2) +
    geom_line(aes(y = estimate, group = .iteration), size = 0.5, alpha = 0.2) +
    facet_wrap(~dept_id, nrow = 2)
```

## Réponse possible problème n°5

On essaye de prédire un jugement exprimé sous forme d'entier entre 1 et
7. Autrement dit, la variable qu'on essaye de prédire est une variable
catégorielle, dont les catégories sont ordonnées de 1 à 7...

```{r plot-moral, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 6}
d5$response %>% table %>%
  plot(xlab = "response", ylab = "", cex.axis = 2, cex.lab = 2)
```

## Réponse possible problème n°5

Ce type de données peut se modéliser en utilisant le modèle de
régression logistique ordinale, brièvement discuté à la fin du Cours
n°09. Ci-dessous un exemple en utilisant `brms`, et les priors par
défaut (NB : ces modèles peuvent être un peu longs à fitter).

```{r models-moral, eval = TRUE, echo = TRUE, results = "hide"}
moral1 <- brm(
    response ~ 1,
    data = d5,
    family = cumulative("logit"),
    cores = parallel::detectCores(),
    control = list(adapt_delta = 0.99),
    backend = "cmdstanr"
    )

moral2 <- brm(
    response ~ 1 + action + intention + contact,
    data = d5,
    family = cumulative("logit"),
    cores = parallel::detectCores(),
    control = list(adapt_delta = 0.99),
    backend = "cmdstanr"
    )
```

## Réponse possible problème n°5

Toutes les pentes sont négatives... ce qui signifie que chaque facteur
réduit la réponse moyenne (i.e., le jugement de moralité). Ces pentes
représentent des changements dans les log-odds cumulatifs.

```{r WAIC-moral, eval = TRUE, echo = TRUE}
brms::waic(moral1, moral2)
```

## Réponse possible problème n°5

```{r summary-moral, eval = TRUE, echo = TRUE}
summary(moral2, prob = 0.95)
```

## Réponse possible problème n°5

On peut représenter les prédictions du modèle en utilisant la fonction
`brms::marginal_effects()`.

```{r, eval = TRUE, echo = TRUE, message = FALSE, warning = FALSE}
marg1 <- marginal_effects(moral2, "action", ordinal = TRUE)
p1 <- plot(marg1, theme = theme_bw(base_size = 20, base_family = "Open Sans"), plot = FALSE)[[1]]

marg2 <- marginal_effects(moral2, "intention", ordinal = TRUE)
p2 <- plot(marg2, theme = theme_bw(base_size = 20, base_family = "Open Sans"), plot = FALSE)[[1]]

marg3 <- marginal_effects(moral2, "contact", ordinal = TRUE)
p3 <- plot(marg3, theme = theme_bw(base_size = 20, base_family = "Open Sans"), plot = FALSE)[[1]]
```

## Réponse possible problème n°5

```{r patchwork-moral, eval = TRUE, echo = TRUE, message = FALSE, warning = FALSE, fig.width = 14, fig.height = 7}
library(patchwork)
p1 + p2 + p3 + plot_layout(guides = "collect") & theme(legend.position = "right")
```

## Réponse possible problème n°5

Pour plus d'informations sur la régression logistique ordinale, voir
@liddell2018, @bürkner2019a, ou le chapitre 11 de @mcelreath2020c.

```{r ppc-moral-1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(moral2, nsamples = 1e2) +
  labs(x = "Moralité", y = "Proportion")
```

## Réponse possible problème n°5

```{r ppc-moral-2, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(moral2, nsamples = 1e2, type = "bars", prob = 0.95, freq = FALSE) +
  scale_x_continuous(breaks = 1:7) +
  labs(x = "Moralité", y = "Proportion")
```

## Références {.refs}
