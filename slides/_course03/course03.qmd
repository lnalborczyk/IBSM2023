---
title: Introduction to Bayesian statistical modelling
subtitle: A course with R, Stan, and brms
author: Ladislas Nalborczyk (UNICOG, NeuroSpin, CEA, Gif/Yvette, France)
from: markdown+emoji
format:
  revealjs:
    incremental: true
    theme: [default, ../custom.scss]
    transition: none # fade
    background-transition: none # fade
    transition-speed: default # default, fast, or slow
    slide-number: c/t
    show-slide-number: all
    preview-links: true
    self-contained: true # when sharing slides
    # chalkboard: true
    csl: ../../files/bib/apa7.csl
    logo: ../../files/cover.png
    footer: "Ladislas Nalborczyk - IBSM2023"
    # width: 1200 # defaults to 1050
    # height: 900 # default to 700
    margin: 0.15 # defaults to 0.1
    scrollable: true
    hide-inactive-cursor: true
    pdf-separate-fragments: false
    highlight-style: zenburn
    code-copy: true
    code-link: false
    code-fold: false
    code-summary: "See the code"
    numbers: true
    progress: false
title-slide-attributes:
    data-background-color: "#1c5253"
bibliography: ../../files/bib/references.bib
editor_options: 
  chunk_output_type: console
---

```{r setup, eval = TRUE, include = FALSE, cache = FALSE}
library(countdown)
library(tidyverse)
library(patchwork)
library(knitr)
library(brms)
library(imsb)

# setting up knitr options
knitr::opts_chunk$set(
  cache = TRUE, echo = TRUE,
  warning = FALSE, message = FALSE,
  fig.align = "center", dev = "svg"
  )

# defining constant colour variables
prior_color <- "steelBlue"
likelihood_color <- "orangered"
posterior_color <- "magenta4"

# setting up ggplot theme
theme_set(theme_bw(base_size = 16, base_family = "Open Sans") )
```

## Planning

Course n°01: Introduction to Bayesian inference, Beta-Binomial model <br> Course n°02: Introduction to brms, linear regression <br> **Course n°03: Markov Chain Monte Carlo, generalised linear model** <br> Course n°04: Multilevel models, cognitive models <br>

$$\newcommand\given[1][]{\:#1\vert\:}$$

## Reminders: notation

The notation $p(y \given \theta)$ can refer to two things depending on the context: the likelihood function and the observation model. In addition, there are many ambiguous notations in statistics. Let's try to clarify them below.

-   $\Pr(Y = y \given \Theta = \theta)$ refers to a **probability** (e.g., `dbinom(x = 2, size = 10, prob = 0.5)`).
-   $p(Y = y \given \Theta = \theta)$ refers to a probability **density** (e.g., `dbeta(x = 0.4, shape1 = 2, shape2 = 3)`).
-   $p(Y = y \given \Theta)$ refers to a (discrete or continuous) likelihood function, $y$ is given/known/fixed, $\Theta$ is a random variable, the sum (or the integral) of this distribution **is not equal to 1** (e.g., `dbinom(x = 2, size = 10, prob = seq(0, 1, 0.1) )`).
-   $p(Y \given \Theta = \theta)$ refers to a probability mass (or density) function (of which the sum or the integral **is equal** to 1) that we call the "observation model" ot "sampling distribution", $Y$ is a random variable, $\theta$ is given/known/fixed (e.g., `dbinom(x = 0:10, size = 10, prob = 0.5)`)

. . .

The goal of a Bayesian analysis (i.e., what is obtained at the end of such an analysis) is the posterior distribution $p(\theta \given y)$. It can be summarised to make the communication of results easier, but all the desired information is contained in **the entire distribution** (not just its mean, mode, or whatever).

## Reminders: notation

```{r greek, echo = FALSE, fig.cap = "Figure from <https://masterofmemory.com/mmem-0333-learn-the-greek-alphabet/>."}
knitr::include_graphics("figures/greek.jpeg")
```

## Reminders: prior predictive checking

```{r, eval = FALSE, echo = TRUE}
#####################################################################
# We define a model with:                                           #
# A Gaussian likelihood function: y ~ Normal(mu, sigma)             #
# A Gaussian prior for the mean: mu ~ Normal(100, 10)               #
# An Exponential prior for the dispersion: sigma ~ Exponential(0.1) #
#####################################################################

# drawing 10.000 observations from a Gaussian distribution without (epistemic) uncertainty
rnorm(n = 1e4, mean = 100, sd = 10) |> hist(breaks = "FD")

# drawing 10.000 observations from the Gaussian prior on mu (i.e., p(mu))
# this prior represents what we know about mu before seeing the data...
mu_prior <- rnorm(n = 1e4, mean = 100, sd = 10)

# drawing 10.000 observations from a Gaussian distribution with prior-related (epistemic) uncertainty
rnorm(n = 1e4, mean = mu_prior, sd = 10) |> hist(breaks = "FD")

# drawing 10.000 observations from the Exponential prior on sigma (i.e., p(sigma))
# this prior represents what we know about sigma before seeing the data...
sigma_prior <- rexp(n = 1e4, rate = 0.1)

# drawing 10.000 observations from a Gaussian distribution with prior-related
# (epistemic) uncertainty on mu AND sigma
# this is what the model expects about y given our priors about mu and sigma and the observation model
rnorm(n = 1e4, mean = mu_prior, sd = sigma_prior) |> hist(breaks = "FD")
```

## Reminders: prior predictive checking

```{r, eval = TRUE, echo = FALSE, out.width = "75%", fig.asp = 0.75}
################################################################################
# Assume a model with a Normal likelihood function: y ~ Normal(mu, sigma)      #
# A Normal prior on the mean: mu ~ Normal(100, 10)                             #
# And an Exponential prior on the standard deviation: sigma ~ Exponential(0.1) #
################################################################################

# graphical parameters (three rows and one column)
par(mfrow = c(3, 1) )

# number of samples to draw
nsamples <- 1e4

# simulating data from a normal distribution without (epistemic) uncertainty
rnorm(n = nsamples, mean = 100, sd = 10) |>
    hist(breaks = "FD", xlim = c(-50, 250) )

# drawing samples from the normal prior for mu (i.e., p(mu))
# what we know about mu before seeing the data
mu_prior <- rnorm(n = nsamples, mean = 100, sd = 10)

# simulating data from a normal distribution with uncertainty on mu
rnorm(n = nsamples, mean = mu_prior, sd = 10) |>
    hist(breaks = "FD", xlim = c(-50, 250) )

# drawing samples from the exponential prior for sigma (i.e., p(sigma))
# what we know about sigma before seeing the data
sigma_prior <- rexp(n = nsamples, rate = 0.1)

# simulating data from a normal distribution with uncertainty on both mu and sigma
# what we (the model) assume(s) about y according to our priors for mu and sigma
rnorm(n = nsamples, mean = mu_prior, sd = sigma_prior) |>
    hist(breaks = "FD", xlim = c(-50, 250) )
```

## The problem with posterior distributions...

$$
\color{purple}{p(\mu, \sigma \given h)} = \frac{\prod_{i} \color{orangered}{\mathrm{Normal}(h_{i} \given \mu, \sigma)}\color{steelblue}{\mathrm{Normal}(\mu \given 178, 20)\mathrm{Uniform}(\sigma \given 0, 50)}}
{\color{green}{\int \int \prod_{i} \mathrm{Normal}(h_{i} \given \mu, \sigma)\mathrm{Normal}(\mu \given 178, 20)\mathrm{Uniform}(\sigma \given 0, 50) \mathrm{d} \mu \mathrm{d} \sigma}}
$$

Problem: The normalisation constant (in green) is obtained by calculating the sum (for discrete variables) or the integral (for continuous variables) of the joint density $p(\text{data}, \theta)$ over all possible values of $\theta$. This becomes complicated when the model includes several parameters and/or the shape of the posterior distribution is complex...

## The problem with posterior distributions...

```{r, eval = FALSE, echo = FALSE}
# from https://plotly.com/r/3d-surface-plots/

z <- c(
  c(8.83,8.89,8.81,8.87,8.9,8.87),
  c(8.89,8.94,8.85,8.94,8.96,8.92),
  c(8.84,8.9,8.82,8.92,8.93,8.91),
  c(8.79,8.85,8.79,8.9,8.94,8.92),
  c(8.79,8.88,8.81,8.9,8.95,8.92),
  c(8.8,8.82,8.78,8.91,8.94,8.92),
  c(8.75,8.78,8.77,8.91,8.95,8.92),
  c(8.8,8.8,8.77,8.91,8.95,8.94),
  c(8.74,8.81,8.76,8.93,8.98,8.99),
  c(8.89,8.99,8.92,9.1,9.13,9.11),
  c(8.97,8.97,8.91,9.09,9.11,9.11),
  c(9.04,9.08,9.05,9.25,9.28,9.27),
  c(9,9.01,9,9.2,9.23,9.2),
  c(8.99,8.99,8.98,9.18,9.2,9.19),
  c(8.93,8.97,8.97,9.18,9.2,9.18)
  )

dim(z) <- c(15, 6)
# z2 <- z + 1
# z3 <- z - 1

fig <- plot_ly(showscale = FALSE)
fig <- fig %>% add_surface(z = ~z)
# fig <- fig %>% add_surface(z = ~z2, opacity = 0.98)
# fig <- fig %>% add_surface(z = ~z3, opacity = 0.98)

# exporting it to an html object
# orca(fig, file = "figures/plotly.png")
htmlwidgets::saveWidget(fig, file = "plotly1.html")
```

```{r, eval = TRUE}
#| echo: false
#| out.width: "100%"
knitr::include_url(url = "plotly1.html", height = "600px")
```

## Reminders from Course n°01

There are three ways of getting around this problem:

-   The prior distribution is a **conjugate prior** of the likelihood function (e.g. Beta-Binomial model). In this case, there is an analytical solution (i.e., one that can be calculated exactly) for the the posterior distribution.

-   Alternatively, for simple models, we can use the **grid method**. The exact value of the posterior probability is calculated at a finite number of points in the parameter space.

-   For more complex models, exploring the entire parameter space space is not tractable. Instead, we will sample a large number of points in the parameter space and use these samples as an approximation of the posterior distribution, but we will sample the posterior space in a smart way.

# Markov Chain Monte Carlo

## Markov Chain Monte Carlo

-   Markov chain **Monte Carlo** <br> $\longrightarrow~$ Random sampling <br> $\longrightarrow~$ The result is an ensemble of parameter values (samples)

-   Markov **chain** Monte Carlo<br> $\longrightarrow~$ Values are generated in a sequence <br> $\longrightarrow~$ With a temporal index to identify the position in the chain <br> $\longrightarrow~$ The result looks like: $\theta^1, \theta^2, \theta^3, \dots, \theta^t$

-   **Markov** chain Monte Carlo <br> $\longrightarrow~$ The current parameter value only depends on the previous parameter value: $\Pr(\theta^{t+1} \given \theta^{t}, \theta^{t-1}, \ldots, \theta^{1}) = \Pr(\theta^{t + 1} \given \theta^{t})$

## Monte Carlo methods

**Monte-Carlo** refers to a family of algorithms designed to calculate (or approximate) a numerical value using random processes (i.e., probabilistic techniques). The method was formalised in 1947 by Nicholas Metropolis, and first published in 1949 in an article co-authored with Stanislaw Ulam.<br>

```{r metropolis_picture, echo = FALSE, out.width = "20%"}
knitr::include_graphics("figures/Nicholas_Metropolis_cropped.png")
```

## Monte Carlo methods: estimating $\pi$

Let $M$ be a point with coordinates $(x, y)$, where $0 < x < 1$ and $0 < y < 1$. We randomly draw the values of $x$ and $y$ between $0$ and $1$ according to a uniform distribution. The point $M$ belongs to the disc of centre $(0, 0)$ of radius $r = 1$ if and only if $\sqrt{x^{2} + y^{2}} \leqslant 1$. We know that the area of the quarter disc is $\sigma = \pi r^{2} / 4 = \pi / 4$ and that the square which contains has a surface $s = r^{2} = 1$. If the probability distribution of which the point is drawn is uniform, then the probability that point $M$ belongs to disc is $\sigma / s = \pi / 4$. By dividing the number of points in the disc by the number of draws $\frac{N_{\text{inner}}}{N_{\text{total}}}$, we obtain an approximation of $\pi / 4$.

```{r pi_gif, echo = FALSE, out.width = "25%"}
knitr::include_graphics("figures/Pi_30K.gif")
```

## Monte Carlo methods: estimating $\pi$

```{r pi1, eval = TRUE, echo = TRUE, out.width = "25%"}
trials <- 1e5 # number of samples
radius <- 1 # radius of the circle
x <- runif(n = trials, min = 0, max = radius) # draws for x
y <- runif(n = trials, min = 0, max = radius) # draws for y
distance <- sqrt(x^2 + y^2) # distance to origin
inside <- distance < radius # is it within the quarter of circle?
pi_estimate <- 4 * sum(inside) / trials # estimated value of pi
```

```{r pi2, eval = TRUE, echo = FALSE, out.width = "33%", dev = "png"}
data.frame(x, y, inside) %>%
    ggplot(aes(x, y, color = inside) ) +
    ggtitle(paste(round(trials), "Trials,", "Estimate =", pi_estimate) ) +
    guides(color = "none") +
    geom_point(size = 1 / trials)
```

## Méthodes Monte Carlo

**Monte-Carlo** refers to a family of algorithms designed to calculate (or approximate) a numerical value using random processes (i.e., probabilistic techniques). Can we use this sort of methods to approximate the posterior distribution?

. . .

We know the priors $p(\theta_{1})$ and $p(\theta_{2})$.<br> We know the likelihood function $p(\text{data} \given \theta_{1}, \theta_{2})$.<br>

. . .

But often, we do not know how to compute the exact posterior distribution $p(\theta_{1}, \theta_{2} \given \text{data}) = \dfrac{p(\text{data} \given \theta_{1}, \theta_{2}) p(\theta_{1}) p(\theta_{2})}{p(\text{data})}$.<br>

. . .

Or rather, we don't know how to compute $p(\text{data})$...! But we can compute something that is proportional to the posterior distribution. Since $p(\text{data})$ is a constant, it does not change the shape of the posterior distribution! So we're going to explore the parameter space and produce samples in proportion to their relative probability (density).

## Influence of the normalisation constant

```{r, eval = FALSE, echo = FALSE}
# from https://plotly.com/r/3d-surface-plots/

z <- c(
  c(8.83,8.89,8.81,8.87,8.9,8.87),
  c(8.89,8.94,8.85,8.94,8.96,8.92),
  c(8.84,8.9,8.82,8.92,8.93,8.91),
  c(8.79,8.85,8.79,8.9,8.94,8.92),
  c(8.79,8.88,8.81,8.9,8.95,8.92),
  c(8.8,8.82,8.78,8.91,8.94,8.92),
  c(8.75,8.78,8.77,8.91,8.95,8.92),
  c(8.8,8.8,8.77,8.91,8.95,8.94),
  c(8.74,8.81,8.76,8.93,8.98,8.99),
  c(8.89,8.99,8.92,9.1,9.13,9.11),
  c(8.97,8.97,8.91,9.09,9.11,9.11),
  c(9.04,9.08,9.05,9.25,9.28,9.27),
  c(9,9.01,9,9.2,9.23,9.2),
  c(8.99,8.99,8.98,9.18,9.2,9.19),
  c(8.93,8.97,8.97,9.18,9.2,9.18)
  )

dim(z) <- c(15, 6)
z2 <- z * 3 - 15

fig <- plot_ly(showscale = FALSE)
fig <- fig %>% add_surface(z = ~z)
fig <- fig %>% add_surface(z = ~z2, opacity = 0.98)

# exporting it to an html object
htmlwidgets::saveWidget(fig, file = "plotly2.html")
```

```{r, eval = TRUE}
#| echo: false
#| out.width: "100%"
knitr::include_url(url = "plotly2.html", height = "600px")
```

## Monte Carle methods: Example

Let's consider a simple example: We have a parameter $\theta$ with 7 possible values and the following distribution function, where $p(\theta) = \theta$.

```{r distribution_theta1, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# knitr::include_graphics("figures/distributionTheta1-7.png")

theta <- c(1, 2, 3, 4, 5, 6, 7)

theta %>%
  data.frame %>%
  ggplot(aes(x = theta, y = theta) ) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = expression(theta), y = expression(paste(p, "(", theta, ")") ) ) +
  scale_x_continuous(breaks = 1:7)
```

## Monte Carle methods: Example

We can approximate this distribution by random draw: This amounts to drawing a large number of points "at random" from among these 28 squares (as in the $\pi$ example)!

```{r distribution_theta2, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/DistribCarré1-7.png")
```

## Monte Carle methods: Example

```{r, eval = FALSE, echo = TRUE}
niter <- 100 # number of samples
theta <- 1:7 # possible values for theta
ptheta <- theta # probability of theta
samples <- sample(x = theta, prob = ptheta, size = niter, replace = TRUE) # samples
```

```{r, eval = TRUE, echo = FALSE, fig.width = 25}
set.seed(667)

trajLength <- 100
theta <- 1:7
ptheta <- theta
trajectory <- sample(theta, prob = ptheta, size = trajLength, replace = TRUE)

layout(matrix(1:2, ncol = 2), widths = c(0.75, 0.25) )

plot(
    trajectory,
    main = "Posterior distribution based on 100 draws",
    ylab = bquote(theta), xlim = c(0, trajLength),
    xlab = "Iteration number",
    type = "o", pch = 20, col = posterior_color,
    cex.lab = 2, cex.main = 3, cex.axis = 2
    )

barplot(
    table(trajectory),
    col = posterior_color,
    horiz = TRUE, axes = FALSE, axisnames = FALSE
    )
```

-   The distribution of samples converges towards the "true" distribution.
-   But this generally requires a lot of samples...
-   No control over the speed of convergence...
-   Should we abandon independent sampling?

## Metropolis algorithm

This algorithm was first presented in @metropolis1953. The problem with Monte-Carlo algorithms is not convergence, but the speed at which the method converges. To increase the speed of convergence, we want to **facilitate access to the most likely parameter values**.

. . .

Principle:

- A proposal (a new position) is made on the basis of the current value of the parameter.
- A random draw is made to accept or reject the new position.

. . .

Two central ideas:

- The proposal should favour the most probable parameter values: These parameter values are used more often.
- The proposal should be limited to values adjacent to the current parameter: The speed of convergence is increased by staying where the information is (i.e., by traversing the parameter space **locally** rather than **globally**).

## Metropolis algorithm in details

Select a starting point (any value of $\theta$ can be selected).

```{r metro1, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
theta %>%
  data.frame() %>%
  ggplot(aes(x = theta, y = theta) ) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = expression(theta), y = expression(paste(p, "(", theta, ")") ) ) +
  scale_x_continuous(breaks = 1:7) +
  annotate(
    geom = "segment", x = 4, y = 9.5, xend = 4, yend = 7.5,
    arrow = arrow(length = unit(5, "mm") )
    ) +
  annotate(
      geom = "text", x = 4, y = 10,
      label = "Starting position", hjust = "center", size = 5
      )
```

## Metropolis algorithm in details

Propose a new position (i.e., a new value for $\theta$) centred on the current value of $\theta$.

```{r metro2, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
theta %>%
  data.frame() %>%
  ggplot(aes(x = theta, y = theta) ) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = expression(theta), y = expression(paste(p, "(", theta, ")") ) ) +
  scale_x_continuous(breaks = 1:7) +
  annotate(
    geom = "segment", x = 3, y = 9.5, xend = 3, yend = 7.5,
    arrow = arrow(length = unit(5, "mm") )
    ) +
  annotate(
    geom = "segment", x = 5, y = 9.5, xend = 5, yend = 7.5,
    arrow = arrow(length = unit(5, "mm") )
    ) +
  annotate(
      geom = "text", x = 3, y = 10,
      label = "50%", hjust = "center", size = 5
      ) +
  annotate(
      geom = "text", x = 5, y = 10,
      label = "50%", hjust = "center", size = 5
      )
```

## Metropolis algorithm in details

Calculate the **probability** of moving to the new position according to the following rule:

$$\Pr_{\text{move}} = \text{min} \left(\frac{\Pr(\theta_{\text{proposed}})}{\Pr(\theta_{\text{current}})}, 1 \right)$$

```{r metro3, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
theta %>%
  data.frame() %>%
  ggplot(aes(x = theta, y = theta) ) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = expression(theta), y = expression(paste(p, "(", theta, ")") ) ) +
  scale_x_continuous(breaks = 1:7) +
  annotate(
    geom = "segment", x = 5, y = 9.5, xend = 5, yend = 7.5,
    arrow = arrow(length = unit(5, "mm") )
    ) +
  annotate(
      geom = "text", x = 5, y = 10, label = "Pr(proposed) / Pr(current) = 5 / 4 > 1",
      hjust = "center", size = 5
      )
```

## Metropolis algorithm in details

The accepted position becomes the new starting position and the algorithm is repeated.

```{r metro4, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
theta %>%
  data.frame() %>%
  ggplot(aes(x = theta, y = theta) ) +
  geom_bar(stat = "identity", width = 0.5) +
  labs(x = expression(theta), y = expression(paste(p, "(", theta, ")") ) ) +
  scale_x_continuous(breaks = 1:7) +
  annotate(
    geom = "segment", x = 5, y = 9.5, xend = 5, yend = 7.5,
    arrow = arrow(length = unit(5, "mm") )
    ) +
  annotate(
      geom = "text", x = 5, y = 10,
      label = "New position", hjust = "center", size = 5
      )
```

## Metropolis algorithm in details

```{r metropolis, eval = TRUE, echo = TRUE}
metropolis <- function (niter = 1e2, startval = 4) {
    
    x <- rep(0, niter) # initialising the chain (vector) of length niter
    x[1] <- startval # defining the initial value of the parameter
    
    for (i in 2:niter) { # for each iteration
        
        current <- x[i - 1] # current value of the parameter
        proposal <- current + sample(c(-1, 1), size = 1)
        # we ensure the proposed value is within the [1, 7] interval
        if (proposal < 1) proposal <- 1
        if (proposal > 7) proposal <- 7
        # computing the probability of moving to the proposed position
        prob_move <- min(1, proposal / current)
        # we move (or not) according to this probability
        # x[i] <- ifelse(prob_move > runif(n = 1, min = 0, max = 1), proposal, current)
        x[i] <- sample(c(proposal, current), size = 1, prob = c(prob_move, 1 - prob_move) )
        
    }
    
    # returning the entire chain
    return (x)
    
}
```

## Monte Carlo methods vs. Metropolis algorithm

```{r metropolis1, eval = TRUE, echo = FALSE, fig.width = 25, fig.height = 6, fig.align = "center"}
set.seed(666)

theta <- 1:7
ptheta <- theta
trajLength <- 200
trajectory <- sample(theta, prob = ptheta, size = trajLength, replace = TRUE)

layout(matrix(1:2, ncol = 2), widths = c(0.75, 0.25) )

plot(
    trajectory,
    main = "Monte Carlo methods",
    ylab = bquote(theta), xlim = c(0, trajLength), xlab = "Number of iterations",
    type = "o", pch = 20, col = prior_color,
    cex.lab = 2, cex.main = 3, cex.axis = 2
    )

barplot(
    table(trajectory), col = prior_color,
    horiz = TRUE, axes = FALSE, axisnames = FALSE
    )
```

```{r metropolis2, eval = TRUE, echo = FALSE, fig.width = 25, fig.height = 6, fig.align = "center"}
set.seed(666)

trajectory <- metropolis(niter = trajLength, startval = 4)

layout(matrix(1:2, ncol = 2), widths = c(0.75, 0.25) )

plot(
  trajectory,
  main = "Metropolis algorithm",
  ylab = bquote(theta), xlim = c(0, trajLength), xlab = "Number of iterations",
  type = "o", pch = 20, col = prior_color, cex.lab = 2, cex.main = 3, cex.axis = 2
  )

barplot(
  table(trajectory), col = prior_color,
  horiz = TRUE, axes = FALSE, axisnames = FALSE
  )
```

## Metropolis algorithm

**Application to coin tosses (continuous case)**

$~\bullet~$ The likelihood function: $\color{orangered}{p(y \given \theta, n) \propto \theta^y(1 - \theta)^{(n - y)}}$ <br> $~\bullet~$ Prior: $\color{steelblue}{p(\theta \given a, b) \propto \theta^{(a - 1)}(1 - \theta)^{(b - 1)}}$ <br> $~\bullet~$ The parameter we want to estimates lies in the $\left[0, 1 \right]$ interval.

. . .

**Problem n°1:** How should we define the proposed move?

The proposal can be modelled by a normal distribution: $\Delta \theta \sim \mathrm{Normal}(0, \sigma)$ <br> $\longrightarrow~$ The mean $\mu$ is $0$: the proposed position is around the current value of the parameter <br> $\longrightarrow~$ The variance remains to be determined, it controls the distance from the new value.

## Metropolis algorithm

**Problem n°2 :** What probability should we use to accept or refuse the move? We use the product of the likelihood and the prior: $\color{orangered}{\theta^y(1 - \theta)^{(n - y)}}\color{steelblue}{\theta^{(a - 1)}(1 - \theta)^{(b - 1)}}$

. . .

The probability of accepting the move is given by: $\Pr_{\text{move}} = \text{min} \left(\frac{\Pr(\theta_{\text{current}} + \Delta\theta)}{\Pr(\theta_{\text{current}})}, 1 \right)$

```{r, echo = FALSE, out.width = "75%"}
knitr::include_graphics("figures/MetroAlgoAcceptProposal.png")
```

NOTE: The ratio $\frac{\Pr(\theta_{\text{current}} + \Delta\theta)}{\Pr(\theta_{\text{current}})}$ is the same whether you use the posterior distribution or the product of the prior and the likelihood (because the normalisation constant cancels out)!

## Metropolis algorithm

$~\bullet~$ Select a starting point <br> $~\bullet~$ Choose $\theta \in \left[0, 1\right]$ <br> $~\bullet~$ Only constraint: $\Pr(\theta_{\text{initial}}) \ne 0$.

. . .

$~\longrightarrow~$ Choose a direction of movement <br> $~\bullet~$ Make a draw according to $\mathrm{Normal}(0, \sigma)$

. . .

$\longrightarrow~$ Accept or reject the proposed move, depending on the probability: <br>

$$\Pr_{\text{move}} = \text{min} \left(\frac{\Pr(\theta_{\text{current}} + \Delta\theta)}{\Pr(\theta_{\text{current}})}, 1 \right)$$

$\longrightarrow~$ The calculated position becomes the new position

## Metropolis algorithm

```{r eval = TRUE, echo = FALSE, fig.width = 8, fig.height = 8}
# source("code/DBDA2E-utilities.R")

# specifies the data to be used in the likelihood function
myData <- c(rep(0, 6), rep(1, 14) )

# defines the Bernoulli likelihood function p(D|theta)
# the argument theta could be a vector, not just a scalar

likelihood <- function (theta, data) {
  
  z <- sum(data)
  N <- length(data)
  pDataGivenTheta <- theta^z * (1 - theta)^(N - z)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the likelihood for theta > 1 or for theta < 0 is zero:
  
  pDataGivenTheta[theta > 1 | theta < 0] = 0
  
  return (pDataGivenTheta)
  
}

# defines the prior density function

prior_prob <- function (theta) {
  
  pTheta <- dbeta(theta, 1, 1)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the prior for theta > 1 or for theta < 0 is zero:
  
  pTheta[theta > 1 | theta < 0] = 0
  
  return (pTheta)
  
}

# defines the relative probability of the target distribution, 
# as a function of vector theta. For our application, this
# target distribution is the unnormalized posterior distribution.

targetRelProb <- function (theta, data) {
  
  targetRelProb <- likelihood(theta, data) * prior_prob(theta)
  
  return (targetRelProb)
  
}

# specifies the length of the trajectory, that is, the number of jumps to try
trajLength <- 50000 # arbitrary large number

# initialises the vector that will store the results:
trajectory <- rep(0, trajLength)

# specifies where to start the trajectory
trajectory[1] <- 0.01 # arbitrary value

# specifies the burn-in period
burnIn <- ceiling(0.0 * trajLength) # arbitrary number, less than trajLength

# initialises accepted, rejected counters, just to monitor performance:
nAccepted <- 0
nRejected <- 0

# now generate the random walk. The 't' index is time or trial in the walk.
# specifies seed to reproduce same random walk:
set.seed(47405)

# specifies standard deviation of proposal distribution
proposalSD <- c(0.02, 0.2, 2.0)[2]

for (t in 1:(trajLength - 1) ) {
  
	currentPosition <- trajectory[t]
	
	# uses the proposal distribution to generate a proposed jump
	
	proposedJump <- rnorm(1, mean = 0, sd = proposalSD)
	
	# computes the probability of accepting the proposed jump
	
	probAccept <- min(
	  1, targetRelProb(currentPosition + proposedJump, myData) / targetRelProb(currentPosition, myData)
	  )
	
	# generates a random uniform value from the interval [0,1] to
	# decide whether or not to accept the proposed jump
	
	if (runif(1) < probAccept) {
	  
		# accept the proposed jump
		trajectory[t + 1] <- currentPosition + proposedJump
		
		# increment the accepted counter, just to monitor performance
		if (t > burnIn) {nAccepted = nAccepted + 1}
		
	} else {
	  
		# rejects the proposed jump, stay at current position
		trajectory[t + 1] = currentPosition
		
		# increments the rejected counter, just to monitor performance
		if (t > burnIn) {nRejected = nRejected + 1}
	
	}
	
}

# extracts the post-burnIn portion of the trajectory
acceptedTraj <- trajectory[ (burnIn+1) : length(trajectory) ]

##########################################
# Display the chain
###################################

# layout(matrix(1:3, nrow = 3) )
# par(mar = c(3, 4, 2, 1), mgp = c(2, 0.7, 0) )

# layout(matrix(c(1,3,2,3), 2, 2, byrow = TRUE) )
layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE) )

# trajectory, a.k.a. trace plot, beginning of chain
idxToPlot <- 1:100

plot(
  trajectory[idxToPlot], idxToPlot, main = "Beginning of Chain",
  xlab = bquote(theta), xlim = c (0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# indicates burn in limit (might not be visible if not in range)
if (burnIn > 0) {
  
  abline(h = burnIn, lty = "dotted")
  text(0.5, burnIn + 1, "Burn In", adj = c(0.5, 1.1) )
  
}

# trajectory, a.k.a. trace plot, end of chain
idxToPlot <- (trajLength - 100):trajLength

plot(
  trajectory[idxToPlot], idxToPlot, main = "End of Chain",
  xlab = bquote(theta), xlim = c(0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# displays proposal SD and acceptance ratio in the plot
text(
  0.0, trajLength, adj = c(0.0, 1.1), cex = 1.5,
  labels = bquote(
    frac(N[acc], N[pro]) == .(signif(nAccepted / length(acceptedTraj), 3) )
    )
  )

paramInfo <- BEST::plotPost(
  paramSampleVec =acceptedTraj, xlim = c(0, 1), xlab = bquote(theta), 
  cex = 2, cex.main = 1.5, col = posterior_color,
  # main = paste0(
  #     "Proposal SD = ", proposalSD,
  #     ", ESS = ", round(coda::effectiveSize(acceptedTraj), 1)
  #     )
  )

# displays proposal SD and acceptance ratio in the plot
text(
  x = 0.2, y = 1, # adj = c(0.0, 1.1),
  cex = 1.5,
  labels = paste0(
      "Proposal SD = ", proposalSD,
      "\nESS = ", round(coda::effectiveSize(acceptedTraj), 1)
      )
  )
```

## Metropolis algorithm

How do you choose $\sigma$ for the proposal? There are two indicators that can be used to assess the quality of the sampling: <br>

$\rightarrow$ The ratio between the number of proposed moves and the number of accepted moves <br>

$\rightarrow$ The effective sample size (i.e., the number of moves that are not correlated with the previous ones)

## Metropolis algorithm

```{r eval = TRUE, echo = FALSE, fig.width = 8, fig.height = 8}
# source("code/DBDA2E-utilities.R")

# specifies the data to be used in the likelihood function
myData <- c(rep(0, 6), rep(1, 14) )

# defines the Bernoulli likelihood function p(D|theta)
# the argument theta could be a vector, not just a scalar

likelihood <- function(theta, data) {
  
  z <- sum(data)
  N <- length(data)
  pDataGivenTheta <- theta^z * (1 - theta)^(N - z)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the likelihood for theta > 1 or for theta < 0 is zero:
  
  pDataGivenTheta[theta > 1 | theta < 0] = 0
  
  return(pDataGivenTheta)
  
}

# defines the prior density function

prior_prob <- function(theta) {
  
  pTheta <- dbeta(theta, 1, 1)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the prior for theta > 1 or for theta < 0 is zero:
  
  pTheta[theta > 1 | theta < 0] = 0
  
  return(pTheta)
  
}

# defines the relative probability of the target distribution, 
# as a function of vector theta. For our application, this
# target distribution is the unnormalized posterior distribution.

targetRelProb <- function(theta, data) {
  
  targetRelProb <- likelihood(theta, data) * prior_prob(theta)
  
  return(targetRelProb)
  
}

# specifies the length of the trajectory, that is, the number of jumps to try
trajLength <- 50000 # arbitrary large number

# initialises the vector that will store the results:
trajectory <- rep(0 , trajLength)

# specifies where to start the trajectory
trajectory[1] <- 0.01 # arbitrary value

# specifies the burn-in period
burnIn <- ceiling(0.0 * trajLength) # arbitrary number, less than trajLength

# initialises accepted, rejected counters, just to monitor performance:
nAccepted <- 0
nRejected <- 0

# now generate the random walk. The 't' index is time or trial in the walk.
# specifies seed to reproduce same random walk:
set.seed(47405)

# specifies standard deviation of proposal distribution
proposalSD <- c(0.02, 0.2, 2.0)[1]

for (t in 1:(trajLength - 1) ) {
  
	currentPosition <- trajectory[t]
	
	# uses the proposal distribution to generate a proposed jump
	
	proposedJump <- rnorm(1, mean = 0, sd = proposalSD)
	
	# computes the probability of accepting the proposed jump
	
	probAccept <- min(
	  1,
		targetRelProb(currentPosition + proposedJump, myData) / targetRelProb(currentPosition, myData)
		)
	
	# generates a random uniform value from the interval [0,1] to
	# decide whether or not to accept the proposed jump
	
	if (runif(1) < probAccept) {
	  
		# accept the proposed jump
		trajectory[t + 1] <- currentPosition + proposedJump
		
		# increment the accepted counter, just to monitor performance
		if (t > burnIn) {nAccepted = nAccepted + 1}
		
	} else {
	  
		# rejects the proposed jump, stay at current position
		trajectory[t + 1] = currentPosition
		
		# increments the rejected counter, just to monitor performance
		if (t > burnIn) {nRejected = nRejected + 1}
	
	}
	
}

# extracts the post-burnIn portion of the trajectory
acceptedTraj <- trajectory[ (burnIn+1) : length(trajectory) ]

##########################################
# Display the chain
###################################

# layout(matrix(1:3, nrow = 3) )
# par(mar = c(3, 4, 2, 1), mgp = c(2, 0.7, 0) )

# layout(matrix(c(1,3,2,3), 2, 2, byrow = TRUE) )
layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE) )

# trajectory, a.k.a. trace plot, beginning of chain
idxToPlot <- 1:100

plot(
  trajectory[idxToPlot], idxToPlot, main = "Beginning of Chain",
  xlab = bquote(theta), xlim = c (0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# indicates burn in limit (might not be visible if not in range)
if (burnIn > 0) {
  
  abline(h = burnIn, lty = "dotted")
  text(0.5, burnIn + 1, "Burn In", adj = c(0.5, 1.1) )
  
}

# trajectory, a.k.a. trace plot, end of chain
idxToPlot <- (trajLength - 100):trajLength

plot(
  trajectory[idxToPlot], idxToPlot, main = "End of Chain",
  xlab = bquote(theta), xlim = c(0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# displays proposal SD and acceptance ratio in the plot
text(
  0.0, trajLength, adj = c(0.0, 1.1), cex = 1.5,
  labels = bquote(
    frac(N[acc], N[pro]) == .(signif(nAccepted / length(acceptedTraj), 3) )
    )
  )

# posterior histogram
paramInfo <- BEST::plotPost(
  acceptedTraj, xlim = c(0, 1), xlab = bquote(theta), 
  cex = 2, cex.main = 1.5, col = posterior_color,
  # main = bquote(list(
  #   "Proposal SD" == .(proposalSD),
  #   "ESS" == .(round(coda::effectiveSize(acceptedTraj), 1) )
  #   ) )
  )

# displays proposal SD and acceptance ratio in the plot
text(
  x = 0.2, y = 1, # adj = c(0.0, 1.1),
  cex = 1.5,
  labels = paste0(
      "Proposal SD = ", proposalSD,
      "\nESS = ", round(coda::effectiveSize(acceptedTraj), 1)
      )
  )
```

## Metropolis algorithm

**Influence of sigma**

$\rightarrow~$ All (or almost all) proposals are accepted.

$\rightarrow~$ Few effective values...

It takes many iterations to get a satisfactory result...

## Metropolis algorithm

```{r eval = TRUE, echo = FALSE, fig.width = 8, fig.height = 8}
# source("code/DBDA2E-utilities.R")

# specifies the data to be used in the likelihood function
myData <- c(rep(0, 6), rep(1, 14) )

# defines the Bernoulli likelihood function p(D|theta)
# the argument theta could be a vector, not just a scalar

likelihood <- function(theta, data) {
  
  z <- sum(data)
  N <- length(data)
  pDataGivenTheta <- theta^z * (1 - theta)^(N - z)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the likelihood for theta > 1 or for theta < 0 is zero:
  
  pDataGivenTheta[theta > 1 | theta < 0] = 0
  
  return(pDataGivenTheta)
  
}

# defines the prior density function

prior_prob <- function(theta) {
  
  pTheta <- dbeta(theta, 1, 1)
  
  # the theta values passed into this function are generated at random,
  # and therefore might be inadvertently greater than 1 or less than 0.
  # the prior for theta > 1 or for theta < 0 is zero:
  
  pTheta[theta > 1 | theta < 0] = 0
  
  return(pTheta)
  
}

# defines the relative probability of the target distribution, 
# as a function of vector theta. For our application, this
# target distribution is the unnormalized posterior distribution.

targetRelProb <- function(theta, data) {
  
  targetRelProb <- likelihood(theta, data) * prior_prob(theta)
  
  return(targetRelProb)
  
}

# specifies the length of the trajectory, that is, the number of jumps to try
trajLength <- 50000 # arbitrary large number

# initialises the vector that will store the results:
trajectory <- rep(0 , trajLength)

# specifies where to start the trajectory
trajectory[1] <- 0.01 # arbitrary value

# specifies the burn-in period
burnIn <- ceiling(0.0 * trajLength) # arbitrary number, less than trajLength

# initialises accepted, rejected counters, just to monitor performance:
nAccepted <- 0
nRejected <- 0

# now generate the random walk. The 't' index is time or trial in the walk.
# specifies seed to reproduce same random walk:
set.seed(47405)

# specifies standard deviation of proposal distribution
proposalSD <- c(0.02, 0.2, 2.0)[3]

for (t in 1:(trajLength - 1) ) {
  
	currentPosition <- trajectory[t]
	
	# uses the proposal distribution to generate a proposed jump
	
	proposedJump <- rnorm(1, mean = 0, sd = proposalSD)
	
	# computes the probability of accepting the proposed jump
	
	probAccept <- min(
	  1,
		targetRelProb(currentPosition + proposedJump, myData) / targetRelProb(currentPosition, myData)
		)
	
	# generates a random uniform value from the interval [0,1] to
	# decide whether or not to accept the proposed jump
	
	if (runif(1) < probAccept) {
	  
		# accept the proposed jump
		trajectory[t + 1] <- currentPosition + proposedJump
		
		# increment the accepted counter, just to monitor performance
		if (t > burnIn) {nAccepted = nAccepted + 1}
		
	} else {
	  
		# rejects the proposed jump, stay at current position
		trajectory[t + 1] = currentPosition
		
		# increments the rejected counter, just to monitor performance
		if (t > burnIn) {nRejected = nRejected + 1}
	
	}
	
}

# extracts the post-burnIn portion of the trajectory
acceptedTraj <- trajectory[ (burnIn+1) : length(trajectory) ]

##########################################
# Display the chain
###################################

# layout(matrix(1:3, nrow = 3) )
# par(mar = c(3, 4, 2, 1), mgp = c(2, 0.7, 0) )

# layout(matrix(c(1,3,2,3), 2, 2, byrow = TRUE) )
layout(matrix(c(1, 2, 3, 3), 2, 2, byrow = TRUE) )

# trajectory, a.k.a. trace plot, beginning of chain
idxToPlot <- 1:100

plot(
  trajectory[idxToPlot], idxToPlot, main = "Beginning of Chain",
  xlab = bquote(theta), xlim = c (0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# indicates burn in limit (might not be visible if not in range)
if (burnIn > 0) {
  
  abline(h = burnIn, lty = "dotted")
  text(0.5, burnIn + 1, "Burn In", adj = c(0.5, 1.1) )
  
}

# trajectory, a.k.a. trace plot, end of chain
idxToPlot <- (trajLength - 100):trajLength

plot(
  trajectory[idxToPlot], idxToPlot, main = "End of Chain",
  xlab = bquote(theta), xlim = c(0, 1), ylab = "Step in Chain",
  type = "o", pch = 20, col = posterior_color, cex.lab = 1.5
  )

# displays proposal SD and acceptance ratio in the plot
text(
  0.0, trajLength, adj = c(0.0, 1.1), cex = 1.5,
  labels = bquote(
    frac(N[acc], N[pro]) == .(signif(nAccepted / length(acceptedTraj), 3) )
    )
  )

# posterior histogram
paramInfo <- BEST::plotPost(
  acceptedTraj, xlim = c(0, 1), xlab = bquote(theta), 
  cex = 2, cex.main = 1.5, col = posterior_color,
  # main = bquote(list(
  #   "Proposal SD" == .(proposalSD),
  #   "ESS" == .(round(coda::effectiveSize(acceptedTraj), 1) )
  #   ) )
  )

# displays proposal SD and acceptance ratio in the plot
text(
  x = 0.2, y = 1, # adj = c(0.0, 1.1),
  cex = 1.5,
  labels = paste0(
      "Proposal SD = ", proposalSD,
      "\nESS = ", round(coda::effectiveSize(acceptedTraj), 1)
      )
  )
```

## Metropolis algorithm

**Influence of sigma**

$\rightarrow$ Proposals are rarely accepted...

$\rightarrow$ Few effective values...

Many iterations are needed to obtain a satisfactory result...

## Metropolis algorithm[^1]

[^1]: The Metropolis-Hastings algorithm is an extension of the Metropolis algorithm allowing for non-symmetric proposals. See <https://en.wikipedia.org/wiki/Metropolis-Hastings_algorithm>.

```{r metropolis-beta-binomial1, eval = TRUE, echo = TRUE}
metropolis_beta_binomial <- function (niter = 1e2, startval = 0.5) {
    
    x <- rep(0, niter) # initialising the chain (vector) of length niter
    x[1] <- startval # defining the starting/initial value
    
    for (i in 2:niter) {
        
        current <- x[i - 1] # current value of the parameter
        current_plaus <- dbeta(current, 2, 3) * dbinom(1, 2, current)
        # proposal <- runif(n = 1, min = current - w, max = current + w) # proposed value
        proposal <- rnorm(n = 1, mean = current, sd = 0.1) # proposed value
        # ensuring that the proposed value is within the [0, 1] interval
        if (proposal < 0) proposal <- 0
        if (proposal > 1) proposal <- 1
        proposal_plaus <- dbeta(proposal, 2, 3) * dbinom(1, 2, proposal)
        # computing the probability of moving
        alpha <- min(1, proposal_plaus / current_plaus)
        # moving (or not) according to this probability
        x[i] <- sample(c(current, proposal), size = 1, prob = c(1 - alpha, alpha) )
        
    }
    
    return (x)
    
}
```

## Metropolis algorithm

```{r metropolis-beta-binomial2, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
z1 <- metropolis_beta_binomial(niter = 1e4, startval = 0.5)
z2 <- metropolis_beta_binomial(niter = 1e4, startval = 0.5)

data.frame(z1 = z1, z2 = z2) %>%
  mutate(sample = 1:nrow(.) ) %>%
  pivot_longer(cols = z1:z2) %>%
  ggplot(aes(x = sample, y = value, colour = name) ) +
  geom_line(show.legend = FALSE) +
  labs(x = "Number of iterations", y = expression(theta) ) + ylim(c(0, 1) )
```

## Metropolis algorithm

```{r metropolis-beta-binomial3, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
data.frame(z1 = z1, z2 = z2) %>%
  pivot_longer(cols = z1:z2) %>%
  rownames_to_column() %>%
  mutate(rowname = as.numeric(rowname) ) %>%
  ggplot(aes(x = value) ) +
  geom_histogram(aes(y = ..density..), color = "white", alpha = 0.8) +
  stat_function(fun = dbeta, args = list(3, 4), color = "magenta4", size = 1) +
  facet_wrap(~name) +
  labs(x = expression(theta), y = "Density")
```

## Metropolis-Hastings algorithm {background-iframe="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=RandomWalkMH&target=standard"}

## Hamiltonian Monte Carlo

The Metropolis and Metropolis-Hastings (or Gibbs) algorithms perform poorly when the model parameters are strongly correlated. The **Hamiltonian Monte Carlo** algorithm solves these problems by taking into account the geometry of the posterior space. We adapt the proposal to the geometry of the posterior distribution around the current position.

. . .

We use Hamiltonians which represent the total energy of a system. This energy is broken down into its **potential energy** (which depends on its position in $\Theta$ parameter space) and its **kinetic energy**, which depends on its **momentum** $m$:

$$
H(\theta, m) = \underbrace{U(\theta)}_{\text{potential energy}} + \underbrace{KE(m)}_{\text{kinetic energy}}
$$

. . .

The potential energy is given by the negative of the log of the posterior density (non-normalised):

$$U(\theta) = -\log[p(\text{data} \given \theta) \times p(\theta)]$$

As the posterior density increases, the potential energy decreases (i.e., it becomes more negative).

## Hamiltonian Monte Carlo

```{r hmc1, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/HMC alorithme.png")
```

## Hamiltonian Monte Carlo

- Select a starting point $\theta_{0}$: Any value of $\theta$ in posterior space can be selected.

- The force with which the ball is thrown (moment) is randomly generated, for example from a multivariate normal distribution: $m \sim \mathrm{MVNormal}(\mu, \Sigma)$.

- A trajectory approximation algorithm (e.g., leapfrog) is used to estimate the trajectory and final position of the ball in posterior space for a given trajectory duration.

- After a certain time, the final position of the ball and its moment are recorded.

- The proposed movement is accepted or rejected according to the following probability (where $\phi$ (phi) is the moment associated with the marble):

. . .

$$
\Pr_{\text{move}} = \min \left(\frac{p(\theta_{\text{proposed}} \given \text{data})\ p(\phi_{\text{proposed}})}{p(\theta_{\text{current}} \given \text{data})\ p(\phi_{\text{current}})}, 1 \right)
$$

- We save the new position and start again...

## Influence of trajectory duration...

```{r hmc_erreur, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/HMC alorithme ERREUR1.png")
```

## Influence of variability in the initial momentum...

```{r hmc_erreur2, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/HMC alorithme ERREUR2.png")
```

## Hamiltonian Monte Carlo {background-iframe="https://chi-feng.github.io/mcmc-demo/app.html?algorithm=HamiltonianMC&target=standard"}

## Assessing MCMCs

These methods may not converge to the "true" posterior distribution, due to limited computation time, the parametrisation of certain hyper-parameters (e.g., variance of the normal distribution of the proposal, or variance of the initial moment for HMC).

These methods produce chains of parameter values (samples). The use of a particular MCMC algorithm to sample the posterior distribution is based on three objectives:

- The chain values must be representative of the posterior distribution. These values must not depend on the starting point. The values should not be restricted to a particular region of the parameter space.

- The chain must be long enough to ensure the accuracy and stability of the result. The central tendency and HDI calculated from the chain must not change if the procedure is restarted.

- The chain should be generated efficiently (i.e., with as few iterations as possible).

## Assessing MCMCs - Representativeness

::: nonincremental
- Visual verification of trajectories: Chains must occupy the same space, convergence does not depend on the starting point, no chain must have a particular trajectory (e.g., cyclic).
- Visual check of densities: Densities must overlap.
:::

```{r repres1, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/Verif_representativité1.png")
```

## Assessing MCMCs - Representativeness

This display shows only the first 500 iterations. The trajectories do not overlap at the beginning (orange zone). The density is also affected. In practice, these first iterations are suppressed ("burn-in" or "warm-up" period).

```{r repres2, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/Verif_representativité2.png")
```

## Assessing MCMCs - Representativeness

Numerical verification of chains: The **shrink factor** (also known as $\hat{R}$ or `Rhat`) is the ratio between the inter-chain and intra-chain variance. This value should ideally tend towards 1 (it is considered acceptable up to 1.01).

```{r repres3, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/Verif_representativité3.png")
```

## Assessing MCMCs - Stability and precision

The longer the chain, the more accurate and stable the result. If the chain "lingers" on each position, and the number of iterations remains the same, then we lose precision. It will need more iterations to achieve the same level of accuracy. Autocorrelation is the correlation of the chain with itself but shifted by $k$ iterations (lag).

```{r autocorrelation, echo = FALSE, out.width = "40%"}
knitr::include_graphics("figures/Verif_autocorrelation.png")
```

## Assessing MCMCs - Stability and precision

The autocorrelation function is shown for each chain (top right). Another result reflects the precision of the sample: the effective sample size, $\text{ESS} = \frac{N}{1 + 2 \sum_k \text{ACF}(k)}$. It represents the size of a non-autocorrelated sample extracted from the sum of all the chains. For reasonable HDI accuracy, an ESS greater than 1000 is recommended.

```{r repres4, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/Verif_representativité4.png")
```

## Assessing MCMCs - Stability and precision

The standard error of a set of samples is given by : $SE = SD / \sqrt{N}$. As $N$ increases, the standard error decreases. We can generalise this idea to Markov chains: $MCSE = SD / \sqrt{ESS}$. For the central tendency to be reasonably accurate, this value must be low.

```{r repres5, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/Verif_representativité5.png")
```

## Assessing MCMCs - brms implementation

```{r diagnostics1, eval = TRUE, echo = TRUE, results = "hide"}
library(tidyverse)
library(imsb)
library(brms)

d <- open_data(howell)
d2 <- d %>% filter(age >= 18)

priors <- c(
  prior(normal(150, 20), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod1 <- brm(
  formula = height ~ 1 + weight,
  prior = priors,
  family = gaussian(),
  data = d2, 
  chains = 4, # number of chains
  iter = 2000, # total number of iteration (per chain)
  warmup = 1000, # number of warm-up iterations
  thin = 1 # thinning (1 = no thinning)
  )
```

## Assessing MCMCs - brms implementation

```{r diagnostics2, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
# combo can be hist, dens, dens_overlay, trace, trace_highlight...
# cf. https://mc-stan.org/bayesplot/reference/MCMC-overview.html
plot(x = mod1, combo = c("dens_overlay", "trace") )
```

## Assessing MCMCs - brms implementation

```{r diagnostics3, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
library(bayesplot)
post <- posterior_samples(mod1, add_chain = TRUE)
post %>% mcmc_acf(pars = vars(b_Intercept:sigma), lags = 10)
```

## Assessing MCMCs - brms implementation

```{r diagnostics4, eval = TRUE, echo = TRUE}
summary(mod1)
```

## Assessing MCMCs - brms implementation

Bulk-ESS refers to the ESS calculated on the distribution of samples normalised by their rank, and more specifically around the central position of this distribution (e.g., mean or median). It is recommended that the Bulk-ESS be at least 100 times greater than the number of chains (i.e., for 4 chains, the Bulk-ESS should be at least 400).

. . .

Tail-ESS gives the minimum of the ESS calculated for the quantiles at 5% and 95% (i.e., for the tails of the distribution of samples normalised by their rank). This value must be high if we attach importance to estimating extreme values (for example to compute credible intervals).

. . .

When things go wrong, see these [recommendations](https://github.com/stan-dev/stan/wiki/Prior-Choice-Recommendations) from Stan's team about priority choices, or this [guide](https://mc-stan.org/misc/warnings.html#divergent-transitions-after-warmup) about frequent error messages. See also [recent article](https://arxiv.org/abs/1903.08008) or this [blog post](https://statmodeling.stat.columbia.edu/2019/03/19/maybe-its-time-to-let-the-old-ways-die-or-we-broke-r-hat-so-now-we-have-to-fix-it/) introducing these new tools.

## Assessing MCMCs - brms implementation

```{r diagnostics5, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
post %>% # rank plots
  mcmc_rank_overlay(pars = vars(b_Intercept:sigma) ) +
  labs(x = "Rang", y = "Frequency") +
  coord_cartesian(ylim = c(25, NA) )
```

## Summary

We have introduced and discussed the use of MCMCs to obtain samples from the (un-normalised) posterior distribution. These samples can then be used to calculate various statistics for the posterior distribution (e.g., mean, median, credible interval).

. . .

The Metropolis-Hastings algorithm can be used for any problem for which a likelihood can be calculated. However, although this algorithm is simple to code, its convergence can be very slow... Furthermore, this algorithm does not work well when there are strong correlations between the different parameters...

. . .

The HMC algorithm avoids these problems by taking into account the geometry of the posterior space as it is explored (i.e., when the algorithm decides where to go next). This algorithm converges much faster and fewer samples will be needed to approximate the posterior distribution.

. . .

The result of Bayesian inference is therefore, in practice, a set of samples obtained using MCMCs. The reliability of these estimates must be assessed by verifying (visually and numerically) that the MCMCs have indeed converged towards an optimal solution.

<!--

## Travaux pratiques

On s'intéresse à la performance économique des capitales `rgdppc_2000` en fonction de deux paramètres : la rudesse du paysage (plus ou moins vallonné) `rugged` et son appartenance au continent africain `cont_africa`.

```{r rugged, eval = TRUE, echo = TRUE}
library(tidyverse)
library(imsb)

d <- open_data(rugged) %>% mutate(log_gdp = log(rgdppc_2000) )
df1 <- d[complete.cases(d$rgdppc_2000), ]
str(df1)
```

## Travaux pratiques

Écrire le modèle qui prédit `log_gdp` en fonction de la rudesse du terrain, du continent, et de l'interaction de ces deux variables avec `brms::brm()`, en spécifiant vos propres priors. Examinez ensuite les estimations de ce modèle (interprétation des paramètres, diagnostiques des MCMCs).

$$
\begin{aligned}
\log(\text{gdp}_{i}) &\sim \mathrm{Normal}(\mu_{i}, \sigma_{i}) \\
\mu_{i} &= \alpha + \beta_{1} \times \text{rugged}_{i} + \beta_{2} \times \text{continent}_{i} + \beta_{3} \times (\text{rugged}_{i} \times \text{continent}_{i}) \\
\alpha &\sim \ldots \\
\beta_{1}, \beta_{2}, \beta_{3} &\sim \ldots \\
\end{aligned}
$$

## Proposition de réponse

```{r mod2b, eval = TRUE, echo = TRUE, results = "hide"}
priors2 <- c(
  prior(normal(0, 100), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod2 <- brm(
  formula = log_gdp ~ 1 + rugged * cont_africa,
  prior = priors2,
  family = gaussian(),
  data = df1,
  chains = 4, # nombre de MCMCs
  iter = 2000, # nombre total d'itérations (par chaîne)
  warmup = 1000 # nombre d'itérations pour le warm-up
  )
```

## Proposition de réponse

```{r mod2-summary, eval = TRUE, echo = TRUE}
summary(mod2)
```

## Proposition de réponse

```{r mod2-diagnostics, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
plot(x = mod2, combo = c("dens_overlay", "trace"), pars = "^b_")
```

## Proposition de réponse

```{r mod2-pairs, eval = TRUE, echo = TRUE, fig.width = 9, fig.height = 6}
pairs(x = mod2, np = nuts_params(mod2) ) # voir ?nuts_params
```

-->

# Generalised linear model


## Introduction

$$
\begin{align}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)}\\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{1} \times x_{1i} + \beta_{2} \times x_{2i}} \\
\end{align}
$$

The linear Gaussian model discussed in Course n°02 is characterised by a number of assumptions, including the following:

- The residuals are distributed according to a Normal distribution.
- The variance of this Normal distribution is constant (homogeneity of variance).
- The predictors act on the mean of this distribution.
- The mean follows a linear or multi-linear model.

## Introduction

This model (the choice of a Normal distribution) implies several constraints, for example:

- The observed data are defined on a continuous space.
- This space is not bounded.

. . .

How can we model data that do not respect these constraints? For example, the proportion of correct answers to a test (bounded between 0 and 1), a response time (restricted to positive values and often distributed in an approximately lognormal manner), a number of avalanches...

## Introduction

We have already encountered a different model: the Beta-Binomial model (cf. Course n°01).

$$
\begin{align}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n, p)} \\
\color{steelblue}{p} \ &\color{steelblue}{\sim \mathrm{Beta}(a, b)} \\
\end{align}
$$
- The observed data is binary (e.g., 0 vs. 1) or the result of a sum of binary observations (e.g., a proportion).
- The prior probability of success (obtaining 1) is characterised by a Beta distribution.
- The probability of success does not depend on any predictor.

## Introduction

This model implies two constraints:

- The observed data are defined in a discrete space.
- This space is bounded.

. . .

How could predictors be added to this model?

## Generalised linear model

$$
\begin{align}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n, p_{i})} \\
\color{black}{f(p_{i})} \ &\color{black}{= \alpha + \beta \times x_{i}} \\
\end{align}
$$

Objectives:

- Accounting for discrete data (e.g., failure/success) generated by a single process.
- Introducing predictors into the model.

. . .

Two changes from the Gaussian model:

- The use of a Binomial probability distribution.
- The linear model is no longer used to directly describe one of the parameters of the distribution, but a function of this parameter (the Gaussian model can also be considered to have been formulated with an identity link function).

## Link function

We use a link function to map the space of a linear (unbounded) model to the space of a potentially bounded parameter such as a probability, defined on the interval $[0, 1]$.

```{r, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models

tibble(x = seq(from = -1, to = 3, by = 0.01) ) %>%
  mutate(probability = 0.35 + x * 0.5) %>%
  ggplot(aes(x = x, y = probability) ) +
  geom_rect(xmin = -1, xmax = 3, ymin = 0,  ymax = 1, fill = "gray90") +
  geom_hline(yintercept = 0:1, linetype = 2) +
  geom_line(aes(linetype = probability > 1), linewidth = 1) +
  geom_segment(x = 1.3, xend = 3, y = 1, yend = 1, linewidth = 2 / 3) +
  scale_y_continuous(breaks = c(0, 0.5, 1) ) +
  coord_cartesian(xlim = c(0, 2), ylim = c(0, 1.2) ) +
  theme(legend.position = "none", panel.grid = element_blank() ) +
  labs(x = "Predictor value", y = "Probability")
```

## Link function

We use a link function to map the space of a linear (unbounded) model to the space of a potentially bounded parameter such as a probability, defined on the interval $[0, 1]$.

```{r, eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models

# make data for the horizontal lines
alpha <- 0
beta  <- 4

lines <-
  tibble(x = seq(from = -1, to = 1, by = 0.25) ) %>% 
  mutate(
    `log-odds` = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    )

# make the primary data 
beta <- 2

d <-
  tibble(x = seq(from = -1, to = 1, length.out = 50) ) %>% 
  mutate(
    `log-odds`  = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    ) 

# make the individual plots
p1 <-
  d %>% 
  ggplot(aes(x = x, y = `log-odds`) ) +
  geom_hline(
    data = lines,
    aes(yintercept = `log-odds`),
    color = "gray"
    ) +
  geom_line(linewidth = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Predictor value", y = "Log-odds")

p2 <-
  d %>% 
  ggplot(aes(x = x, y = probability) ) +
  geom_hline(
    data = lines,
    aes(yintercept = probability),
    color = "gray"
    ) +
  geom_line(linewidth = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Predictor value", y = "Probability")

p1 + p2
```

## Logistic regression

The logit function of the binomial GLM (known as "log-odds"):

$$\text{logit}(p_{i}) = \log \left(\frac{p_{i}}{1 - p_{i}} \right)$$

. . .

The odds of an event are the ratio between the probability of the event occurring and the probability of it not occurring. The logarithm of this odds is predicted by a linear model.

$$
\log \left(\frac{p_{i}}{1 - p_{i}} \right) = \alpha + \beta \times x_{i}
$$

. . .

To retrieve the probability of an event, we use the **inverse link** function, the **logistic** (or logit-inverse) function:

$$
p_{i} = \frac{\exp(\alpha + \beta \times x_{i})}{1 + \exp(\alpha + \beta \times x_{i})}
$$

## Complications caused by the link function

Such link functions pose problems of interpretation: a change of one unit in a predictor no longer has a constant effect on the probability but impacts it more or less according to its distance from the origin. When $x = 0$, an increase of half a unit (i.e., $\Delta x = 0.5$) results in an increase in probability of $0.25$. Then, each half-unit increase results in a smaller and smaller increase in $p$...

```{r, eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# plot from https://bookdown.org/content/4857/big-entropy-and-the-generalized-linear-model.html#generalized-linear-models

# make data for the horizontal lines
alpha <- 0
beta  <- 4

lines <-
  tibble(x = seq(from = -1, to = 1, by = 0.25) ) %>% 
  mutate(
    `log-odds` = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    )

# make the primary data 
beta <- 2

d <-
  tibble(x = seq(from = -1, to = 1, length.out = 50) ) %>% 
  mutate(
    `log-odds`  = alpha + x * beta,
    probability = exp(alpha + x * beta) / (1 + exp(alpha + x * beta) )
    ) 

# make the individual plots
p1 <-
  d %>% 
  ggplot(aes(x = x, y = `log-odds`) ) +
  geom_hline(
    data = lines,
    aes(yintercept = `log-odds`),
    color = "gray"
    ) +
  geom_line(linewidth = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Predictor value", y = "Log-odds")

p2 <-
  d %>% 
  ggplot(aes(x = x, y = probability) ) +
  geom_hline(
    data = lines,
    aes(yintercept = probability),
    color = "gray"
    ) +
  geom_line(linewidth = 1) +
  coord_cartesian(xlim = c(-1, 1) ) +
  theme(panel.grid = element_blank() ) +
  labs(x = "Predictor value", y = "Probability")

p1 + p2
```

## Complications caused by the link function

Second complication: this link function "forces" each predictor to interact with itself and with ALL the other predictors, even if the interactions are not explicit...

. . .

In a Gaussian model, the rate of change of $y$ as a function of $x$ is given by $\partial(\alpha + \beta x)~/~\partial x = \beta$ and does not depend on $x$ (i.e., $\beta$ is constant).

. . .

In a binomial GLM (with a logit link function), the probability of an event is given by the logistic function:

$$p_{i} = \frac{\exp(\alpha + \beta \times x_{i})}{1 + \exp(\alpha + \beta \times x_{i})}$$

. . .

And the rate of change of $p$ as a function of the predictor $x$ is given by:

$$
\frac{\partial p}{\partial x} = \frac{\beta}{2(1 + \cosh(\alpha + \beta \times x))}
$$

We can see that the variation on $p$ due to the predictor $x$ is a function of the predictor $x$, and also depends on the value of $alpha$... !

## Logistic regression example: Prosociality in chimpanzees

```{r chimp, echo = FALSE, out.width = "50%"}
knitr::include_graphics("figures/chimp_exp.jpg")
```

## Logistic regression example

```{r, echo = TRUE}
library(tidyverse)
library(imsb)

df1 <- open_data(chimpanzees) 
str(df1)
```

- **pulled_left**: 1 when the chimpanzee pushes the left lever, 0 otherwise.
- **prosoc_left**: 1 when the left lever is associated with the prosocial option, 0 otherwise.
- **condition**: 1 when a partner is present, 0 otherwise.

## Logistic regression example

### The question

We want to know whether the presence of a partner chimpanzee encourages the chimpanzee to press the prosocial lever, that is, the lever that gives food to both individuals. In other words, is there an interaction between the effect of laterality and the effect of the presence of another chimpanzee on the probability of pressing the left lever?

### The variables

::: nonincremental
- Observations (`pulled_left`): These are Bernoulli variables. Their value is 0/1.
- Predictor (`prosoc_left`): Are the two dishes on the left or the right?
- Predictor (`condition`): Is a partner present?
:::

## Logistic regression example

$$
\begin{align}
\color{orangered}{L_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(1, p_{i})} \\
\text{(equivalent to)} \quad \color{orangered}{L_{i}} \ &\color{orangered}{\sim \mathrm{Bernoulli}(p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, \omega)} \\
\end{align}
$$

Mathematical model without any predictor. How do you pick a value for $\omega$...?

## Prior predictive check

We write the previous model with `brms` and sample from the prior to check that the model's predictions (based on the prior and likelihood function alone) match our expectations.

```{r mod1, eval = TRUE, echo = TRUE, results = "hide"}
library(brms)

mod1.1 <- brm(
  # "trials" allows defining the number of trials (i.e., n)
  formula = pulled_left | trials(1) ~ 1,
  family = binomial(),
  prior = prior(normal(0, 10), class = Intercept),
  data = df1,
  # we samples from the prior
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod1.1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "60%"}
# retrieving sample from the prior predictive distribution
prior_draws(x = mod1.1) %>%
  # applying the inverse link function
  mutate(p = brms::inv_logit_scaled(Intercept) ) %>%
  ggplot(aes(x = p) ) +
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(x = "Prior probability of pulling the left lever", y = "Probability density")
```

## Prior predictive check

```{r ppc-mod1.2, eval = TRUE, echo = FALSE, results = "hide", fig.width = 12, fig.height = 6, out.width = "80%"}
mod1.2 <- brm(
  formula = pulled_left | trials(1) ~ 1,
  family = binomial,
  prior = prior(normal(0, 1), class = Intercept),
  data = df1,
  sample_prior = "yes"
  )

bind_rows(prior_draws(mod1.1), prior_draws(mod1.2) ) %>% 
  mutate(
    p = inv_logit_scaled(Intercept),
    w = factor(rep(c(10, 1), each = n() / 2), levels = c(10, 1) )
    ) %>%
  ggplot(aes(x = p, fill = w) ) +
  geom_density(alpha = 0.8, adjust = 0.1) +
  scale_fill_manual(expression(italic(omega) ), values = c("steelblue", "blue") ) +
  labs(x = "Prior probability of pulling the left lever", y = "Probability density")
```

## Logistic regression

The intercept is interpreted in the log-odds space... to interpret it as a probability, we should apply the inverse link function. We can use the `brms::inv_logit_scaled()` function or the `plogis()` function.

. . .

```{r, eval = TRUE, echo = TRUE}
fixed_effects <- fixef(mod1.2) # fixed effects (i.e., the intercept)
plogis(fixed_effects) # inverse link function
```

On average (without considering the predictors), it seems that chimpanzees are slightly more likely to pull the left lever than the right one...

## Logistic regression

```{r, eval = TRUE, echo = TRUE, results = "hide", fig.width = 9, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod1.2) # retrieving the posterior sample
intercept_samples <- plogis(post$b_Intercept) # posterior samples for the intercept

posterior_plot(samples = intercept_samples, compval = 0.5) + labs(x = "Probability of pulling left")
```

## Logistic regression

How can we pick a value for $\omega$ (in the priors on the slopes)?

$$
\begin{align}
\color{orangered}{L_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(1, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha + \beta_{P} P_{i} + \beta_{C} C_{i} + \beta_{PC} P_{i} C_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta_{P}, \beta_{C}, \beta_{PC}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, \omega)} \\
\end{align}
$$

- $L_{i}$ indicates whether the monkey pulled the left lever (`pulled_left`).
- $P_{i}$ indicates whether the left side corresponds to the prosocial side.
- $C_{i}$ indicates the presence of a partner.

## Logistic regression

```{r mod2, eval = TRUE, echo = TRUE, results = "hide"}
# recoding predictors
df1 <- df1 %>%
  mutate(
    prosoc_left = ifelse(prosoc_left == 1, 0.5, -0.5),
    condition = ifelse(condition == 1, 0.5, -0.5)
    )

priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 10), class = b)
  )

mod2.1 <- brm(
  formula = pulled_left | trials(1) ~ 1 + prosoc_left * condition,
  family = binomial,
  prior = priors,
  data = df1,
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod2.1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "50%"}
prior_draws(x = mod2.1) %>% # prior samples
  mutate(
    condition1 = plogis(Intercept - 0.5 * b), # p in condition 1
    condition2 = plogis(Intercept + 0.5 * b) # p in condition 0
    ) %>%
  ggplot(aes(x = condition2 - condition1) ) + # plotting the difference
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(
    x = "Difference in the probability of pulling the left lever between conditions",
    y = "Probability density"
    )
```

## Logistic regression

```{r mod2.2, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
  )

mod2.2 <- brm(
  formula = pulled_left | trials(1) ~ 1 + prosoc_left * condition,
  family = binomial,
  prior = priors,
  data = df1,
  sample_prior = "yes"
  )
```

## Prior predictive check

```{r ppc-mod2.2, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6, out.width = "50%"}
prior_draws(mod2.2) %>% # prior samples
  mutate(
    condition1 = plogis(Intercept - 0.5 * b), # p in condition 1
    condition2 = plogis(Intercept + 0.5 * b) # p in condition 0
    ) %>%
  ggplot(aes(x = condition2 - condition1) ) +
  geom_density(fill = "steelblue", adjust = 0.1) +
  labs(
    x = "Difference in the probability of pulling the left lever between conditions",
    y = "Probability density"
    )
```

## Logistic regression

```{r, eval = TRUE, echo = TRUE}
summary(mod2.2)
```

## Relative effects vs. absolute effects

The linear model does not directly predict the probability but the log-odds of the probability:

$$
\begin{align}
\text{logit}(p_{i}) &= \log \left(\frac{p_{i}}{1 - p_{i}} \right) = \alpha + \beta \times x_{i} \\
\end{align}
$$

. . .

Two types of effect can be distinguished and interpreted.

**Relative effect**: The relative effect relates to the logarithm of the probability ratio. It indicates the proportion of change induced by the predictor on the **chances** of success (or rather, on the odds). It tells us nothing about the probability of the event, in absolute terms.

. . .

**Absolute effect**: Effect which directly affects the probability of an event. It depends on all the parameters of the model and gives us the effective impact of a change of one unit of a predictor (in probability space).

## Relative effect

This is a **proportion** of change induced by the predictor on the odds ratio. Illustration with a model without interaction.

$$ 
\begin{align}
\log\left(\frac{p_{i}}{1 - p_{i}}\right) &= \alpha + \beta x_{i} \\
\frac{p_{i}}{1 - p_{i}} &= \exp(\alpha + \beta x_{i}) \\
\end{align}
$$

. . .

The proportional odds $q$ of an event is the number by which the odds are multiplied when $x_{i}$ increases by one.

$$
\begin{align}
q = \frac{\exp(\alpha + \beta(x_{i} + 1))}{\exp(\alpha + \beta x_{i})} = \frac{\exp(\alpha) \exp(\beta x_{i}) \exp(\beta)}{\exp(\alpha) \exp(\beta x_{i})} = \exp(\beta)
\end{align}
$$

When $q = 2$ (for example), a one-unit increase in $x_{i}$ doubles the odds.

## Interpreting relative effects

The relative effect of a parameter **also depends on the other parameters**. In the previous model, the predictor `prosoc_left` increases the log odds by about 0.54, which translates into an increase in odds of $\exp(0.54) \approx 1.72$, that is, an increase in odds of about 72%.

. . .

Let's assume that the intercept $\alpha = 4$.

- The probability of pulling the lever without further consideration is $\text{logit}^{-1}(4) \approx 0.98$.
- Considering the effect of `prosoc_left`, we obtain $\text{logit}^{-1}(4 + 0.54) \approx 0.99$.

. . .

An increase of 72% in the log-odds translates into an increase of just 1% in the effective probability... Relative effects can lead to misinterpretations when the scale of the variable being measured is not taken into account.

## Interpreting relative effects

```{r, eval = TRUE, echo = TRUE}
fixef(mod2.2) # retrieving estimates for "fixed effects"
```

. . .

```{r, eval = TRUE, echo = TRUE, fig.width = 9, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod2.2) # posterior samples
posterior_plot(samples = exp(post$b_prosoc_left), compval = 1) + labs(x = "Odds ratio")
```

## Absolute effects

The absolute effect depends on all the parameters of the model and gives us the effective impact of a change of one unit in a predictor (in probability space).

```{r, eval = TRUE, echo = TRUE}
model_predictions <- fitted(mod2.2) %>% # prediction for p (i.e., the probability)
  data.frame() %>% 
  bind_cols(df1) %>%
  mutate(condition = factor(condition), prosoc_left = factor(prosoc_left) )
```

```{r, eval = TRUE, echo = FALSE, fig.width = 9, fig.height = 6, out.width = "50%"}
model_predictions %>%
  ggplot(aes(
    x = prosoc_left, y = Estimate,
    ymin = Q2.5, ymax = Q97.5, colour = condition
    ) ) +
  geom_hline(yintercept = 0.5, lty = 2) +
  geom_line(
    aes(group = condition),
    size = 1,
    position = position_dodge(0.2)
    ) +
  geom_pointrange(
    aes(color = condition),
    size = 1, fatten = 2, show.legend = TRUE,
    position = position_dodge(0.2)
    ) +
  ylim(0, 1) +
  scale_x_discrete(labels = c("No", "Yes") ) +
  scale_colour_discrete(labels = c("Alone", "Social") ) +
  labs(
  x = "Was the prosocial option on the left?",
  y = "Probability of pulling the left lever"
  )
```

## Aggregated binomial regression

These data represent the number of applications to UC Berkeley by gender and department. Each application was either accepted or rejected and the results are aggregated by department and gender.

```{r eval = TRUE, echo = TRUE}
(df2 <- open_data(admission) )
```

We want to know whether there is a gender bias in recruitment?

## Aggregated binomial regression

We will build a model of the admissions decision using the gender of the applicant as a predictor.

$$
\begin{align}
\color{orangered}{\text{admit}_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_i)} \ &\color{black}{= \alpha + \beta_{m} \times m_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta_{m}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{align}
$$

. . .

Variables:

- $\text{admit}_{i}$: The number of applications accepted (`admit`).
- $n_{i}$: The total number of applications (`applications`).
- $m_{i}$: The gender of the applicant (`1 = Male`).

## Aggregated binomial regression

```{r mod3, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(prior(normal(0, 1), class = Intercept) )

mod3 <- brm(
  formula = admit | trials(applications) ~ 1,
  family = binomial(link = "logit"),
  prior = priors,
  data = df2,
  sample_prior = "yes"
  )
```

## Aggregated binomial regression

```{r mod4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
  )

# dummy-coding
df2$male <- ifelse(df2$gender == "Male", 1, 0)

mod4 <- brm(
  formula = admit | trials(applications) ~ 1 + male,
  family = binomial(link = "logit"),
  prior = priors,
  data = df2,
  sample_prior = "yes"
  )
```

## Aggregated binomial regression

```{r eval = TRUE, echo = TRUE}
summary(mod4)
```

Being a man seems to be an advantage...! The odds ratio is $\exp(0.61) \approx 1.84$.

## Aggregated binomial regression

Let's calculate the difference in probability of admission between men and women.

```{r eval = TRUE, echo = TRUE, fig.width = 8, fig.height = 6, out.width = "50%", dev = "png", dpi = 200}
post <- as_draws_df(x = mod4)
p.admit.male <- plogis(post$b_Intercept + post$b_male)
p.admit.female <- plogis(post$b_Intercept)
diff.admit <- p.admit.male - p.admit.female
posterior_plot(samples = diff.admit, compval = 0)
```

## Visualising the model's predictions

Let's examine the model's predictions by department.

```{r eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
# pp_check(mod4, type = "intervals", nsamples = 1e2, prob = 0.5, prob_outer = 0.95) +
#   scale_x_continuous(breaks = 1:12, limits = c(1, 12) ) +
#   theme_bw(base_size = 20) +
#   labs(x = "Sexe / Département", y = "Nombre d'admissions")

df2 <- df2 %>% mutate(case = factor(1:12) )

p <- 
  predict(mod4) %>% 
  as_tibble() %>% 
  bind_cols(df2)

d_text <-
  df2 %>%
  group_by(dept) %>%
  summarise(
    case  = mean(as.numeric(case) ),
    admit = mean(admit / applications) + 0.05
    )

ggplot(data = df2, aes(x = case, y = admit / applications) ) +
  geom_pointrange(
    data = p, 
    aes(
      y = Estimate / applications,
      ymin = Q2.5 / applications ,
      ymax = Q97.5 / applications
      ),
    shape = 1, alpha = 0.5
    ) +
  geom_point(color = "steelblue") +
  geom_line(
    aes(group = dept),
    color = "steelblue"
    ) +
  geom_text(
    data = d_text,
    aes(y = admit, label = dept),
    color = "steelblue"
    ) +
  coord_cartesian(ylim = 0:1) +
  scale_x_discrete(
    breaks = 1:12,
    labels = rep(c("male", "female"), 6)
    ) +
  labs(
    x = "",
    y = "Admission probability",
    title = "Posterior predictive check"
    )
```

## Aggregated binomial regression

The model's predictions are very poor... There are only two departments for which women have a lower probability of admission than men (C and E), whereas the model predicts a lower probability of admission for all departments...

. . .

The problem is twofold:

- Men and women do not apply to the same departments.
- The departments do not all have the same number of students.

. . .

This is [Simpson's "paradox"](https://en.wikipedia.org/wiki/Simpson%27s_paradox)... remarks:

- The posterior distribution alone would not have detected this problem.
- We were able to pinpoint the problem by examining the detailed model's predictions...

## Aggregated binomial regression

We therefore build a model of admission decisions by gender, within each department.

$$
\begin{align}
\color{orangered}{\text{admit}_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_i)} \ &\color{black}{= \alpha_{\text{dept}[i]} + \beta_{m} \times m_{i}} \\
\color{steelblue}{\alpha_{\text{dept}[i]}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta_{m}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{align}
$$

## Aggregated binomial regression

```{r eval = TRUE, echo = TRUE, results = "hide"}
# model without any predictor
mod5 <- brm(
  admit | trials(applications) ~ 0 + dept,
  family = binomial(link = "logit"),
  prior = prior(normal(0, 1), class = b),
  data = df2
  )

# model with one predictor (sex)
mod6 <- brm(
  admit | trials(applications) ~ 0 + dept + male,
  family = binomial(link = "logit"),
  prior = prior(normal(0, 1), class = b),
  data = df2
  )
```

## Aggregated binomial regression

```{r eval = TRUE, echo = TRUE}
summary(mod6)
```

## Aggregated binomial regression

```{r eval = TRUE, echo = TRUE}
fixef(mod6)
```

Now, the prediction for $\beta_{m}$ goes the other way... The odds ratio is $\exp(-0.1) = 0.9$, the odds of admission for men are estimated to be 90% of the odds for women.

## Aggregated binomial regression

```{r eval = TRUE, echo = FALSE, fig.width = 12, fig.height = 6, out.width = "75%"}
predict(mod6) %>%
  as_tibble() %>% 
  bind_cols(df2) %>%
  ggplot(aes(x = case, y = admit / applications) ) +
  geom_pointrange(
    aes(
      y = Estimate / applications,
      ymin = Q2.5 / applications,
      ymax = Q97.5 / applications
      ),
    color = "steelblue",
    shape = 1, alpha = 0.5
    ) +
  geom_point(color = "steelblue") +
  geom_line(
    aes(group = dept),
    color = "steelblue"
    ) +
  geom_text(
    data = d_text,
    aes(y = admit, label = dept),
    color = "steelblue"
    ) +
  coord_cartesian(ylim = 0:1) +
  scale_x_discrete(
    breaks = 1:12,
    labels = rep(c("male", "female"), 6)
    ) +
  labs(
    x = "",
    y = "Admission probability",
    title = "Posterior predictive check"
    )
```

## Conclusions

Men and women do not apply to the same departments and the departments vary in their probability of admission. In this case, women applied more to departments E and F (with a lower probability of admission) and applied less to departments A or B, with a higher probability of admission.

. . .

To assess the effect of gender on the probability of admission, we therefore need to ask the following question: "What is the difference in probability of admission between men and women **within each department**?" (rather than in general).

. . .

Remember that the regression model can be generalised to different data generation models (i.e., different probability distributions, such as Normal, Binomial, Poisson, etc) and that the parameter space can be "connected" to the predictor space (measured variables) using link functions (e.g., logarithm, exponential, logit, etc).

. . .

Remember the distinction between **relative effects** (e.g., a change in odds) and **absolute effects** (e.g., a difference in probability).

## Practical work - Experimental absenteeism

Working with human subjects implies a minimum of mutual cooperation. But this is not always the case. A non-negligible proportion of students who register for Psychology experiments do not turn up on the day they are supposed to... We wanted to estimate the **probability of a registered student's attendance** as a function of whether or not a reminder email was sent (this example is presented in detail in two blog articles, accessible [here](http://www.barelysignificant.com/post/absenteeism/) and [here](http://www.barelysignificant.com/post/absenteeism2/)).

```{r eval = TRUE, echo = TRUE}
df3 <- open_data(absence)
df3 %>% sample_frac %>% head(10)
```

## Practical work

::: nonincremental
- **What is the probability that a participant who has registered on his or her own initiative will actually come and take part in the experiment?**
- What is the effect of the reminder?
- What is the effect of the registration method?
- What is the joint effect of these two predictors?
:::

## Practical work

Write the model that predicts the presence of a participant without a predictor.

$$
\begin{aligned}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{aligned}
$$

## Practical work

```{r mod7, eval = TRUE, echo = TRUE, results = "hide"}
mod7 <- brm(
    presence | trials(total) ~ 1,
    family = binomial(link = "logit"),
    prior = prior(normal(0, 1), class = Intercept),
    data = df3,
    # using all available parallel cores
    cores = parallel::detectCores()
    )
```

```{r, eval = TRUE, echo = TRUE}
fixef(mod7) # relative effect (log-odds)
fixef(mod7) %>% plogis # absolute effect (probability of presence)
```

## Practical work

::: nonincremental
- What is the probability that a participant who has registered on his or her own initiative will actually come and take part in the experiment?
- **What is the effect of the reminder?**
- What is the effect of the registration method?
- What is the joint effect of these two predictors?
:::

## Practical work

We start by recoding into dummy variables `reminder` and `inscription`.

```{r eval = TRUE, echo = TRUE}
df3 <-
  df3 %>%
  mutate(
    reminder = ifelse(reminder == "no", 0, 1),
    inscription = ifelse(inscription == "panel", 0, 1)
    )

head(df3, n = 10)
```

## Practical work

Write the model that predicts presence as a function of recall.

$$
\begin{aligned}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha + \beta \times \text{reminder}_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{aligned}
$$

## Practical work

Write the model that predicts the probability of presence as a function of reminder.

```{r mod8, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
  )

mod8 <- brm(
    presence | trials(total) ~ 1 + reminder,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Practical work

What is the **relative** effect of the reminder email?

```{r eval = TRUE, echo = TRUE}
exp(fixef(mod8)[2]) # odds ratio with and without the reminder e-mail
```

Sending a reminder e-mail increases the odds by about $3$.

## Practical work

What is the **absolute** effect of the reminder email?

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5, dev = "png", dpi = 200}
post <- as_draws_df(x = mod8) # retrieving posterior samples
p.no <- plogis(post$b_Intercept) # probability of presence without reminder e-mail
p.yes <- plogis(post$b_Intercept + post$b_reminder) # probability of presence with reminder e-mail
posterior_plot(samples = p.yes - p.no, compval = 0, usemode = TRUE)
```

## Practical work

```{r eval = TRUE, echo = TRUE, fig.width = 8, fig.height = 4}
library(tidybayes)
library(modelr)

df3 %>%
  group_by(total) %>%
  data_grid(reminder = seq_range(reminder, n = 1e2) ) %>%
  add_fitted_draws(mod8, newdata = ., n = 100, scale = "linear") %>%
  mutate(estimate = plogis(.value) ) %>%
  group_by(reminder, .draw) %>%
  summarise(estimate = mean(estimate) ) %>%
  ggplot(aes(x = reminder, y = estimate, group = .draw) ) +
  geom_hline(yintercept = 0.5, lty = 2) +
  geom_line(aes(y = estimate, group = .draw), size = 0.5, alpha = 0.1) +
  ylim(0, 1) +
  labs(x = "Reminder e-mail", y = "Probability of presence")
```

## Practical work

::: nonincremental
- What is the probability that a participant who has registered on his or her own initiative will actually come and take part in the experiment?
- What is the effect of the reminder?
- **What is the effect of the registration method?**
- What is the joint effect of these two predictors?
:::

## Practical work

Write the model that predicts the probability of presence as a function of registration mode.

$$
\begin{aligned}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha + \beta \times \text{inscription}_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{aligned}
$$

## Practical work

```{r mod9, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
  )

mod9 <- brm(
    presence | trials(total) ~ 1 + inscription,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Practical work

```{r eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5, dev = "png", dpi = 200}
post <- as_draws_df(x = mod9)
p.panel <- plogis(post$b_Intercept) # average probability of presence - panel
p.doodle <- plogis(post$b_Intercept + post$b_inscription) # average probability of presence- doodle
posterior_plot(samples = p.panel - p.doodle, compval = 0, usemode = TRUE)
```

The probability of presence is increased by around $0.16$ when registering on a panel compared with registering on a Doodle (slightly smaller effect than for the reminder).

## Practical work

::: nonincremental
- What is the probability that a participant who has registered on his or her own initiative will actually come and take part in the experiment?
- What is the effect of the reminder?
- What is the effect of the registration method?
- **What is the joint effect of these two predictors?**
:::

## Practical work

Write the full model.

$$
\begin{aligned}
\color{orangered}{y_{i}} \ &\color{orangered}{\sim \mathrm{Binomial}(n_{i}, p_{i})} \\
\color{black}{\text{logit}(p_{i})} \ &\color{black}{= \alpha + \beta_{1} \times \text{reminder}_{i} + \beta_{2} \times \text{inscription}_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\beta_{1}, \beta_{2}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\end{aligned}
$$

## Practical work

```{r mod10, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 1), class = Intercept),
  prior(normal(0, 1), class = b)
  )

mod10 <- brm(
    presence | trials(total) ~ 1 + reminder + inscription,
    family = binomial(link = "logit"),
    prior = priors,
    data = df3,
    cores = parallel::detectCores()
    )
```

## Practical work

```{r eval = TRUE, echo = TRUE}
summary(mod10)
```

## Practical work

The reminder e-mail seems to have less effect in the full model than in the simple model... why is this?

```{r eval = TRUE, echo = TRUE}
fixef(mod8) %>% exp() # computing the odds ratio
fixef(mod9) %>% exp() # computing the odds ratio
fixef(mod10) %>% exp() # computing the odds ratio
```

## Practical work

When two predictors share some of the same information, the slope estimates are correlated...

```{r eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
as_draws_df(x = mod10) %>%
    ggplot(aes(b_reminder, b_inscription) ) +
    geom_point(size = 3, pch = 21, alpha = 0.8, color = "white", fill = "black") +
    labs(x = "Effect (slope) of reminder email", y = "Effect (slope) of registration method")
```

## Practical work

Indeed, the data were collected by two experimenters. One of them recruited all her participants via Doodle, and did not often send a reminder email. The second experimenter recruited all her participants via a physical sign in the laboratory and systematically sent a reminder email. In other words, these two variables are almost perfectly identical.

```{r eval = TRUE, echo = TRUE}
open_data(absence) %>%
  group_by(inscription, reminder) %>%
  summarise(n = sum(total) ) %>%
  spread(key = reminder, value = n) %>%
  data.frame()
```

## References {.refs}
