{
  "hash": "5d7572115a9206765b3102eecd030cfe",
  "result": {
    "markdown": "---\ntitle: Introduction à la modélisation statistique bayésienne\nsubtitle: Un cours en R, Stan, et brms\nauthor: Ladislas Nalborczyk (LPC, LNC, CNRS, Aix-Marseille Univ)\nfrom: markdown+emoji\nformat:\n  revealjs:\n    incremental: true\n    # https://quarto.org/docs/presentations/revealjs/\n    # https://quarto.org/docs/presentations/revealjs/presenting.html\n    theme: [default, ../custom.scss]\n    transition: fade\n    background-transition: fade\n    transition-speed: default # default, fast, or slow\n    slide-number: c/t\n    show-slide-number: all\n    preview-links: true\n    self-contained: true # when sharing slides\n    # chalkboard: true\n    csl: csl/apa7.csl\n    logo: https://github.com/lnalborczyk/IMSB2021/raw/master/cover.png\n    footer: \"Ladislas Nalborczyk - IMSB2022\"\n    # width: 1200 # defaults to 1050\n    # height: 900 # default to 700\n    margin: 0.15 # defaults to 0.1\n    scrollable: true\n    hide-inactive-cursor: true\n    pdf-separate-fragments: false\n    # https://quarto.org/docs/output-formats/html-code.html#highlighting\n    highlight-style: zenburn\n    code-copy: true\n    code-link: false\n    code-fold: false\n    code-summary: \"Voir le code\"\n    numbers: true\n    progress: false\ntitle-slide-attributes:\n    data-background-color: \"#1c5253\"\nbibliography: ./bib/references.bib\neditor: \n  markdown: \n    wrap: 72\n---\n\n\n## Planning\n\n\n\n\n\nCours n°01 : Introduction à l'inférence bayésienne <br> **Cours n°02 :\nModèle Beta-Binomial** <br> Cours n°03 : Introduction à brms, modèle de\nrégression linéaire <br> Cours n°04 : Modèle de régression linéaire\n(suite) <br> Cours n°05 : Markov Chain Monte Carlo <br> Cours n°06 :\nModèle linéaire généralisé <br> Cours n°07 : Comparaison de modèles <br>\nCours n°08 : Modèles multi-niveaux <br> Cours n°09 : Modèles\nmulti-niveaux généralisés <br> Cours n°10 : Data Hackathon <br>\n\n## Rappels\n\nPrincipes de l'analyse bayésienne :\n\n-   On dispose d'un ensemble de données à analyser\n-   On suppose un modèle génératif défini par un ensemble de paramètres\n-   On dispose d'une connaissance a priori quant à la valeur de ces\n    paramètres\n\n. . .\n\n> The first idea is that Bayesian inference is **reallocation of\n> credibility across possibilities**. The second foundational idea is\n> that the possibilities, over which we allocate credibility, are\n> **parameter values** in meaningful mathematical models\n> [@kruschke2015].\n\n## Rappels\n\nInférence bayésienne : On infère (ou plutôt on déduit) la probabilité\nque le paramètre ait telle ou telle valeur sachant les données (et le\nprior) via le théorème de Bayes.\n\n\n$$\n\\color{purple}{p(\\theta | y)} = \\frac{\\color{orangered}{p(y | \\theta)}\\ \\color{steelblue}{p(\\theta)}}{\\color{green}{p(y)}} \\propto \\color{orangered}{p(y | \\theta)}\\ \\color{steelblue}{p(\\theta)}\n$$\n\n\n. . .\n\nObjectif de l'analyse de données bayésienne : Faire évoluer une\nconnaissance a priori sur les paramètres $\\color{steelblue}{p(\\theta)}$\nen une connaissance a posteriori $\\color{purple}{p(\\theta | y)}$,\nintégrant l'information contenue dans les nouvelles données via\n$\\color{orangered}{p(y | \\theta)}$.\n\n## Rappels\n\nLes étapes de l'analyse de données bayésienne :\n\n**1. Définir le modèle** - Identifier les paramètres du modèle\ngénératif, définir une distribution a priori pour ces paramètres.\n\n. . .\n\n**2. Mettre à jour le modèle** - Calculer la distribution a posteriori\ndes paramètres (ou une bonne approximation).\n\n. . .\n\n**3. Interpréter la distribution postérieure** - Comparaison de modèles,\nestimation des paramètres, vérification des prédictions du modèle.\n\n. . .\n\n**Objectif du cours** : Illustrer les différentes étapes de cette\ndémarche à l'aide d'un modèle simple (un seul paramètre), le modèle\nBeta-Binomial.\n\n## Le modèle Beta-Binomial\n\nPourquoi ce modèle ?\n\n-   Le modèle Beta-Binomial couvre un grand nombre de problèmes de la\n    vie courante :\n\n    -   Réussite / échec à un test\n    -   Présence / absence d'effets secondaires lors du test d'un\n        médicament\n\n-   C'est un modèle simple\n\n    -   Un seul paramètre\n    -   Solution analytique\n\n## Loi de Bernoulli\n\nS'applique à toutes les situations où le processus de génération des\ndonnées ne peut résulter qu'en deux issues mutuellement exclusives\n(e.g., un lancer de pièce). À chaque essai, si on admet que\n$\\Pr(\\text{face}) = \\theta$, alors $\\Pr(\\text{pile}) = 1 - \\theta$.\n\n. . .\n\nDepuis Bernoulli, on sait calculer la probabilité du résultat d'un\nlancer de pièce, du moment que l'on connait le biais de la pièce\n$\\theta$. Admettons que $Y = 0$ lorsqu'on obtient pile, et que $Y = 1$\nlorsqu'on obtient face. Alors $Y$ est distribuée selon une loi de\nBernoulli :\n\n\n$$p(y \\ | \\ \\theta) = \\Pr(Y = y \\ | \\ \\theta) = \\theta^{y} (1 - \\theta)^{(1 - y)}$$\n\n\n. . .\n\nEn remplaçant $y$ par $0$ ou $1$, on retombe bien sur nos observations\nprécédentes :\n\n\n$$\\Pr(Y = 1 \\ | \\ \\theta) = \\theta^{1} (1 - \\theta)^{(1 - 1)} = \\theta \\times 1 = \\theta$$\n\n\n. . .\n\n\n$$\\Pr(Y = 0 \\ | \\ \\theta) = \\theta^{0} (1 - \\theta)^{(1 - 0)} = 1 \\times (1 - \\theta) = 1 - \\theta$$\n\n\n## Schéma de Bernoulli\n\nSi l'on dispose d'une suite de lancers $\\{Y_i\\}$ indépendants et\nidentiquement distribués (i.e., chaque lancer a une distribution de\nBernoulli de probabilité $\\theta$), l'ensemble de ces lancers peut être\ndécrit par une **distribution binomiale**.\n\n. . .\n\nPar exemple, imaginons que l'on dispose de la séquence de cinq lancers\nsuivants : Pile, Pile, Pile, Face, Face. On peut recoder cette séquence\nen $\\{0, 0, 0, 1, 1\\}$.\n\nRappel : La probabilité de chaque $1$ est $\\theta$ est la probabilité de\nchaque $0$ est $1 - \\theta$.\n\nQuelle est la probabilité d'obtenir 2 faces sur 5 lancers ?\n\n## Schéma de Bernoulli\n\nSachant que les essais sont indépendants les uns des autres, la\nprobabilité d'obtenir cette séquence est de\n$(1 - \\theta) \\times (1 - \\theta) \\times (1 - \\theta) \\times \\theta \\times \\theta$,\nc'est à dire : $\\theta^{2} (1 - \\theta)^{3}$.\n\n. . .\n\nOn peut généraliser ce résultat pour une séquence de $n$ lancers et $y$\n\"succès\" :\n\n\n$$\\theta^{y} (1 - \\theta)^{n - y}$$\n\n\n. . .\n\nMais, jusque là on a considéré seulement une seule séquence résultant en\n2 succès pour 5 lancers, mais il existe de nombreuses séquences pouvant\nrésulter en 2 succès pour 5 lancers (e.g., $\\{0, 0, 1, 0, 1\\}$,\n$\\{0, 1, 1, 0, 0\\}$)...\n\n## Coefficient binomial\n\nLe **coefficient binomial** nous permet de calculer le nombre de\ncombinaisons possibles résultant en $y$ succès pour $n$ lancers de la\nmanière suivante (lu \"$y$ parmi $n$\" ou \"nombre de combinaisons de $y$\nparmi $n$\") :\n\n\n$$\n\\left(\\begin{array}{l} n \\\\ y \\end{array}\\right) = C_{n}^{y} = \\frac{n !}{y !(n - y) !}\n$$\n\n\n. . .\n\nPar exemple pour $y = 1$ et $n = 3$, on sait qu'il existe 3 combinaisons\npossibles : $\\{0, 0, 1\\}, \\{0, 1, 0\\}, \\{1, 0, 0\\}$. On peut vérifier ça\npar le calcul, en appliquant la formule ci-dessus.\n\n\n$$\n\\left(\\begin{array}{l} 3 \\\\ 1\\end{array}\\right) = C_{1}^{3} = \\frac{3 !}{1 !(3 - 1) !} = \\frac{3 \\times 2 \\times 1}{1 \\times 2 \\times 1} = \\frac{6}{2} = 3\n$$\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\" output-location='fragment' hash='Cours02_cache/revealjs/binomialcoef_8396bb1b0fb107a039329fedc46a698a'}\n\n```{.r .cell-code}\n# computing the total number of possible configurations in R\nchoose(n = 3, k = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 3\n```\n:::\n:::\n\n\n## Loi binomiale\n\n\n$$p(y \\ | \\ \\theta) = \\Pr(Y = y \\ | \\ \\theta) = \\left(\\begin{array}{l} n \\\\ y \\end{array}\\right) \\theta^{y}(1 - \\theta)^{n - y}$$\n\n\nLa loi binomiale nous permet de calculer la probabilité d'obtenir $y$\nsuccès sur $n$ essais, pour un $\\theta$ donné. Exemple de la\ndistribution binomiale pour une pièce non biaisée ($\\theta = 0.5$),\nindiquant la probabilité d'obtenir $n$ faces sur 10 lancers (en R:\n`dbinom(x = 0:10, size = 10, prob = 0.5)`).\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-1-1.svg){fig-align='center' width=720}\n:::\n:::\n\n\n## Générer des données à partir d'une distribution binomiale\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/berndata_4bf4ccc37c76d654facd63499d7f4cfd'}\n\n```{.r .cell-code  code-line-numbers=\"|4\"}\nlibrary(tidyverse)\nset.seed(666) # for reproducibility\n\nrbinom(n = 500, size = 1, prob = 0.6) %>% # theta = 0.6\n        data.frame %>%\n        mutate(x = seq_along(.), y = cumsum(.) / seq_along(.) ) %>%\n        ggplot(aes(x = x, y = y), log = \"y\") +\n        geom_line(lwd = 1) +\n        geom_hline(yintercept = 0.6, lty = 2) +\n        labs(x = \"Nombre de lancers\", y = \"Proportion de faces\") +\n        ylim(0, 1)\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/berndata-1.svg){fig-align='center' width=50%}\n:::\n:::\n\n\n## Définition du modèle (likelihood)\n\nFonction de vraisemblance (likelihood)\n\n-   Nous considérons $y$ comme étant le nombre de succès\n-   Nous considérons le nombre d'observations $n$ comme étant une\n    **constante**\n-   Nous considérons $\\theta$ comme étant le **paramètre** de notre\n    modèle (i.e., la probabilité de succès)\n\n. . .\n\nLa fonction de vraisemblance s'écrit de la manière suivante :\n\n\n$$\n\\color{orangered}{\\mathcal{L}(\\theta\\ |\\ y, n) = p(y \\ |\\ \\theta, n) = \\left(\\begin{array}{l} n \\\\ y \\end{array}\\right) \\theta^{y}(1 - \\theta)^{n - y} \\propto \\theta^{y}(1 - \\theta)^{n - y}}\n$$\n\n\n## Vraisemblance versus probabilité\n\nOn lance à nouveau une pièce de biais $\\theta$ (où $\\theta$ représente\nla probabilité d'obtenir Face). On lance cette pièce deux fois et on\nobtient une Face et un Pile.\n\n. . .\n\nOn peut calculer la probabilité de ces données selon (i.e., *en fonction\nde*) différentes valeurs de $\\theta$ de la manière suivante :\n\n\n$$\n\\begin{aligned}\n\\Pr(F, P \\ | \\ \\theta) + \\Pr(P, F \\ | \\ \\theta) &= 2 \\times \\Pr(P \\ | \\ \\theta) \\times \\Pr(F \\ | \\ \\theta) \\\\\n&= \\theta(1 - \\theta) + \\theta(1 - \\theta) \\\\\n&= 2 \\theta(1 - \\theta)\n\\end{aligned}\n$$\n\n\n. . .\n\nCette probabilité est définie pour un jeu de données fixe et une valeur\nde $\\theta$ variable. On peut représenter cette fonction visuellement.\n\n## Vraisemblance versus probabilité\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/likelihood_af5f39d6fcdbaf4c967a513c71a5793e'}\n\n```{.r .cell-code  code-line-numbers=\"|7\"}\n# Représentation graphique de la fonction de vraisemblance de theta pour y = 1 et n = 2\n\ny <- 1 # nombre de faces\nn <- 2 # nombre d'essais\n\ndata.frame(theta = seq(from = 0, to = 1, length.out = 1e3) ) %>%\n  mutate(likelihood = dbinom(x = y, size = n, prob = theta) ) %>%\n  ggplot(aes(x = theta, y = likelihood) ) +\n  geom_area(color = \"orangered\", fill = \"orangered\", alpha = 0.5) +\n  xlab(expression(paste(theta, \" - Pr(face)\") ) ) + ylab(\"Likelihod\")\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/likelihood-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Vraisemblance versus probabilité\n\nSi on calcule l'aire sous la courbe de cette fonction, on obtient :\n\n\n$$\\int_{0}^{1} 2 \\theta(1 - \\theta) \\mathrm{d} \\theta = \\frac{1}{3}$$\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-2_11cfb19302a85d7331ca00a355583f1e'}\n\n```{.r .cell-code}\nf <- function(theta) {2 * theta * (1 - theta) }\nintegrate(f = f, lower = 0, upper = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n0.3333333 with absolute error < 3.7e-15\n```\n:::\n:::\n\n\n. . .\n\nQuand on varie $\\theta$, la fonction de vraisemblance *n'est pas* une\ndistribution de probabilité valide (i.e., son intégrale n'est pas égale\nà 1). On utilise le terme de **vraisemblance**, pour distinguer ce type\nde fonction des fonctions de densité de probabilité. On utilise la\nnotation suivante pour mettre l'accent sur le fait que la fonction de\nvraisemblance est une fonction de $\\theta$, et que les données sont\nfixes : $\\mathcal{L}(\\theta \\ | \\ data) = p(data \\ | \\ \\theta)$.\n\n## Vraisemblance versus probabilité\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-3_73642ffd0b7bd2a10c39ad822aee2719'}\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table\" style=\"margin-left: auto; margin-right: auto;\">\n<caption>Probabilité vs. vraisemblance pour deux lancers de pièce</caption>\n <thead>\n<tr>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n<th style=\"border-bottom:hidden;padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; \" colspan=\"3\"><div style=\"border-bottom: 1px solid #ddd; padding-bottom: 5px; \">Nombre de Faces (y)</div></th>\n<th style=\"empty-cells: hide;border-bottom:hidden;\" colspan=\"1\"></th>\n</tr>\n  <tr>\n   <th style=\"text-align:center;\"> theta </th>\n   <th style=\"text-align:center;\"> 0 </th>\n   <th style=\"text-align:center;\"> 1 </th>\n   <th style=\"text-align:center;\"> 2 </th>\n   <th style=\"text-align:center;\"> Total </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:center;\"> 0 </td>\n   <td style=\"text-align:center;\"> 1.00 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 0.2 </td>\n   <td style=\"text-align:center;\"> 0.64 </td>\n   <td style=\"text-align:center;\"> 0.32 </td>\n   <td style=\"text-align:center;\"> 0.04 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 0.4 </td>\n   <td style=\"text-align:center;\"> 0.36 </td>\n   <td style=\"text-align:center;\"> 0.48 </td>\n   <td style=\"text-align:center;\"> 0.16 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 0.6 </td>\n   <td style=\"text-align:center;\"> 0.16 </td>\n   <td style=\"text-align:center;\"> 0.48 </td>\n   <td style=\"text-align:center;\"> 0.36 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 0.8 </td>\n   <td style=\"text-align:center;\"> 0.04 </td>\n   <td style=\"text-align:center;\"> 0.32 </td>\n   <td style=\"text-align:center;\"> 0.64 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> 1 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:center;\"> 0.00 </td>\n   <td style=\"text-align:center;\"> 1.00 </td>\n   <td style=\"text-align:center;\"> 1 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:center;\"> Total </td>\n   <td style=\"text-align:center;\"> 2.20 </td>\n   <td style=\"text-align:center;\"> 1.60 </td>\n   <td style=\"text-align:center;\"> 2.20 </td>\n   <td style=\"text-align:center;\">  </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\nNotons que la vraisemblance de $\\theta$ pour une donnée particulière est\négale à la probabilité de cette donnée pour cette valeur de $\\theta$.\nCependant, la *distribution* de ces vraisemblances (en colonne) n'est\npas une distribution de probabilité. Dans l'analyse bayésienne, **les\ndonnées sont considérées comme fixes** et la valeur de $\\theta$ est\nconsidérée comme une **variable aléatoire**.\n\n## Définition du modèle (prior)\n\nComment définir un prior dans le cas du lancer de pièce ?\n\n. . .\n\n**Aspect sémantique** $~\\rightarrow~$ *le prior doit pouvoir rendre\ncompte* :\n\n-   D'une absence d'information\n-   D'une connaissance d'observations antérieures concernant la pièce\n    étudiée\n-   D'un niveau d'incertitude concernant ces observations antérieures\n\n. . .\n\n**Aspect mathématique** $~\\rightarrow~$ *pour une solution entièrement\nanalytique* :\n\n-   Les distributions a priori et a posteriori doivent avoir la même\n    forme\n-   La vraisemblance marginale doit pouvoir se calculer analytiquement\n\n## La distribution Beta\n\n\n$$\n\\begin{align}\n\\color{steelblue}{p(\\theta\\ | \\ a, b)} \\ &\\color{steelblue}{= \\mathrm{Beta}(\\theta\\ |\\ a, b)} \\\\\n& \\color{steelblue}{= \\theta^{a - 1}(1 - \\theta)^{b - 1} / B(a, b)} \\\\\n& \\color{steelblue}{\\propto \\theta^{a - 1}(1 - \\theta)^{b - 1}}\n\\end{align}\n$$\n\n\noù $a$ et $b$ sont deux paramètres tels que $a \\geq 0$, $b \\geq 0$, et\n$B(a, b)$ est une constante de normalisation.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/beta1_038287e63a6587952db5dbd19b67327c'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/beta1-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Interprétation des paramètres du prior Beta\n\n-   On peut exprimer l'absence de connaissance a priori par $a = b = 1$\n    (distribution orange).\n-   On peut exprimer un prior en faveur d'une absence de biais par\n    $a = b \\geq 2$ (distribution verte).\n-   On peut exprimer un biais en faveur de *Face* par $a > b$\n    (distribution bleue).\n-   On peut exprimer un biais en faveur de *Pile* par $a < b$\n    (distribution violette).\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/beta2_fd712c04ba268f1f178b88d598850a07'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/beta2-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Interprétation des paramètres du prior Beta\n\nLe niveau de certitude augmente avec la somme $\\kappa = a + b$.\n\n-   Aucune idée sur la provenance de la pièce : $a = b = 1$ -\\> **prior\n    plat**.\n-   En attendant le début de l'expérience, on a lancé la pièce 10 fois\n    et observé 5 \"Face\" : $a = b = 5$ -\\> **prior peu informatif**.\n-   La pièce provient de la banque de France : $a = b = 50$ -\\> **prior\n    fort**.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/beta3_43eda745c2f40740523c6b8442c319f1'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/beta3-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Interprétation des paramètres du prior Beta\n\nSupposons que l'on dispose d'une estimation de la valeur la plus\nprobable $\\omega$ du paramètre $\\theta$. On peut reparamétriser la\ndistribution Beta en fonction du mode $\\omega$ et du niveau de certitude\n$\\kappa$ :\n\n\n$$\n\\begin{align}\na &= \\omega(\\kappa - 2) + 1 \\\\\nb &= (1 - \\omega)(\\kappa - 2) + 1 &&\\mbox{pour } \\kappa > 2\n\\end{align}\n$$\n\n\n. . .\n\nSi $\\omega = 0.65$ et $\\kappa = 25$ alors\n$p(\\theta) = \\mathrm{Beta}(\\theta \\ | \\ 15.95, 9.05)$. <br> Si\n$\\omega = 0.65$ et $\\kappa = 10$ alors\n$p(\\theta) = \\mathrm{Beta}(\\theta \\ | \\ 6.2, 3.8)$.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/beta4_77b2830bb3da853b187264589d73675b'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/beta4-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Prior conjugué\n\nFormellement, si $\\mathcal{F}$ est une classe de distributions\nd'échantillonnage $p(y|\\theta)$, et $\\mathcal{P}$ est une classe de\ndistributions a priori pour $\\theta$, alors $\\mathcal{P}$ est\n**conjuguée** à $\\mathcal{F}$ si et seulement si :\n\n\n$$\np(\\theta|y) \\in \\mathcal{P} \\text{ for all } p(\\cdot | \\theta) \\in \\mathcal{F} \\text{ and } p(\\cdot) \\in \\mathcal{P}\n$$\n\n\n(Gelman et al., 2013, p.35). En d'autres termes, un prior est appelé\n**conjugué** si, lorsqu'il est converti en une distribution a posteriori\nen étant multiplié par la fonction de vraisemblance, il conserve la même\nforme. Dans notre cas, le prior Beta est un prior conjugué pour la\nvraisemblance binomiale, car le posterior est également une distribution\nBeta.\n\n. . .\n\n> Le résultat du produit d'un prior Beta et d'une fonction de\n> vraisemblance Binomiale est proportionnel à une distribution Beta. On\n> dit alors que la distribution Beta est **un prior conjugué** de la\n> fonction de vraisemblance Binomiale.\n\n## Dérivation analytique de la distribution a posteriori\n\nSoit un prior défini par :\n$\\ \\color{steelblue}{p(\\theta \\ | \\ a, b) = \\mathrm{Beta}(a, b) \\propto \\theta^{a - 1}(1 - \\theta)^{b - 1}}$\n\n. . .\n\nSoit une fonction de vraisemblance associée à $y$ \"Face\" pour $n$\nlancers :\n$\\ \\color{orangered}{p(y \\ | \\ n, \\theta) = \\mathrm{Bin}(y \\ | \\ n, \\theta) = \\left(\\begin{array}{l} n \\\\ y \\end{array}\\right) \\theta^{y}(1 - \\theta)^{n - y} \\propto \\theta^{y}(1 - \\theta)^{n - y}}$\n\n. . .\n\n\n$$\n\\begin{align}\n\\color{purple}{p(\\theta \\ | \\ y, n)} &\\propto \\color{orangered}{p(y \\ | \\ n, \\theta)} \\ \\color{steelblue}{p(\\theta)} &&\\mbox{Théorème de Bayes} \\\\\n&\\propto \\color{orangered}{\\mathrm{Bin}(y \\ | \\ n, \\theta)} \\ \\color{steelblue}{\\mathrm{Beta}(\\theta \\ | \\ a, b)} \\\\\n&\\propto \\color{orangered}{\\theta^{y}(1 - \\theta)^{n - y}} \\ \\color{steelblue}{\\theta^{a - 1}(1 - \\theta)^{b - 1}} &&\\mbox{Application des formules précédentes} \\\\\n&\\propto \\color{purple}{\\theta}^{\\color{orangered}{y} + \\color{steelblue}{a - 1}}\\color{purple}{(1 - \\theta)}^{\\color{orangered}{n - y} + \\color{steelblue}{b - 1}} &&\\mbox{En regroupant les termes identiques} \\\\\n&\\propto \\color{purple}{\\theta^{a' - 1}(1 - \\theta)^{b' - 1}} &&\\mbox{Avec } a' = y + a \\mbox{ et } b' = n - y + b \\\\\n\\color{purple}{p(\\theta \\ | \\ y, n)} \\ &= \\color{purple}{\\mathrm{Beta}(y + a, n - y + b)}\n\\end{align}\n$$\n\n\n## Un exemple pour digérer\n\nOn observe $y = 7$ réponses correctes sur $n = 10$ questions. On choisit\nun prior $\\mathrm{Beta}(1, 1)$, c'est à dire un prior uniforme sur\n$[0, 1]$. Ce prior équivaut à une connaissance a priori de 0 succès et 0\néchecs (i.e., prior plat).\n\n. . .\n\nLa distribution postérieure est donnée par :\n\n\n$$\n\\begin{align}\n\\color{purple}{p(\\theta \\ | \\ y, n)} &\\propto \\color{orangered}{p(y \\ | \\ n, \\theta)} \\ \\color{steelblue}{p(\\theta)} \\\\\n&\\propto \\color{orangered}{\\mathrm{Bin}(7 \\ | \\ 10, \\theta)} \\ \\color{steelblue}{\\mathrm{Beta}(\\theta \\ | \\ 1, 1)} \\\\\n&= \\color{purple}{\\mathrm{Beta}(y + a, n - y + b)} \\\\\n&= \\color{purple}{\\mathrm{Beta}(8, 4)}\n\\end{align}\n$$\n\n\n. . .\n\nLa moyenne de la distribution postérieure est donnée par :\n\n\n$$\n\\color{purple}{\\underbrace{\\frac{y + a}{n + a + b}}_{posterior}} = \\color{orangered}{\\underbrace{\\frac{y}{n}}_{data}} \\underbrace{\\frac{n}{n + a + b}}_{weight} + \\color{steelblue}{\\underbrace{\\frac{a}{a + b}}_{prior}} \\underbrace{\\frac{a + b}{n + a + b}}_{weight}\n$$\n\n\n## Un exemple pour digérer\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/beta-exemple_c599ac5ea6b3106e5155cdefc4ac6939'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/beta-exemple-1.svg){fig-align='center' width=864}\n:::\n:::\n\n\n## Influence du prior sur la distribution postérieure\n\nCas $n < a + b, (n = 10, a = 4, b = 16)$.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/posterior-exemple1_21eb75f4d58d21167cc349879f503baf'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/posterior-exemple1-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Influence du prior sur la distribution postérieure\n\nCas $n = a + b, (n = 20, a = 4, b = 16)$.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/posterior-exemple2_5ae64efd88f65bccd8b07153b98c00c6'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/posterior-exemple2-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Influence du prior sur la distribution postérieure\n\nCas $n > a + b, (n = 40, a = 4, b = 16)$.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/posterior-exemple3_5800034b0701f0c210281cfb81e46d27'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/posterior-exemple3-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Ce qu'il faut retenir\n\n> The posterior distribution is always a compromise between the prior\n> distribution and the likelihood function [@kruschke2015].\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/posterior-exemple4_5b6f7baa2ad3bdff7c612cb3989eb964'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/posterior-exemple4-1.svg){fig-align='center' width=1344}\n:::\n:::\n\n\n## Ce qu'il faut retenir\n\nPlus on a de données, moins le prior a d'influence dans l'estimation de\nla distribution a posteriori (et réciproquement). **Attention :**\nLorsque le prior accorde une probabilité de 0 à certaines valeurs de\n$\\theta$, le modèle est incapable d'apprendre (ces valeurs sont alors\nconsidérées comme \"impossibles\")...\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/posterior-exemple5_f97cc64fd3ed9781eb0f229d090c91b1'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/posterior-exemple5-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La vraisemblance marginale\n\n\n$$\n\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Marginal likelihood}} \\propto \\text{Likelihood} \\times \\text{Prior}\n$$\n\n$$\np(\\theta | \\text{data}) = \\frac{p(\\text{data} | \\theta) \\times \\ p(\\theta)}{p(\\text{data})} \\propto p(\\text{data} | \\theta) \\times p(\\theta)\n$$\n\n\n. . .\n\nSi on zoom sur la vraisemblance marginale (aussi connue comme\n*evidence*)...\n\n\n$$\n\\begin{align}\n\\color{green}{p(\\text{data})} &= \\int p(\\text{data}, \\theta) \\, \\mathrm d\\theta &&\\mbox{Marginalisation sur le paramètre } \\theta \\\\\n\\color{green}{p(\\text{data})} &= \\color{green}{\\int p(\\text{data} | \\theta) \\times p(\\theta) \\, \\mathrm{d} \\theta} && \\mbox{Application de la règle du produit}\n\\end{align}\n$$\n\n\n## La vraisemblance marginale\n\nPetit problème : $p(\\text{data})$ s'obtient en calculant la somme (pour\ndes variables discrètes) ou l'intégrale (pour des variables continues)\nde la densité conjointe $p(\\text{data}, \\theta)$ sur toutes les valeurs\npossibles de $\\theta$. Cela se complique lorsque le modèle comprend\nplusieurs paramètres continus...\n\n. . .\n\nPar exemple pour deux paramètres discrets :\n\n\n$$\np(\\text{data}) = \\sum_{\\theta_{1}} \\sum_{\\theta_{2}} p(\\text{data}, \\theta_{1}, \\theta_{2})\n$$\n\n\n. . .\n\nEt pour un modèle avec deux paramètres continus :\n\n\n$$\np(\\text{data}) = \\int\\limits_{\\theta_{1}} \\int\\limits_{\\theta_{2}} p(\\text{data}, \\theta_{1}, \\theta_{2}) \\mathrm{d} \\theta_{1} \\mathrm{d} \\theta_{2}\n$$\n\n\n## La vraisemblance marginale\n\nTrois méthodes pour résoudre (contourner) ce problème :\n\n-   Solution analytique $\\longrightarrow$ Utilisation d'un prior\n    conjugué (e.g., le modèle Beta-Binomial).\n\n-   Solution discrétisée $\\longrightarrow$ Calcul de la solution sur un\n    ensemble fini de points (grid method).\n\n-   Solution approchée $\\longrightarrow$ On échantillonne\n    \"intelligemment\" l'espace conjoint des paramètres (e.g., méthodes\n    MCMC, Cours n°05).\n\n## Distributions discrètes\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/discrete_7eccf14d240be6212c810912e1141b32'}\n::: {.cell-output-display}\n![](figures/discrete.png){fig-align='center' width=100%}\n:::\n:::\n\n\n## Distributions continues\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/continuous_2125edfa3559254f3e832990a3f44cf2'}\n::: {.cell-output-display}\n![](figures/continuous.png){fig-align='center' width=100%}\n:::\n:::\n\n\nProblème : Cette solution est très contraignante. Idéalement, le modèle\n(likelihood + prior) devrait être défini à partir de l'interprétation\nque l'on peut faire des paramètres de ces distributions, et non pour\nfaciliter les calculs...\n\n## La distribution postérieure, grid method\n\n::: nonincremental\n-   **Définir la grille**\n-   Calculer la valeur du prior pour chaque valeur de la grille\n-   Calculer la valeur de la vraisemblance pour chaque valeur de la\n    grille\n-   Calculer le produit prior x vraisemblance pour chaque valeur de la\n    grille, puis normalisation\n:::\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/grid1_ff885290995a165ac5e8435866dc7e14'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/grid1-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La distribution postérieure, grid method\n\n::: nonincremental\n-   Définir la grille\n-   **Calculer la valeur du prior pour chaque valeur de la grille**\n-   Calculer la valeur de la vraisemblance pour chaque valeur de la\n    grille\n-   Calculer le produit prior x vraisemblance pour chaque valeur de la\n    grille, puis normalisation\n:::\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/grid2_1b3bc15d87c93de88953565dbabad9a5'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/grid2-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La distribution postérieure, grid method\n\n::: nonincremental\n-   Définir la grille\n-   Calculer la valeur du prior pour chaque valeur de la grille\n-   **Calculer la valeur de la vraisemblance pour chaque valeur de la\n    grille**\n-   Calculer le produit prior x vraisemblance pour chaque valeur de la\n    grille, puis normalisation\n:::\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/grid3_1fb90c6579cd3529318823c13bad1ccc'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/grid3-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La distribution postérieure, grid method\n\n::: nonincremental\n-   Définir la grille\n-   Calculer la valeur du prior pour chaque valeur de la grille\n-   Calculer la valeur de la vraisemblance pour chaque valeur de la\n    grille\n-   **Calculer le produit prior x vraisemblance pour chaque valeur de la\n    grille, puis normalisation**\n:::\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/grid4_835f99c16875a0888cc0562d8407d392'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/grid4-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La distribution postérieure, grid method\n\n::: nonincremental\n-   Définir la grille\n-   Calculer la valeur du prior pour chaque valeur de la grille\n-   Calculer la valeur de la vraisemblance pour chaque valeur de la\n    grille\n-   **Calculer le produit prior x vraisemblance pour chaque valeur de la\n    grille, puis normalisation**\n:::\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/grid5_cd57a750a3e9c9990357e00c9efa3944'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/grid5-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## La distribution postérieure, grid method\n\nProblème du nombre de paramètres... En affinant la grille on augmente le\ntemps de calcul :\n\n-   3 paramètres avec une grille de $10^3$ noeuds = une grille de $10^9$\n    points de calcul\n-   10 paramètres avec une grille de $10^3$ noeuds = une grille de\n    $10^{30}$ points de calcul\n\n. . .\n\nLe \"superordinateur\" chinois Tianhe-2 réalise $33,8 \\text{×} 10^{15}$\nopérations par seconde. Si on considère qu'il réalise 3 opérations par\nnoeud de la grille, il lui faudrait $10^{14}$ secondes pour parcourir la\ngrille une fois (pour comparaison, l'âge de l'univers est\napproximativement de $(4,354 ± 0,012)\\text{×}10^{17}$ secondes)...\n\n. . .\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/work-gif_d91e193f68b1b082bde7cf91d70b9426'}\n::: {.cell-output-display}\n![](figures/not_gonna_work.gif){fig-align='center' width=500px}\n:::\n:::\n\n\n## Échantillonner la distribution postérieure\n\nPour échantillonner une distribution postérieure, on peut utiliser\ndifférentes implémentations des méthodes MCMC (e.g.,\nMetropolis-Hastings, Gibbs, Hamilton, cf. Cours n°05).\n\n. . .\n\nEn pratique :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/sampling1_ca449b74799f4adb5b85ad892ccaf0cd'}\n\n```{.r .cell-code}\np_grid <- seq(from = 0, to = 1, length.out = 1000) # creates a grid\nprior <- rep(1, 1000) # uniform prior\nlikelihood <- dbinom(y, size = n, prob = p_grid) # computes likelihood\nposterior <- (likelihood * prior) / sum(likelihood * prior) # computes posterior\nsamples <- sample(posterior, size = 1e3, prob = posterior, replace = TRUE) # sampling\nhist(samples, main = \"\", xlab = expression(theta), cex.axis = 1, cex.lab = 1.5) # histogram\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/sampling1-1.svg){fig-align='center' width=768}\n:::\n:::\n\n\n## Échantillonner la distribution postérieure\n\nLa précision de l'approximation dépend de la taille de l'échantillon...\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-4_5e86b3ed04ce45ba68953b1bf852dc30'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-4-1.svg){fig-align='center' width=1920}\n:::\n:::\n\n\n. . .\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-5_e124b85e2320909b808ed3f6396bc67c'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-5-1.svg){fig-align='center' width=1920}\n:::\n:::\n\n\n## La distribution postérieure, résumé\n\nCas analytique :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-6_3a4c12ea8bbb17c2fc92bbd102ea4ad0'}\n\n```{.r .cell-code}\np_grid <- seq(from = 0, to = 1, length.out = 1000)\na <- b <- 1 # parameters of the Beta prior\nn <- 9 # number of observations\ny <- 6 # number of successes\nposterior <- dbeta(p_grid, y + a, n - y + b)\n```\n:::\n\n\n. . .\n\nGrid method :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-7_98445ff7994e32bb430475ff6e30b559'}\n\n```{.r .cell-code}\np_grid <- seq(from = 0, to = 1, length.out = 1000)\nprior <- rep(1, 1000) # uniform prior\nlikelihood <- dbinom(x = y, size = n, prob = p_grid)\nposterior <- (likelihood * prior) / sum(likelihood * prior)\n```\n:::\n\n\n. . .\n\nÉchantillonner la distribution postérieure :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-8_9985053e495c15e222a05489bdaacca5'}\n\n```{.r .cell-code}\nsample(x = p_grid, size = 1e4, prob = posterior, replace = TRUE)\n```\n:::\n\n\n## La distribution postérieure, résumé\n\n**Méthode analytique**\n\n-   La distribution postérieure est décrite explicitement\n-   Le modèle est fortement contraint\n\n. . .\n\n**Méthode Grid**\n\n-   La distribution postérieure n'est donnée que pour un ensemble fini\n    de valeurs\n-   Plus la grille est fine, meilleure est l'estimation de la\n    distribution postérieure\n-   Compromis *Précision - Temps de calcul*\n\n## Utiliser les échantillons pour résumer la distribution postérieure\n\nEstimation de la tendance centrale : À partir d'un ensemble\nd'échantillons d'une distribution postérieure, on peut calculer la\nmoyenne, le mode, et la médiane. Par exemple pour un prior uniforme, 10\nlancers, et 3 Faces.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/tendance-centrale1_0ecc9e5b17e8049a94b9acdbfbc53126'}\n\n```{.r .cell-code}\nmode_posterior <- find_mode(samples) # en bleu\nmean_posterior <- mean(samples) # en orange\nmedian_posterior <- median(samples) # en vert\n```\n:::\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/tendance-centrale2_98d02cc8220c1bf6a9bcca9b5d6d1fee'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/tendance-centrale3_fceb598ba77f6ba0471d3ae142b788b5'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/tendance-centrale3-1.svg){fig-align='center' width=1728}\n:::\n:::\n\n\n## Utiliser les échantillons pour résumer la distribution postérieure\n\nQuelle est la probabilité que le biais de la pièce $\\theta$ soit\nsupérieur à 0.5 ?\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/superiority-prob_c103e4c82a1068f7611838859776b600'}\n\n```{.r .cell-code}\nsum(samples > 0.5) / length(samples) # équivalent à mean(samples > 0.5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.112\n```\n:::\n:::\n\n\n. . .\n\nQuelle est la probabilité que le biais de la pièce $\\theta$ soit compris\nentre 0.2 et 0.4 ?\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/interval-prob_72632af5c306c43b94a0592484390619'}\n\n```{.r .cell-code}\nsum(samples > 0.2 & samples < 0.4) / length(samples)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.5482\n```\n:::\n:::\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/interval-prob-plot_69343c898fc920824dbd8418297ecfe5'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/interval-prob-plot-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Highest density interval (HDI)\n\nHighest density interval (HDI) :\n\n-   Le HDI indique les valeurs du paramètre qui sont les plus probables\n    (sachant les données et le prior)\n-   Plus le HDI est étroit et plus le degré de certitude est élevé\n-   La largeur du HDI diminue avec l'augmentation du nombre de mesures\n\n. . .\n\n> Définition : les valeurs du paramètre $\\theta$ contenues dans un HDI à\n> 89% sont telles que $p(\\theta) > W$ où $W$ satisfait la condition\n> suivante :\n>\n> $$\\int_{\\theta \\ : \\ p(\\theta) > W} p(\\theta) \\, \\mathrm{d} \\theta = 0.89.$$\n\n## Highest density interval (HDI)\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/hdi-plot_28b72a846870ca4bfe0ecaa2eb66d75b'}\n::: {.cell-output-display}\n![](figures/HDI.png){fig-align='center' width=35%}\n:::\n:::\n\n\n## Highest density interval (HDI)\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-9_ff7f46e079eb856840160df4b202ab5d'}\n\n```{.r .cell-code}\nlibrary(BEST)\n\nset.seed(666)\np_grid <- seq(from = 0, to = 1, length.out = 1e3)\npTheta <- dbeta(p_grid, 3, 10)\nmassVec <- pTheta / sum(pTheta)\nsamples <- sample(p_grid, size = 1e4, replace = TRUE, prob = pTheta)\n\nplotPost(samples, credMass = 0.89, cex = 1.5, xlab = expression(theta), xlim = c(0, 1) )\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-9-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Region of practical equivalence (ROPE)\n\nCette procédure permet d'accepter ou de rejeter une valeur nulle (null\nvalue). La région d'équivalence pratique ou *region of practical\nequivalence* (ROPE) définit un intervalle de valeurs qu'on considère\ncomment étant \"équivalentes\" à la valeur nulle. La figure ci-dessous\nrésume les issues décisions possibles issues de cette procédure\n[@kruschke2018].\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-10_a2ac217d3b1c731e54d57d16bb2861ce'}\n::: {.cell-output-display}\n![](figures/hdi_rope.png){fig-align='center' width=50%}\n:::\n:::\n\n\n## Region of practical equivalence (ROPE)\n\nLa valeur du paramètre (e.g., $\\theta = 0.5$) est rejetée si le HDI est\nentièrement hors de la ROPE. La valeur du paramètre (e.g.,\n$\\theta = 0.5$) est acceptée si le HDI est entièrement dans la ROPE. Si\nle HDI et la ROPE se chevauchent on ne peut pas conclure...\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-11_09dadee23985c97183fe5848dbe2f51e'}\n\n:::\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-12_b398af50f25d1b917fef97c56ffe127b'}\n\n```{.r .cell-code}\nplotPost(\n  paramSampleVec = samples, credMass = 0.89,\n  cex = 2, cex.axis = 1.5, cex.lab = 2,\n  xlab = expression(theta), xlim = c(0, 1),\n  ROPE = c(0.49, 0.51)\n  )\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-12-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Comparaison de modèles\n\nOn lance une pièce 200 fois et on obtient 115 \"Faces\". Est-ce que la\npièce est biaisée ? Nous construisons deux modèles et essayons de savoir\nlequel rend le mieux compte des données.\n\n\\begin{eqnarray*}\n\\left\\{ \n\\begin{array}{ll}\n    \\mathcal{M}_0: Y \\sim \\mathrm{Binomial}(n, \\theta = 0.5) & \\quad \\text{La pièce n'est pas biaisée}\\\\\n    \\mathcal{M}_1: Y \\sim \\mathrm{Binomial}(n, \\theta \\neq 0.5) & \\quad \\text{La pièce est biaisée}\n\\end{array}\\right.\n\\end{eqnarray*}\n\n. . .\n\nLe facteur de Bayes (*Bayes factor*) fait le rapport des vraisemblances\n(marginales) des deux modèles.\n\n\n$$\\frac{p(\\mathcal{M}_{0} | \\text{data})}{p(\\mathcal{M}_{1} | \\text{data})} = \\color{green}{\\frac{p(\\text{data} | \\mathcal{M}_{0})}{p(\\text{data} | \\mathcal{M}_{1})}} \\ \\frac{p(\\mathcal{M}_{0})}{p(\\mathcal{M}_{1})}$$\n\n\n## Comparaison de modèles\n\nLe facteur de Bayes (Bayes factor) fait le rapport des vraisemblances\n(marginales) des deux modèles.\n\n\n$$\\frac{p(\\mathcal{M}_{0} | \\text{data})}{p(\\mathcal{M}_{1} | \\text{data})} = \\color{green}{\\frac{p(\\text{data} | \\mathcal{M}_{0})}{p(\\text{data} | \\mathcal{M}_{1})}} \\ \\frac{p(\\mathcal{M}_{0})}{p(\\mathcal{M}_{1})}$$\n\n\n. . .\n\nSoit dans notre exemple :\n\n\n$$BF_{01} = \\frac{p(\\mathcal{M}_{0} | \\text{data})}{p(\\mathcal{M}_{1} | \\text{data})} = \\frac{0.005955}{0.005} = 1.1971.$$\n\n\nLe rapport de probabilités a augmenté de 20% en faveur de\n$\\mathcal{M}_{0}$ après avoir pris connaissance des données. Le facteur\nde Bayes peut également s'interpréter de la manière suivante : Les\ndonnées sont 1.2 fois plus probables sous le modèle $\\mathcal{M}_{0}$\nque sous le modèle $\\mathcal{M}_{1}$.\n\n## Model checking\n\nLes deux rôles de la fonction de vraisemblance :\n\n-   C'est une fonction de $\\theta$ pour le calcul de la distribution\n    postérieure : $\\mathcal{L}(\\theta \\ | \\ y, n)$\n-   Lorsque $\\theta$ est connu / fixé, c'est une distribution de\n    probabilité : $p(y \\ |\\ \\theta, n) = \\theta^y(1 - \\theta)^{(n - y)}$\n\n. . .\n\nOn peut utiliser cette distribution de probabilité pour générer des\ndonnées... !\n\n. . .\n\nPar exemple : Générer 10000 valeurs à partir d'une loi binomiale basée\nsur 9 lancers et une probabilité de Face de 0.6 :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-13_b815681eefa737ec92625f74d5cd4457'}\n\n```{.r .cell-code}\nsamples <- rbinom(n = 1e4, size = 10, prob = 0.6)\n```\n:::\n\n\n## Model checking\n\nDeux sources d'incertitude dans ces prédictions :\n\n-   Incertitude liée au processus d'échantillonnage <br> -\\> On tire une\n    donnée issue d'une distribution Binomiale\n-   Incertitude sur la valeur de $\\theta$ elle-même <br> -\\>\n    L'incertitude quant à la valeur de $\\theta$ est représentée par une\n    distribution de probabilité (postérieure)\n\n. . .\n\nPar exemple : Générer 10000 valeurs à partir d'une loi binomiale basé\nsur 9 lancers et une probabilité de Face décrite par la distribution\npostérieure de $\\theta$ :\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-14_2d5cd73d8c93edbabbc075bb301ece76'}\n\n```{.r .cell-code}\nposterior <- rbeta(n = 1e4, shape1 = 16, shape2 = 10)\nsamples <- rbinom(n = 1e4, size = 10, prob = posterior)\n```\n:::\n\n\n## Prior and posterior predictive checking\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/ppc_a180cb27a7c06e8a921cd73cf0bd955e'}\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/ppc-1.svg){fig-align='center' width=1152}\n:::\n:::\n\n\n## Posterior predictive checking\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/model-ppc_87fce079d3c80f68a5d5d5360ae3c966'}\n::: {.cell-output-display}\n![](figures/ModelPredictions.jpg){fig-align='center' width=75%}\n:::\n:::\n\n\n## Exercices\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/tartine_7eaa8fd924d5d72a28dc2ad430ffc4b8'}\n::: {.cell-output-display}\n![](figures/tartine.jpg){fig-align='center' width=25%}\n:::\n:::\n\n\nUn analyste qui travaille dans une fabrique de célèbres petits pains\nsuédois a lu un livre qui soulevait une épineuse question... Pourquoi la\ntartine tombe toujours du côté du beurre ? À défaut de proposer une\nréponse plausible, il se propose de vérifier cette assertion. La première\nexpérience qu'il réalise consiste à faire tomber une tartine\nbeurrée de la hauteur d'une table. Les résultats obtenus sont\naccessibles dans le document suivant : `Cours02/data/experiment_TP2_1.csv`.\n\n## Récupérer les données\n\nPremière tâche : Ouvrir ce fichier (utiliser si besoin les fonctions\n`getwd()` et `setwd()`).\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-15_dd3510c80fb7bab18c23bebab02f5843'}\n\n```{.r .cell-code}\nlibrary(tidyverse)\n\n# importer les données\ndata <- read.csv(\"data/experiment_TP2_1.csv\")\n\n# description sommaire des données\nstr(data)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t100 obs. of  3 variables:\n $ X    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ trial: int  1 2 3 4 5 6 7 8 9 10 ...\n $ value: int  0 0 1 0 0 1 1 1 0 0 ...\n```\n:::\n:::\n\n\n## Questions\n\n::: nonincremental\n- La tartine n'ayant que deux faces, le résultat s'apparente à un\n    tirage sur une loi binomiale de paramètre $\\theta$ inconnu. Quelle\n    est la distribution postérieure du paramètre $\\theta$ au vue de ces\n    données, sachant que l'analyste n'avait aucun a priori (vous pouvez\n    également utiliser vos propres connaissances a priori).\n\n- Calculer le HDI à 95% de la distribution postérieure et en donner\n    une représentation graphique (indice : utilisez le package `BEST`).\n\n- Peut-on rejeter l'hypothèse nulle selon laquelle $\\theta = 0.5$ ?\n    Répondez à cette question en utilisant la procédure HDI+ROPE.\n\n- Importer les observations du fichier `experiment_TP2_2.csv`. Mettre\n    à jour le modèle en utilisant le mode de la distribution postérieure\n    calculée précédemment.\n:::\n\n## Proposition de solution - Question 1\n\nLa tartine n'ayant que deux faces, le résultat s'apparente à un tirage\nsur une loi binomiale de paramètre $\\theta$ inconnu. Quelle est la\ndistribution postérieure du paramètre $\\theta$ ?\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-16_af6ae0ca5bf3f9f72179421b03b4a3eb'}\n\n```{.r .cell-code}\n# nombre d'essais\nnbTrial <- length(data$trial)\n\n# nombre de \"succès\" (i.e., la tartine tombe du côté du beurre)\nnbSuccess <- sum(data$value)\n\n# taile de la grille\ngrid_size <- 1e3\n\n# génère la grille\np_grid <- seq(from = 0, to = 1, length.out = grid_size)\n\n# prior uniforme\nprior <- rep(1, grid_size)\n\n# calcul de la vraisemblance\nlikelihood <- dbinom(x = nbSuccess, size = nbTrial, prob = p_grid)\n\n# calcul du posterior\nposterior <- likelihood * prior / sum(likelihood * prior)\n```\n:::\n\n\n## Proposition de solution - Question 2\n\nCalculer le HDI à 95% de la distribution postérieure et en donner une\nreprésentation graphique.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-17_5f8b761724b040fd019d333c34f76699'}\n\n```{.r .cell-code}\nsamples <- sample(x = p_grid, prob = posterior, size = 1e4, replace = TRUE)\nplotPost(samples, cex = 2, cex.axis = 1.5, cex.lab = 2, xlab = expression(theta) )\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-17-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Proposition de solution - Question 3\n\nPeut-on rejeter l'hypothèse nulle selon laquelle $\\theta = 0.5$ ?\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-18_dc76d4a27100e9e6fa8af1e3894d1af6'}\n\n```{.r .cell-code}\nplotPost(\n  samples, cex = 2, cex.axis = 1.5, cex.lab = 2,\n  xlab = expression(theta),\n  ROPE = c(0.49, 0.51), compVal = 0.5\n  )\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-18-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Proposition de solution - Question 4\n\nÀ ce stade, on ne peut pas conclure. L'analyste décide de relancer une\nsérie d'observations afin d'affiner ses résultats.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-19_846e756ec58820e2534504880fb0730f'}\n\n```{.r .cell-code}\ndata2 <- read.csv(\"data/experiment_TP2_2.csv\")\nstr(data2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n'data.frame':\t500 obs. of  3 variables:\n $ X    : int  1 2 3 4 5 6 7 8 9 10 ...\n $ trial: int  1 2 3 4 5 6 7 8 9 10 ...\n $ value: int  1 1 0 1 0 0 1 1 1 0 ...\n```\n:::\n\n```{.r .cell-code}\nnbTrial2 <- length(data2$trial) # nombre d'essais\nnbSucces2 <- sum(data2$value) # nombre de succès\n```\n:::\n\n\n## Proposition de solution - Question 4\n\nOn utilise le posterior précédent comme prior de ce nouveau modèle.\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-20_7bedc2c9244a68a4767d62a8c256687b'}\n\n```{.r .cell-code}\nmode1 <- find_mode(samples)\nprior2 <- dbeta(p_grid, mode1 * (nbTrial - 2) + 1, (1 - mode1) * (nbTrial - 2) + 1)\n\ndata.frame(x = p_grid, y = prior2) %>%\n  ggplot(aes(x = x, y = y) ) +\n  geom_area(alpha = 0.8, fill = \"steelblue\") +\n  geom_line(size = 0.8) +\n  labs(x = expression(theta), y = \"Densité de probabilité\")\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-20-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Proposition de solution - Question 4 (suite)\n\n\n::: {.cell layout-align=\"center\" hash='Cours02_cache/revealjs/unnamed-chunk-21_eb666e8fd850930180a4eeb0e09e4d83'}\n\n```{.r .cell-code}\nlikelihood2 <- dbinom(x = nbSucces2, size = nbTrial2, prob = p_grid)\nposterior2 <- likelihood2 * prior2 / sum(likelihood2 * prior2)\nsamples2 <- sample(p_grid, prob = posterior2, size = 1e4, replace = TRUE)\n\nplotPost(\n  samples2, cex = 2, cex.axis = 1.5, cex.lab = 2,\n  xlab = expression(theta),\n  ROPE = c(0.49, 0.51), compVal = 0.5\n  )\n```\n\n::: {.cell-output-display}\n![](Cours02_files/figure-revealjs/unnamed-chunk-21-1.svg){fig-align='center' width=960}\n:::\n:::\n\n\n## Références {.refs}\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ],
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    function fireSlideChanged(previousSlide, currentSlide) {\n\n      // dispatch for htmlwidgets\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for reveal\n    if (window.Reveal) {\n      window.Reveal.addEventListener(\"slidechanged\", function(event) {\n        fireSlideChanged(event.previousSlide, event.currentSlide);\n      });\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}