<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapitre 1 Introduction à l’inférence bayésienne | Notes de cours - Introduction à la modélisation statistique bayésienne</title>
  <meta name="description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  <meta name="generator" content="bookdown 0.29 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapitre 1 Introduction à l’inférence bayésienne | Notes de cours - Introduction à la modélisation statistique bayésienne" />
  <meta property="og:type" content="book" />
  <meta property="og:image" content="https://www.barelysignificant.com/IMSB2022/notes/docs/./figures/cover_distributions.png" />
  <meta property="og:description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapitre 1 Introduction à l’inférence bayésienne | Notes de cours - Introduction à la modélisation statistique bayésienne" />
  
  <meta name="twitter:description" content="<p>Ce document regroupe les notes de l’édition 2022 de la formation doctorale
‘Introduction à la modélisation statistique bayésienne’, co-organisée par le collège
des écoles doctorales de l’Université Grenoble Alpes et la Maison de la Modélisation
et de la Simulation, Nanoscience et Environnement (MaiMoSiNE).</p>" />
  <meta name="twitter:image" content="https://www.barelysignificant.com/IMSB2022/notes/docs/./figures/cover_distributions.png" />

<meta name="author" content="Ladislas Nalborczyk" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  <link rel="shortcut icon" href="./figures/cover_distributions.png" type="image/x-icon" />
<link rel="prev" href="index.html"/>
<link rel="next" href="A-glossaire.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<!-- font families -->

<link href="https://fonts.googleapis.com/css?family=PT+Sans|Pacifico|Source+Sans+Pro" rel="stylesheet">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

<script src="js/hideOutput.js"></script>

<!-- Mathjax -->
<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/default.js"></script>

 <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        extensions: ["tex2jax.js", "TeX/AMSmath.js"],
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
        jax: ["input/TeX","output/CommonHTML"]
      });
      MathJax.Hub.processSectionDelay = 0;
  </script>

<!-- Global site tag (gtag.js) - Google Analytics
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-110299877-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-110299877-1');
</script>
-->

<!-- open review block -->

<script async defer src="https://hypothes.is/embed.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  background-color: #f8f8f8; }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ef2929; } /* Alert */
code span.an { color: #8f5902; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #c4a000; } /* Attribute */
code span.bn { color: #0000cf; } /* BaseN */
code span.cf { color: #204a87; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4e9a06; } /* Char */
code span.cn { color: #000000; } /* Constant */
code span.co { color: #8f5902; font-style: italic; } /* Comment */
code span.cv { color: #8f5902; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #8f5902; font-weight: bold; font-style: italic; } /* Documentation */
code span.dt { color: #204a87; } /* DataType */
code span.dv { color: #0000cf; } /* DecVal */
code span.er { color: #a40000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #0000cf; } /* Float */
code span.fu { color: #000000; } /* Function */
code span.im { } /* Import */
code span.in { color: #8f5902; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #204a87; font-weight: bold; } /* Keyword */
code span.op { color: #ce5c00; font-weight: bold; } /* Operator */
code span.ot { color: #8f5902; } /* Other */
code span.pp { color: #8f5902; font-style: italic; } /* Preprocessor */
code span.sc { color: #000000; } /* SpecialChar */
code span.ss { color: #4e9a06; } /* SpecialString */
code span.st { color: #4e9a06; } /* String */
code span.va { color: #000000; } /* Variable */
code span.vs { color: #4e9a06; } /* VerbatimString */
code span.wa { color: #8f5902; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
/* Used with Pandoc 2.11+ new --citeproc when CSL is used */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="css/style.css" type="text/css" />
<link rel="stylesheet" href="css/toc.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Introduction à la modélisation statistique bayésienne</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Préface</a></li>
<li class="chapter" data-level="1" data-path="1-introduction.html"><a href="1-introduction.html"><i class="fa fa-check"></i><b>1</b> Introduction à l’inférence bayésienne</a>
<ul>
<li class="chapter" data-level="1.1" data-path="1-introduction.html"><a href="1-introduction.html#quest-ce-quune-probabilité"><i class="fa fa-check"></i><b>1.1</b> Qu’est-ce qu’une probabilité ?</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="1-introduction.html"><a href="1-introduction.html#axiomes-des-probabilités"><i class="fa fa-check"></i><b>1.1.1</b> Axiomes des probabilités</a></li>
<li class="chapter" data-level="1.1.2" data-path="1-introduction.html"><a href="1-introduction.html#interprétations-probabilistes"><i class="fa fa-check"></i><b>1.1.2</b> Interprétations probabilistes</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="1-introduction.html"><a href="1-introduction.html#rappels-de-théorie-des-probabilités"><i class="fa fa-check"></i><b>1.2</b> Rappels de théorie des probabilités</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-conjointe"><i class="fa fa-check"></i><b>1.2.1</b> Probabilité conjointe</a></li>
<li class="chapter" data-level="1.2.2" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-marginale"><i class="fa fa-check"></i><b>1.2.2</b> Probabilité marginale</a></li>
<li class="chapter" data-level="1.2.3" data-path="1-introduction.html"><a href="1-introduction.html#probabilité-conditionnelle"><i class="fa fa-check"></i><b>1.2.3</b> Probabilité conditionnelle</a></li>
<li class="chapter" data-level="1.2.4" data-path="1-introduction.html"><a href="1-introduction.html#dérivation-du-théorème-de-bayes"><i class="fa fa-check"></i><b>1.2.4</b> Dérivation du théorème de Bayes</a></li>
<li class="chapter" data-level="1.2.5" data-path="1-introduction.html"><a href="1-introduction.html#loi-de-probabilité-cas-discret"><i class="fa fa-check"></i><b>1.2.5</b> Loi de probabilité, cas discret</a></li>
<li class="chapter" data-level="1.2.6" data-path="1-introduction.html"><a href="1-introduction.html#loi-de-probabilité-cas-continu"><i class="fa fa-check"></i><b>1.2.6</b> Loi de probabilité, cas continu</a></li>
<li class="chapter" data-level="1.2.7" data-path="1-introduction.html"><a href="1-introduction.html#aparté-quest-ce-quune-intégrale"><i class="fa fa-check"></i><b>1.2.7</b> Aparté, qu’est-ce qu’une intégrale ?</a></li>
<li class="chapter" data-level="1.2.8" data-path="1-introduction.html"><a href="1-introduction.html#notations-terminologie"><i class="fa fa-check"></i><b>1.2.8</b> Notations, terminologie</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="1-introduction.html"><a href="1-introduction.html#logique-et-raisonnement-scientifique"><i class="fa fa-check"></i><b>1.3</b> Logique et raisonnement scientifique</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="1-introduction.html"><a href="1-introduction.html#introduction-à-la-logique"><i class="fa fa-check"></i><b>1.3.1</b> Introduction à la logique</a></li>
<li class="chapter" data-level="1.3.2" data-path="1-introduction.html"><a href="1-introduction.html#quelques-syllogismes-connus"><i class="fa fa-check"></i><b>1.3.2</b> Quelques syllogismes connus</a></li>
<li class="chapter" data-level="1.3.3" data-path="1-introduction.html"><a href="1-introduction.html#quest-ce-quune-théorie-scientifique"><i class="fa fa-check"></i><b>1.3.3</b> Qu’est-ce qu’une théorie scientifique ?</a></li>
<li class="chapter" data-level="1.3.4" data-path="1-introduction.html"><a href="1-introduction.html#test-dhypothèse-nulle-et-raisonnement-scientifique"><i class="fa fa-check"></i><b>1.3.4</b> Test d’hypothèse nulle et raisonnement scientifique</a></li>
<li class="chapter" data-level="1.3.5" data-path="1-introduction.html"><a href="1-introduction.html#lapproche-par-comparaison-de-modèles"><i class="fa fa-check"></i><b>1.3.5</b> L’approche par comparaison de modèles</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="1-introduction.html"><a href="1-introduction.html#problème-du-sac-de-billes-mcelreath_statistical_2016"><i class="fa fa-check"></i><b>1.4</b> Problème du sac de billes <span class="citation">(<span>McElreath, 2016b</span>)</span></a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="1-introduction.html"><a href="1-introduction.html#énumérer-les-possibilités"><i class="fa fa-check"></i><b>1.4.1</b> Énumérer les possibilités</a></li>
<li class="chapter" data-level="1.4.2" data-path="1-introduction.html"><a href="1-introduction.html#accumulation-dévidence"><i class="fa fa-check"></i><b>1.4.2</b> Accumulation d’évidence</a></li>
<li class="chapter" data-level="1.4.3" data-path="1-introduction.html"><a href="1-introduction.html#incorporer-un-prior"><i class="fa fa-check"></i><b>1.4.3</b> Incorporer un prior</a></li>
<li class="chapter" data-level="1.4.4" data-path="1-introduction.html"><a href="1-introduction.html#des-énumérations-aux-probabilités"><i class="fa fa-check"></i><b>1.4.4</b> Des énumérations aux probabilités</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="1-introduction.html"><a href="1-introduction.html#quelques-exemples-dapplication"><i class="fa fa-check"></i><b>1.5</b> Quelques exemples d’application</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="1-introduction.html"><a href="1-introduction.html#diagnostique-médical-gigerenzer-2002"><i class="fa fa-check"></i><b>1.5.1</b> Diagnostique médical (Gigerenzer, 2002)</a></li>
<li class="chapter" data-level="1.5.2" data-path="1-introduction.html"><a href="1-introduction.html#problème-de-monty-hall"><i class="fa fa-check"></i><b>1.5.2</b> Problème de Monty Hall</a></li>
</ul></li>
</ul></li>
<li class="appendix"><span><b>Annexes</b></span></li>
<li class="chapter" data-level="A" data-path="A-glossaire.html"><a href="A-glossaire.html"><i class="fa fa-check"></i><b>A</b> Glossaire</a></li>
<li class="chapter" data-level="B" data-path="B-notations.html"><a href="B-notations.html"><i class="fa fa-check"></i><b>B</b> Notations</a></li>
<li class="chapter" data-level="" data-path="bibliographie.html"><a href="bibliographie.html"><i class="fa fa-check"></i>Bibliographie</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank"> Powered by bookdown </a></li>
<li><a href="http://www.barelysignificant.com" target="blank"> Ladislas Nalborczyk </a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes de cours - Introduction à la modélisation statistique bayésienne</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div class = rmdreview>
Ce livret est en "<b>Open Review</b>". Votre retour est essentiel afin de l'améliorer, pour vous-même ainsi que pour les futurs étudiant•e•s. Vous pouvez annoter le texte en <span style="background-color: #3297FD; color: white">le sélectionnant avec le curseur</span> et en cliquant sur l'icône dans le menu qui s'affiche en pop-up. Vous pouvez également lire les annotations des autres utilisateurs du livret en cliquant sur <i class="fa fa-chevron-left"></i> dans le coin supérieur droit de cette page.
</div>
<div id="introduction" class="section level1 hasAnchor" number="1">
<h1><span class="header-section-number">Chapitre 1</span> Introduction à l’inférence bayésienne<a href="1-introduction.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>Notre environnement est rempli d’incertitude. Quel temps fera-t-il demain ? Qui sera le prochain président de la République ? Vais-je apprendre quelque chose en lisant ce livre ? Tout individu est capable de se faire une idée intuitive de la réponse à ces questions (avec plus ou moins de réussite) sans avoir jamais lu aucun livre traitant formellement de théorie des probabilités. Cependant, un examen plus détaillé des processus menant à ces réponses révèle une complexité et une diversité insoupçonnées. Qu’est-ce qu’une probabilité ? À quoi le concept de probabilité réfère-t-il, concrètement, dans le monde ? Et surtout, à quoi est-ce que tout cela pourrait bien nous servir pour l’analyse de données ?</p>
<p>Dans ce premier chapitre, nous allons approfondir cette réflexion sur le concept de probabilité en se basant sur plusieurs définitions ayant été proposées au fil du temps. Puis, nous discuterons plus particulièrement de l’inférence bayésienne, une approche de l’inférence statistique qui utilise les probabilités comme langage pour décrire l’incertitude (et où le concept de <strong>probabilité</strong> est à comprendre dans son acception <strong>épistémique</strong>). Nous proposerons également un bref rappel de théorie des probabilités avant de dériver le théorème de Bayes à partir des règles élémentaires du calcul probabiliste. Le théorème de Bayes est le “moteur” de l’inférence statistique bayésienne, permettant de mettre à jour un état de connaissance a priori (i.e., avant d’observer certaines données) en un état de connaissance a posteriori (i.e., après avoir observé ces données). Nous illustrerons ce mécanisme par plusieurs exemples concrets.</p>
<div id="quest-ce-quune-probabilité" class="section level2 hasAnchor" number="1.1">
<h2><span class="header-section-number">1.1</span> Qu’est-ce qu’une probabilité ?<a href="1-introduction.html#quest-ce-quune-probabilité" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="axiomes-des-probabilités" class="section level3 hasAnchor" number="1.1.1">
<h3><span class="header-section-number">1.1.1</span> Axiomes des probabilités<a href="1-introduction.html#axiomes-des-probabilités" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Pour quantifier notre incertitude vis à vis de la survenue de certains <strong>événements</strong> (e.g., obtenir un chiffre pair lors d’un lancer de dé), on assigne des probabilités à ces événements. On définit une probabilité comme une valeur numérique assignée à un événement <span class="math inline">\(A\)</span>, compris comme une possibilité appartenant à l’univers <span class="math inline">\(\Omega\)</span> (l’ensemble de tous les événements possibles). Les probabilités telles que définies et utilisées dans ce livre se conforment aux axiomes suivants <span class="citation">(<a href="bibliographie.html#ref-kolmogorov_foundations_1933" role="doc-biblioref">Kolmogorov, 1933</a>)</span><a href="#fn1" class="footnote-ref" id="fnref1"><sup>1</sup></a> :</p>
<ul>
<li><p><strong>Axiome n°1</strong> : <span class="math inline">\(\Pr(A) \geq 0\)</span>. La probabilité d’un événement <span class="math inline">\(A\)</span> ne peut pas être négative.</p></li>
<li><p><strong>Axiome n°2</strong> : <span class="math inline">\(\Pr(\Omega) = 1\)</span>. La somme des probabilités de tous les événements possibles est égale à <span class="math inline">\(1\)</span> (et par conséquent, chaque probabilité individuelle ne peut dépasser <span class="math inline">\(1\)</span>).</p></li>
<li><p><strong>Axiome n°3</strong> : <span class="math inline">\(\Pr(A_{1} \cup A_{2}) = \Pr(A_{1}) + \Pr(A_{2})\)</span>. La probabilité d’obtenir soit l’événement <span class="math inline">\(A_{1}\)</span>, soit l’événement <span class="math inline">\(A_{2}\)</span> (sachant que ces événements sont <strong>incompatibles</strong>) est égale à la somme des probabilités de chacun de ces deux événements.</p></li>
</ul>
<p>Le dernier axiome est également connu comme la <strong>règle de la somme</strong> et n’est valide dans cette forme que pour des événements deux à deux <strong>incompatibles</strong> ou <strong>mutuellement exclusifs</strong>.<a href="#fn2" class="footnote-ref" id="fnref2"><sup>2</sup></a> Il se généralise à des événements non mutuellement exclusifs de la manière suivante : <span class="math inline">\(\Pr(A_{1} \cup A_{2}) = \Pr(A_{1}) + \Pr(A_{2}) - \Pr(A_{1} \cap A_{2})\)</span>. Autrement dit, et pour résumer, une probabilité est une valeur numérique positive, bornée entre 0 et 1, et qui respecte la règle de la somme.</p>
</div>
<div id="interprétations-probabilistes" class="section level3 hasAnchor" number="1.1.2">
<h3><span class="header-section-number">1.1.2</span> Interprétations probabilistes<a href="1-introduction.html#interprétations-probabilistes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Bien que nous ayons donné ci-dessus une définition des probabilités, cela ne nous donne aucune indication sur la manière d’interpréter ce genre de valeur. Qu’est-ce qu’une probabilité ? À quoi dans le monde fait référence une probabilité ? Cette question fait encore aujourd’hui couler beaucoup d’encre en philosophie de la connaissance. Nous discutons ci-dessous brièvement de quelques interprétations possibles du concept de probabilité.</p>
<div id="interprétation-classique-ou-théorique" class="section level4 hasAnchor" number="1.1.2.1">
<h4><span class="header-section-number">1.1.2.1</span> Interprétation classique (ou théorique)<a href="1-introduction.html#interprétation-classique-ou-théorique" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La première interprétation proposée est généralement la première définition que nous rencontrons dans notre cursus scolaire. Il s’agit également d’une interprétation précédent l’observation de données. En effet, dans ce cadre, une probabilité peut être calculée avant même d’avoir observé quelque donnée que ce soit, par simple connaissance du système étudié. Plus précisément, on définit la probabilité comme le rapport entre le nombre de cas favorables sur le nombre de cas possibles. Par exemple, si on s’intéresse à la probabilité de l’événement “Obtenir un chiffre pair” lors du lancer d’un dé (non pipé), alors cette probabilité peut se calculer de la manière suivante :</p>
<p><span class="math display">\[
\Pr(\text{pair}) = \frac{\text{nombre de cas favorables}}{\text{nombre de cas possibles}} = \frac{3}{6} = \frac{1}{2} \cdot
\]</span></p>
<p>Cette définition fonctionne bien pour les situations dans lesquelles il n’y a qu’un nombre <strong>fini</strong> de résultats possibles <strong>équiprobables</strong> (i.e., de même probabilité). Cependant, si on applique cette définition à des situations plus complexes, on se rend compte que sa portée est limitée. Par exemple, si on applique cette définition à la question suivante : “Quelle est la probabilité qu’il pleuve demain ?”, on se retrouve avec le calcul suivant :</p>
<p><span class="math display">\[
\Pr(\text{pluie}) = \frac{\text{pluie}}{ \{\text{pluie, non-pluie} \} } = \frac{1}{2}
\]</span></p>
<p>Et on se rend compte assez facilement que cette définition ne s’applique pas à des situations de prédiction météorologique, où il peut exister un grand nombre d’évènements possibles n’ayant pas nécessairement la même probabilité.</p>
</div>
<div id="interprétation-fréquentiste-ou-empirique" class="section level4 hasAnchor" number="1.1.2.2">
<h4><span class="header-section-number">1.1.2.2</span> Interprétation fréquentiste (ou empirique)<a href="1-introduction.html#interprétation-fréquentiste-ou-empirique" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>L’interprétation fréquentiste du concept de probabilité propose que la probabilité est ce vers quoi tend le rapport présenté dans la section précédente lorsque le nombre d’essais s’approche de l’infini (i.e., lorsque le nombre d’essais devient très important). Autrement dit, la probabilité est définie de la manière suivante :</p>
<p><span class="math display">\[\Pr(x) = \lim_{n_{t} \to \infty}\frac{n_{x}}{n_{t}}\]</span></p>
<p>où <span class="math inline">\(n_{x}\)</span> est le nombre d’occurrences de l’événement <span class="math inline">\(x\)</span> et <span class="math inline">\(n_{t}\)</span> le nombre total d’essais. L’interprétation <strong>fréquentiste</strong> postule que, à long-terme (i.e., quand le nombre d’essais s’approche de l’infini), la fréquence relative va converger <em>exactement</em> vers ce qu’on appelle “probabilité”.</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="1-introduction.html#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb1-2"><a href="1-introduction.html#cb1-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-3"><a href="1-introduction.html#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="fu">sample</span>(<span class="at">x =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>), <span class="at">size =</span> <span class="dv">500</span>, <span class="at">replace =</span> <span class="cn">TRUE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb1-4"><a href="1-introduction.html#cb1-4" aria-hidden="true" tabindex="-1"></a>        <span class="fu">data.frame</span>() <span class="sc">%&gt;%</span></span>
<span id="cb1-5"><a href="1-introduction.html#cb1-5" aria-hidden="true" tabindex="-1"></a>        <span class="fu">mutate</span>(<span class="at">x =</span> <span class="fu">seq_along</span>(.), <span class="at">y =</span> <span class="fu">cummean</span>(.) ) <span class="sc">%&gt;%</span></span>
<span id="cb1-6"><a href="1-introduction.html#cb1-6" aria-hidden="true" tabindex="-1"></a>        <span class="fu">ggplot</span>(<span class="fu">aes</span>(<span class="at">x =</span> x, <span class="at">y =</span> y) ) <span class="sc">+</span></span>
<span id="cb1-7"><a href="1-introduction.html#cb1-7" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_line</span>(<span class="at">lwd =</span> <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-8"><a href="1-introduction.html#cb1-8" aria-hidden="true" tabindex="-1"></a>        <span class="fu">geom_hline</span>(<span class="at">yintercept =</span> <span class="fl">0.5</span>, <span class="at">lty =</span> <span class="dv">3</span>) <span class="sc">+</span></span>
<span id="cb1-9"><a href="1-introduction.html#cb1-9" aria-hidden="true" tabindex="-1"></a>        <span class="fu">labs</span>(<span class="at">x =</span> <span class="st">&quot;Nombre de lancers&quot;</span>, <span class="at">y =</span> <span class="st">&quot;Proportion de faces&quot;</span>) <span class="sc">+</span></span>
<span id="cb1-10"><a href="1-introduction.html#cb1-10" aria-hidden="true" tabindex="-1"></a>        <span class="fu">ylim</span>(<span class="dv">0</span>, <span class="dv">1</span>) <span class="sc">+</span></span>
<span id="cb1-11"><a href="1-introduction.html#cb1-11" aria-hidden="true" tabindex="-1"></a>        <span class="fu">theme_bw</span>(<span class="at">base_size =</span> <span class="dv">12</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:frequency"></span>
<img src="IMSB_files/figure-html/frequency-1.svg" alt="Illustration de l'interprétation fréquentiste du concept de probabilité. Lorsque le nombre d'essais augmente (en abscisse), la fréquence relative (en ordonnée) converge vers la probabilité d'obtenir Face." width="75%" />
<p class="caption">
Figure 1.1: Illustration de l’interprétation fréquentiste du concept de probabilité. Lorsque le nombre d’essais augmente (en abscisse), la fréquence relative (en ordonnée) converge vers la probabilité d’obtenir Face.
</p>
</div>
<p>La Figure <a href="1-introduction.html#fig:frequency">1.1</a> illustre l’<strong>interprétation fréquentiste</strong> du concept de probabilité en montrant que la fréquence relative converge vers une fréquence donnée (la “probabilité”) quand le nombre d’essais augmente. Une conséquence importante de cette définition est que le concept de probabilité s’applique uniquement aux <strong>collectifs</strong> (i.e., aux séquences), et non aux événements singuliers. La probabilité est définie comme la limite d’une fréquence relative, et ne permet pas de parler de la probabilité d’un événement unique.</p>
<p>L’interprétation fréquentiste rencontre d’autres problèmes, comme celui de la classe de référence. Considérons par exemple la question suivante : “Quelle est la probabilité que je vive jusqu’à 80 ans ?” Pour répondre à cette question, nous avons besoin de définir la classe de référence à partir de laquelle l’individu examiné (“je”) provient. Autrement dit, je peux estimer la probabilité qu’un individu ayant mes caractéristiques vive jusqu’à 80 ans, mais il faut d’abord déterminer quelles sont les caractéristiques importantes au regard de la question posée. Selon mon sexe biologique, ma nationalité, ou mon statut socio-économique, la réponse à cette question peut varier drastiquement. L’interprétation fréquentiste ne propose pas de procédure stricte permettant de définir la classe de référence pertinente.</p>
<p>Par ailleurs, cette définition ne s’applique pas directement aux évènements qui ne peuvent pas se répéter. Par exemple, quelle est la probabilité que j’apprenne quelque chose pendant cette formation ? La réponse à cette question ne peut s’établir qu’en considérant des facteurs extérieurs à la question (e.g., le niveau de connaissance a priori), et ne peut pas reposer sur une évaluation sur le long-terme de la fréquence d’occurrence de l’événement “apprendre quelque chose” (cela n’aurait pas de sens de refaire la formation 1000 fois pour calculer le nombre de fois où on aura appris quelque chose).</p>
<!--

Une autre limite importante de l'interprétation fréquentiste est la question de la résolution (ou précision) du calcul de cette probabilité. À partir de combien de lancers (d'une pièce par exemple) a-t-on une bonne approximation de la probabilité ? On sait qu'une classe finie d’événements de taille $n$ ne peut produire que des fréquences relatives de précision $1/n$. Jusque quand devrions-nous donc continuer "d'échantillonner le long-terme" avant d'avoir une estimation précise de la probabilité ?

-->
</div>
<div id="interprétation-propensionniste" class="section level4 hasAnchor" number="1.1.2.3">
<h4><span class="header-section-number">1.1.2.3</span> Interprétation propensionniste<a href="1-introduction.html#interprétation-propensionniste" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Selon l’interprétation propensionniste du concept de probabilité, les propriétés fréquentistes (i.e., à long terme) des objets (e.g., une pièce) seraient provoquées par des <em>propriétés physiques intrinsèques</em> aux objets. Par exemple, une pièce biaisée va engendrer une fréquence relative (et donc une probabilité, selon l’interprétation fréquentiste) biaisée en raison de ses propriétés physiques. Pour les propensionnistes, les probabilités représentent ces caractéristiques intrinsèques, ces <strong>propensions</strong> à générer certaines fréquences relatives, et non les fréquences relatives en elles-mêmes.</p>
<p>Une conséquence intéressante de cette définition (et un progrès par rapport à l’interprétation fréquentiste) est que ces propriétés sont les propriétés d’événements individuels… et non de séquences ! L’interprétation propensionniste nous permet donc de parler de la probabilité d’événements uniques.</p>
</div>
<div id="interprétation-logique" class="section level4 hasAnchor" number="1.1.2.4">
<h4><span class="header-section-number">1.1.2.4</span> Interprétation logique<a href="1-introduction.html#interprétation-logique" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>L’interprétation logique du concept de probabilité, comme l’interprétation classique, postule que les probabilités peuvent être déterminées a priori en examinant les caractéristiques du système étudié (e.g., les caractéristiques de l’objet, l’ensemble des événements possibles, etc). Cependant, contrairement à l’interprétation classique, l’interprétation logique permet de rendre compte des événements non équiprobables. Cette interprétation se propose de réaliser cet objectif en généralisant la logique binaire (vrai / faux) au monde probabiliste, en étudiant le degré de support logique fourni par un ensemble de preuves pour une hypothèse donnée. Considérons par exemple l’argument logique ci-dessous.</p>
<p><strong>Prémisse n°1</strong> : Considérons une salle dans laquelle sont présents 10 étudiants</p>
<p><strong>Prémisse n°2</strong> : Neuf étudiants portent un t-shirt vert</p>
<p><strong>Prémisse n°3</strong> : Un étudiant porte un t-shirt rouge</p>
<p><strong>Prémisse n°4</strong> : Une personne est tirée au sort…</p>
<hr>

<p><strong>Conclusion n°1</strong> : L’étudiant tiré au sort porte un t-shirt</p>
<p>Cette conclusion est <em>vraie</em> et l’argument qui y est attaché est <em>valide</em>. Pour rappel, on dit qu’un argument est <em>valide</em> lorsqu’il n’existe aucune situation logiquement possible dans laquelle tous les prémisses de l’argument soient vrais et sa conclusion fausse <span class="citation">(<a href="bibliographie.html#ref-talbot_critical_2015" role="doc-biblioref">Talbot, 2015</a>)</span>. Autrement dit, si on considère les prémisses 1 à 4 comme vrais, alors il est (logiquement) impossible pour cette conclusion d’être fausse.</p>
<hr>

<p><strong>Conclusion n°2</strong> : L’étudiant tiré au sort porte un t-shirt rouge</p>
<p>Cette conclusion est <em>fausse</em> et l’argument qui y est attaché est <em>invalide.</em></p>
<hr>

<p><strong>Conclusion n°3</strong> : L’étudiant tiré au sort porte un t-shirt vert</p>
<p>Cette conclusion est également <em>fausse</em> et l’argument qui y est attaché est <em>invalide</em>. Cependant, on pourrait dire intuitivement que cette conclusion est “un peu moins fausse” que la conclusion précédente (je m’excuse en avance pour les logiciens qui me lisent), dans le sens où elle est “plus fortement” impliquée par les prémisses 1 à 4 que la conclusion n°2.</p>
<p>Bien que les règles de la logique formelle n’autorisent pas des conclusions à être “plus ou moins vraies”, l’interprétation logique du concept de probabilité cherche justement à étendre les règles de la logique aux événements continus, et se propose d’utiliser le langage des probabilités dans ce but. Autrement dit, la probabilité représente donc le <strong>degré de support logique</strong> qu’une conclusion peut avoir, relativement à un ensemble de prémices <span class="citation">(<a href="bibliographie.html#ref-carnap_logical_1950" role="doc-biblioref">Carnap, 1950</a>; <a href="bibliographie.html#ref-keynes_treatise_1921" role="doc-biblioref">Keynes, 1921</a>)</span>.</p>
<p>Une conséquence intéressante de cette interprétation est que toute probabilité est <strong>conditionnelle</strong>, que ce soit à de l’information a priori ou, par exemple, à un ensemble de prémisses.</p>
</div>
<div id="interprétation-bayésienne" class="section level4 hasAnchor" number="1.1.2.5">
<h4><span class="header-section-number">1.1.2.5</span> Interprétation bayésienne<a href="1-introduction.html#interprétation-bayésienne" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Selon l’interprétation bayésienne (subjective), la probabilité est <strong>une mesure du degré de croyance</strong> (ou “crédence”) ou d’<em>incertitude</em>. Un événement <em>certain</em> aura donc une probabilité de 1 et un évènement <strong>impossible</strong> aura une probabilité de 0.</p>
<blockquote>
<p>So to assign equal probabilities to two events is not in any way an assertion that they must occur equally often in any “random experiment”; as Jeffrey emphasized, it is only a formal way of saying “I don’t know” <span class="citation">(<a href="bibliographie.html#ref-jaynes_bayesian_1986" role="doc-biblioref">Jaynes, 1986</a>)</span>.</p>
</blockquote>
<p>Pour parler de probabilités, dans ce cadre, nous n’avons donc plus besoin de nous référer à la limite d’occurrence d’un évènement (à sa fréquence). La probabilité est un concept abstrait faisant référence à un état de connaissance et / ou permettant de quantifier l’incertitude liée à cet état de connaissance.</p>
</div>
<div id="interprétations-probabilistes---résumé" class="section level4 hasAnchor" number="1.1.2.6">
<h4><span class="header-section-number">1.1.2.6</span> Interprétations probabilistes - résumé<a href="1-introduction.html#interprétations-probabilistes---résumé" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Pour résumer, les différentes interprétations discutées ci-dessus peuvent être classées dans deux grandes catégories :</p>
<blockquote>
<p><strong>Interprétation épistémique</strong> : toute probabilité est conditionnelle à de l’information disponible (e.g., prémisses ou données). La probabilité est utilisée comme moyen de quantifier l’incertitude.</p>
<p>Interprétation logique (e.g., Keynes, Carnap), interprétation bayésienne (e.g., Jeffreys, de Finetti, Savage).</p>
</blockquote>
<blockquote>
<p><strong>Interprétation physique</strong> : les probabilités dépendent d’un état du monde, de caractéristiques physiques, elles sont indépendantes de l’information disponible (ou de l’incertitude).</p>
<p>Interprétation classique (e.g., Laplace, Bernouilli, Leibniz), interprétation fréquentiste (e.g., Venn, Reichenbach, von Mises).</p>
</blockquote>
<p>Les plus curieux d’entre vous seront ravis de trouver plus d’informations dans cet excellent article de la <em>Stanford Encyclopedia of Philosophy</em> <span class="citation">(<a href="bibliographie.html#ref-sep-probability-interpret" role="doc-biblioref">Hájek, 2019</a>)</span> sur les différentes interprétations du concept de probabilité.</p>
</div>
</div>
</div>
<div id="rappels-de-théorie-des-probabilités" class="section level2 hasAnchor" number="1.2">
<h2><span class="header-section-number">1.2</span> Rappels de théorie des probabilités<a href="1-introduction.html#rappels-de-théorie-des-probabilités" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Pour rappel, une probabilité est donc une valeur numérique comprise entre 0 et 1 et qui respecte la règle de la somme. Ces valeurs sont assignées à des <em>évènements</em> <span class="math inline">\(\omega\)</span>, étant définis comme des sous-ensembles d’un grand <em>ensemble</em> <span class="math inline">\(\Omega\)</span>. Chaque évènement de cet ensemble peut se voir assigner une probabilité qui représente notre in(certitude) vis à vis de sa survenue. Ces probabilités sont assignées par des <em>fonctions de probabilité</em> qui, à chaque élément <span class="math inline">\(\omega \in \Omega\)</span>, associe ou attribue une probabilité <span class="citation">(<a href="bibliographie.html#ref-blitzstein_introduction_2019" role="doc-biblioref">Blitzstein &amp; Hwang, 2019</a>; <a href="bibliographie.html#ref-dekking_modern_2005" role="doc-biblioref">Dekking, 2005</a>; <a href="bibliographie.html#ref-noel_psychologie_2015" role="doc-biblioref">Noël, 2015</a>)</span>.</p>
<p>Comme illustration, considérons l’exemple suivant. En postulant qu’il est impossible qu’une pièce lancée retombe sur sa tranche, un lancer de pièce peut seulement résulter en deux issues : Pile ou Face. Autrement dit, l’ensemble des issues possibles est défini comme <span class="math inline">\(\Omega = \{\text{Pile}, \ \text{Face}\}\)</span>. Étant donné qu’un <em>évènement</em> est défini comme un sous-ensemble de <span class="math inline">\(\Omega\)</span>, Pile et Face sont donc deux évènements possibles.</p>
<div class="definition">
<p><span id="def:prob-function" class="definition"><strong>Définition 1.1  (Fonction de probabilité) </strong></span>Une fonction de probabilité <span class="math inline">\(p\)</span> définie sur un ensemble fini <span class="math inline">\(\Omega\)</span> assigne à chaque événement <span class="math inline">\(A\)</span> dans <span class="math inline">\(\Omega\)</span> une valeur <span class="math inline">\(\Pr(A) \in [0, 1]\)</span> de manière à ce que :</p>
<ul>
<li><span class="math inline">\(\Pr(\Omega) = 1\)</span> et</li>
<li><span class="math inline">\(\Pr(A \cup B) = \Pr(A) + \Pr(B)\)</span> si <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span> sont disjoints.</li>
</ul>
<p>La valeur <span class="math inline">\(\Pr(A)\)</span> représente la <em>probabilité</em> que <span class="math inline">\(A\)</span> se réalise.</p>
</div>
<p>Dans l’exemple d’un lancer de pièce, si la pièce n’est pas truquée, alors <span class="math inline">\(\Pr(\text{Pile}) = \Pr(\text{Face}) = \frac{1}{2}\)</span>…</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:venn"></span>
<img src="figures/venn.png" alt="Diagrammes représentant les notions d'intersection, d'union, et de complément." width="100%" />
<p class="caption">
Figure 1.2: Diagrammes représentant les notions d’intersection, d’union, et de complément.
</p>
</div>
<p>…</p>
<div id="probabilité-conjointe" class="section level3 hasAnchor" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Probabilité conjointe<a href="1-introduction.html#probabilité-conjointe" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>La probabilité conjointe <span class="math inline">\(\Pr(A, B)\)</span> nous indique la probabilité qu’à la fois <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span> se réalisent, c’est à dire la probabilité de l’union de <span class="math inline">\(A\)</span> et <span class="math inline">\(B\)</span>, qu’on note également <span class="math inline">\(\Pr(A \cap B)\)</span>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="1-introduction.html#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span>
<span id="cb2-2"><a href="1-introduction.html#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="1-introduction.html#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(HairEyeColor) <span class="co"># données adaptés de Snee (1974)</span></span>
<span id="cb2-4"><a href="1-introduction.html#cb2-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-5"><a href="1-introduction.html#cb2-5" aria-hidden="true" tabindex="-1"></a>cont <span class="ot">&lt;-</span> <span class="fu">apply</span>(HairEyeColor, <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), sum) <span class="sc">%&gt;%</span> t </span>
<span id="cb2-6"><a href="1-introduction.html#cb2-6" aria-hidden="true" tabindex="-1"></a>cont <span class="ot">&lt;-</span> <span class="fu">round</span>(cont <span class="sc">/</span> <span class="fu">sum</span>(cont), <span class="dv">2</span>)</span>
<span id="cb2-7"><a href="1-introduction.html#cb2-7" aria-hidden="true" tabindex="-1"></a>cont</span></code></pre></div>
<pre><code>##        Hair
## Eye     Black Brown  Red Blond
##   Brown  0.11  0.20 0.04  0.01
##   Blue   0.03  0.14 0.03  0.16
##   Hazel  0.03  0.09 0.02  0.02
##   Green  0.01  0.05 0.02  0.03</code></pre>
<p>Dans chaque cellule du tableau de données ci-dessus, on trouve la <strong>probabilité conjointe</strong> d’avoir telle couleur de cheveux <strong>ET</strong> telle couleur d’yeux, qui s’écrit <span class="math inline">\(\Pr(c, y) = \Pr(y, c)\)</span>.</p>
</div>
<div id="probabilité-marginale" class="section level3 hasAnchor" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Probabilité marginale<a href="1-introduction.html#probabilité-marginale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="1-introduction.html#cb4-1" aria-hidden="true" tabindex="-1"></a>cont2 <span class="ot">&lt;-</span> cont <span class="sc">%&gt;%</span> as.data.frame <span class="sc">%&gt;%</span> <span class="fu">mutate</span>(<span class="at">marginal_eye =</span> <span class="fu">rowSums</span>(cont) )</span>
<span id="cb4-2"><a href="1-introduction.html#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(cont2) <span class="ot">&lt;-</span> <span class="fu">row.names</span>(cont)</span>
<span id="cb4-3"><a href="1-introduction.html#cb4-3" aria-hidden="true" tabindex="-1"></a>cont2</span></code></pre></div>
<pre><code>##       Black Brown  Red Blond marginal_eye
## Brown  0.11  0.20 0.04  0.01         0.36
## Blue   0.03  0.14 0.03  0.16         0.36
## Hazel  0.03  0.09 0.02  0.02         0.16
## Green  0.01  0.05 0.02  0.03         0.11</code></pre>
<p>On peut aussi s’intéresser à la probabilité d’avoir des yeux bleus, de manière générale. Il s’agit de la probabilité <strong>marginale</strong> de l’évènement <em>yeux bleus</em>, qui s’obtient par la somme de toutes les probabilités jointes impliquant l’évènement <em>yeux bleus</em>. Elle s’écrit <span class="math inline">\(\Pr(y)\)</span>.</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="1-introduction.html#cb6-1" aria-hidden="true" tabindex="-1"></a>cont3 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(cont2, <span class="fu">colSums</span>(cont2) )</span>
<span id="cb6-2"><a href="1-introduction.html#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(cont3) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fu">row.names</span>(cont2), <span class="st">&quot;marginal_hair&quot;</span>)</span>
<span id="cb6-3"><a href="1-introduction.html#cb6-3" aria-hidden="true" tabindex="-1"></a>cont3</span></code></pre></div>
<pre><code>##               Black Brown  Red Blond marginal_eye
## Brown          0.11  0.20 0.04  0.01         0.36
## Blue           0.03  0.14 0.03  0.16         0.36
## Hazel          0.03  0.09 0.02  0.02         0.16
## Green          0.01  0.05 0.02  0.03         0.11
## marginal_hair  0.18  0.48 0.11  0.22         0.99</code></pre>
<p>On peut bien entendu aussi s’intéresser aux probabilités des couleurs de cheveux, de manière générale. Elle s’écrit <span class="math inline">\(\Pr(c)\)</span>.</p>
</div>
<div id="probabilité-conditionnelle" class="section level3 hasAnchor" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Probabilité conditionnelle<a href="1-introduction.html#probabilité-conditionnelle" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>On pourrait aussi s’intéresser à la probabilité qu’une personne ait les cheveux blonds, <strong>sachant</strong> qu’elle a les yeux bleus. Il s’agit d’une probabilité <strong>conditionnelle</strong>, et s’écrit <span class="math inline">\(p(c|y)\)</span>. Cette probabilité conditionnelle peut se ré-écrire: <span class="math inline">\(p(c|y)= \frac{p(c,y)}{p(y)}\)</span>.</p>
<pre><code>##      Black Brown  Red Blond marginal_eye
## Blue  0.03  0.14 0.03  0.16         0.36</code></pre>
<p>Par exemple, quelle est la probabilité d’avoir des yeux bleus lorsqu’on a les cheveux blonds ?</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="1-introduction.html#cb9-1" aria-hidden="true" tabindex="-1"></a>cont3[<span class="st">&quot;Blue&quot;</span>, <span class="st">&quot;Blond&quot;</span>] <span class="sc">/</span> cont3[<span class="st">&quot;Blue&quot;</span>, <span class="st">&quot;marginal_eye&quot;</span>]  </span></code></pre></div>
<pre><code>##      Blue 
## 0.4444444</code></pre>
<p>On remarque dans le cas précédent que <span class="math inline">\(p(blonds|bleus)\)</span> <strong>n’est pas nécessairement égal</strong> à <span class="math inline">\(p(bleus|blonds)\)</span>.</p>
<p>Autre exemple: la probabilité de mourir sachant qu’on a été attaqué par un requin n’est pas la même que la probabilité d’avoir été attaqué par un requin, sachant qu’on est mort (<a href="https://en.wikipedia.org/wiki/Confusion_of_the_inverse"><em>confusion of the inverse</em></a>). De la même manière, <span class="math inline">\(p(data|H_{0}) \neq p(H_{0}|data)\)</span>.</p>
<p>À partir des axiomes de Kolmogorov (cf. début du cours), et des définitions précédentes des probabilités conjointes, marginales, et conditionnelles, découle la <strong>règle du produit</strong> (en multipliant chaque côté par <span class="math inline">\(p(y)\)</span>) :</p>
<p><span class="math display">\[p(a, b) = p(b) \cdot p(a|b) = p(a) \cdot p(b|a)\]</span></p>
<p>…</p>
</div>
<div id="dérivation-du-théorème-de-bayes" class="section level3 hasAnchor" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Dérivation du théorème de Bayes<a href="1-introduction.html#dérivation-du-théorème-de-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><span class="math display">\[p(x, y) = p(x|y) p(y) = p(y|x)p(x)\]</span></p>
<p><span class="math display">\[p(y|x)p(x) = p(x|y)p(y)\]</span></p>
<p><span class="math display">\[p(y|x) = \dfrac{p(x|y)p(y)}{p(x)}\]</span></p>
<p><span class="math display">\[p(x|y) = \dfrac{p(y|x)p(x)}{p(y)}\]</span></p>
<p>On retrouve le résultat présenté dans la section précédente, en remplaçant <span class="math inline">\(x\)</span> par <em>données</em> et <span class="math inline">\(y\)</span> par <em>hypothèse</em> :</p>
<p><span class="math display">\[
\Pr(\text{hypothèse} \ | \ \text{données}) = \frac{\Pr(\text{données} \ | \ \text{hypothèse}) \times \Pr(\text{hypothèse})}{\text{Somme des produits}}
\]</span></p>
<p>…</p>
</div>
<div id="loi-de-probabilité-cas-discret" class="section level3 hasAnchor" number="1.2.5">
<h3><span class="header-section-number">1.2.5</span> Loi de probabilité, cas discret<a href="1-introduction.html#loi-de-probabilité-cas-discret" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>…</p>
<div class="definition">
<p><span id="def:PMF" class="definition"><strong>Définition 1.2  (Fonction de masse de probabilité) </strong></span>La fonction de masse de probabilité <span class="math inline">\(p\)</span> d’une variable aléatoire <span class="math inline">\(X\)</span> is la fonction <span class="math inline">\(p : \mathbb{R} \rightarrow [0, 1]\)</span>, définie par :</p>
<p><span class="math display">\[p(a) = \Pr(X = a) \quad \text{for} - \infty &lt; a &lt; \infty\]</span></p>
</div>
<p>Une fonction de masse (<em>probability mass function</em>, ou <em>PMF</em>) est une fonction qui attribue une probabilité à chaque valeur d’une variable aléatoire. Exemple de la distribution binomiale pour une pièce non biaisée (<span class="math inline">\(\theta = 0.5\)</span>), indiquant la probabilité d’obtenir <span class="math inline">\(N\)</span> faces sur 10 lancers.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:binomial-barplot"></span>
<img src="IMSB_files/figure-html/binomial-barplot-1.svg" alt="Distribution de la probabilité d'obtenir N 'Face' sur 10 lancers de pièce." width="50%" />
<p class="caption">
Figure 1.3: Distribution de la probabilité d’obtenir N ‘Face’ sur 10 lancers de pièce.
</p>
</div>
<p>Somme à 1…</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="1-introduction.html#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PMFs sum to 1</span></span>
<span id="cb11-2"><a href="1-introduction.html#cb11-2" aria-hidden="true" tabindex="-1"></a><span class="fu">dbinom</span>(<span class="at">x =</span> <span class="dv">0</span><span class="sc">:</span><span class="dv">10</span>, <span class="at">size =</span> <span class="dv">10</span>, <span class="at">prob =</span> <span class="fl">0.5</span>) <span class="sc">%&gt;%</span> sum</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
</div>
<div id="loi-de-probabilité-cas-continu" class="section level3 hasAnchor" number="1.2.6">
<h3><span class="header-section-number">1.2.6</span> Loi de probabilité, cas continu<a href="1-introduction.html#loi-de-probabilité-cas-continu" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="definition">
<p><span id="def:PDF" class="definition"><strong>Définition 1.3  (Fonction de densité de probabilité) </strong></span>Une variable aléatoire <span class="math inline">\(X\)</span> est dite <em>continue</em> si pour une fonction donnée <span class="math inline">\(p : \mathbb{R} \rightarrow \mathbb{R}\)</span> et pour tout nombres <span class="math inline">\(a\)</span> et <span class="math inline">\(b\)</span> avec <span class="math inline">\(a \leq b\)</span>,</p>
<p><span class="math display">\[\Pr(a \leq X \leq b) = \int_{a}^{b} p(x) \mathrm{d} x\]</span></p>
<p>La fonction <span class="math inline">\(p\)</span> doit satisfaire la condition <span class="math inline">\(p(x) \geq 0\)</span> pour tout <span class="math inline">\(x\)</span> et <span class="math inline">\(\int_{-\infty}^{\infty} p(x) \mathrm{d} x = 1\)</span>. On appelle <span class="math inline">\(p\)</span> la fonction de densité de probabilité (ou densité de probabilité) de <span class="math inline">\(X\)</span>.</p>
</div>
<p>Une fonction de densité de probabilité (<em>probability density function</em>, ou <em>PDF</em>), est une fonction qui permet de représenter une loi de probabilité sous forme d’intégrales (l’équivalent de la PMF pour des variables aléatoires strictement continues).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:pdf-plot"></span>
<img src="IMSB_files/figure-html/pdf-plot-1.svg" alt="Blah blah..." width="50%" />
<p class="caption">
Figure 1.4: Blah blah…
</p>
</div>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="1-introduction.html#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="co"># PDFs integrate to 1</span></span>
<span id="cb13-2"><a href="1-introduction.html#cb13-2" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(dnorm, <span class="sc">-</span><span class="cn">Inf</span>, <span class="cn">Inf</span>, <span class="at">mean =</span> <span class="dv">100</span>, <span class="at">sd =</span> <span class="dv">15</span>)</span></code></pre></div>
<pre><code>## 1 with absolute error &lt; 1.3e-06</code></pre>
<p>…</p>
<div id="KC1.1" class="keyconcept">
<h3 class="right">
Concept essentiel 1.1
</h3>
<h3 class="left">
Variable aléatoire continue
</h3>
<p>
Une variable aléatoire continue peut prendre (littéralement) une infinité de valeurs. On se retrouve donc face un problème. Si on attribue une probabilité non-nulle à chacune de ces valeurs (à une infinité de valeurs donc), la somme des probabilités de ces valeurs sera elle aussi infinie, et cette fonction ne pourra donc pas être considérée comme une fonction de probabilité. Pour pallier à ce problème, chaque valeur ponctuelle d’une variable aléatoire est assignée une probabilité nulle (i.e., <span class="math inline">\(\Pr(X = x) = 0\)</span>) et uniquement des intervalles (e.g., <span class="math inline">\(\Pr(a &lt; x &lt; b)\)</span>) peuvent se voir attribuer une probabilité.
</p>
</div>
<p>…</p>
</div>
<div id="aparté-quest-ce-quune-intégrale" class="section level3 hasAnchor" number="1.2.7">
<h3><span class="header-section-number">1.2.7</span> Aparté, qu’est-ce qu’une intégrale ?<a href="1-introduction.html#aparté-quest-ce-quune-intégrale" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Une intégrale correspond à la <strong>surface</strong> (aire géométrique) délimitée par la représentation graphique d’une fonction, <em>l’aire sous la courbe</em>. Une distribution est dite <strong>impropre</strong> si son intégrale n’est pas égale à un nombre fini (e.g., <span class="math inline">\(+ \infty\)</span>) et <strong>normalisée</strong> si son intégrale est égale à 1.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:integral"></span>
<img src="IMSB_files/figure-html/integral-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 1.5: Blah blah…
</p>
</div>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:integral-qi"></span>
<img src="IMSB_files/figure-html/integral-qi-1.svg" alt="Blah blah..." width="75%" />
<p class="caption">
Figure 1.6: Blah blah…
</p>
</div>
<p>L’intégrale de <span class="math inline">\(f(x)\)</span> sur l’intervalle [90 ; 96] vaut: <span class="math inline">\(p(90 &lt; x &lt; 96) = \int_{90}^{96} f(x) \ \mathrm{d}x = 0.142\)</span>.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="1-introduction.html#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">integrate</span>(dnorm, <span class="dv">90</span>, <span class="dv">96</span>, <span class="at">mean =</span> <span class="dv">100</span>, <span class="at">sd =</span> <span class="dv">15</span>)</span></code></pre></div>
<pre><code>## 0.1423704 with absolute error &lt; 1.6e-15</code></pre>
</div>
<div id="notations-terminologie" class="section level3 hasAnchor" number="1.2.8">
<h3><span class="header-section-number">1.2.8</span> Notations, terminologie<a href="1-introduction.html#notations-terminologie" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Ayant introduit de manière intuitive les concepts centraux de l’inférence bayésienne (en particulier, la mise à jour d’un connaissance a posteriori en une connaissance a posteriori) nous allons maintenant établit la terminologie qui nous accompagner au fil de ce livre.</p>
<ul>
<li><p><span class="math inline">\(\theta\)</span> désigne habituellement un paramètre ou un vecteur de paramètres (e.g., la proportion de billes bleues)</p></li>
<li><p><span class="math inline">\(\color{orangered}{p(x\vert \theta)}\)</span> <span style="color:orangered"> désigne la probabilité conditionnelle des données <span class="math inline">\(x\)</span> sachant le paramètre <span class="math inline">\(\theta\)</span> </span> <span class="math inline">\(\color{orangered}{[p(x | \theta = \theta)]}\)</span></p></li>
<li><p><span class="math inline">\(\color{orangered}{p(x\vert \theta)}\)</span> <span style="color:orangered"> une fois que la valeur de <span class="math inline">\(x\)</span> est connue, est vue comme la fonction de vraisemblance (<em>likelihood</em>) du paramètre <span class="math inline">\(\theta\)</span>. Attention, il ne s’agit pas d’une distribution de probabilité (n’intègre pas à 1). </span> <span class="math inline">\(\color{orangered}{[p(x = x | \theta)]}\)</span></p></li>
<li><p><span class="math inline">\(\color{steelblue}{p(\theta)}\)</span> <span style="color:steelblue"> la probabilité a priori de <span class="math inline">\(\theta\)</span></span></p></li>
<li><p><span class="math inline">\(\color{purple}{p(\theta \vert x)}\)</span> <span style="color:purple"> la probabilité a posteriori de <span class="math inline">\(\theta\)</span> (sachant <span class="math inline">\(x\)</span>)</span></p></li>
<li><p><span class="math inline">\(\color{green}{p(x)}\)</span> <span style="color:green"> la probabilité marginale de <span class="math inline">\(x\)</span> (sur <span class="math inline">\(\theta\)</span>)</span></p></li>
</ul>
<p><br></p>
<p><span class="math display">\[
\color{purple}{p(\theta \vert x)} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{p(x)}} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{\sum\limits_{\theta}p(x|\theta)p(\theta)}} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{\int\limits_{\theta}p(x|\theta)p(\theta)\mathrm{d}x}} \propto \color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}
\]</span></p>
<p>…</p>
<div id="KC1.1" class="keyconcept">
<h3 class="right">
Concept essentiel 1.1
</h3>
<h3 class="left">
La théorie des probabilités comme extension de la logique
</h3>
<p>
<p>La théorie des probabilités est parfois présentée comme une extension de la logique. En effet, elle généralise les règles de la logique qui s’appliquent à des événements discrets (vrais ou faux) à des événements continus. Ce faisant, les probabilités nous permettent de décrire et quantifier l’incertitude. Il est important de souligner que les règles du calcul probabiliste ont le même statut que les règles logiques : ces règles de base peuvent être utilisées pour déduire des conclusions qui seront garanties d’être correctes, si les prémises sont corrects.</p>
Dans ce cadre, l’analyse statistique bayésienne peut être conceptualisée comme une application de la théorie des probabilités à l’analyse statistique. Bien que la dépendance des conclusions de ce genre d’analyse aux a priori qu’elles rendent explicitent est souvent présenté comme une faiblesse, c’est précisémment ce qui les rend “optimales” ou “cohérentes” (au sens où elles respectent les règles du calcul probabiliste). Comme résumé par Vandekerckhove (2018), conclure que les analyses bayésiennes seraient invalidées par l’utilisation d’informations a priori serait similaire à conclure que des déductions logiques seraient invalidées par la considération de prémisses.
</p>
</div>
</div>
</div>
<div id="logique-et-raisonnement-scientifique" class="section level2 hasAnchor" number="1.3">
<h2><span class="header-section-number">1.3</span> Logique et raisonnement scientifique<a href="1-introduction.html#logique-et-raisonnement-scientifique" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="introduction-à-la-logique" class="section level3 hasAnchor" number="1.3.1">
<h3><span class="header-section-number">1.3.1</span> Introduction à la logique<a href="1-introduction.html#introduction-à-la-logique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le but de cette section est de proposer une courte (et très incomplète) introduction à la logique, afin de pouvoir analyser dans une section ultérieure l’argument central de l’inférence fréquentiste et d’illustrer les similarités entre la logique et le fonctionnement de l’inférence bayésienne. Commençons tout d’abord par définir les termes utilisés <span class="citation">(cf. <a href="bibliographie.html#ref-talbot_critical_2015" role="doc-biblioref">Talbot, 2015</a>)</span>.</p>
<div class="definition">
<p><span id="def:argument" class="definition"><strong>Définition 1.4  </strong></span>Un <em>argument</em> est un ensemble de propositions dans lequel une proposition est affirmée sur la base d’autres propositions.</p>
</div>
<p>Un argument (du moins tel que défini ici) est donc composé de différentes propositions. Parmi ces propositions, certaines vont être utilisées pour affirmer une autre proposition.</p>
<div class="definition">
<p><span id="def:concusion" class="definition"><strong>Définition 1.5  </strong></span>La <em>conclusion</em> est l’affirmation faite sur la base d’autres propositions.</p>
</div>
<div class="definition">
<p><span id="def:prémisse" class="definition"><strong>Définition 1.6  </strong></span>Les <em>prémisses</em> d’un argument sont les raisons offertes qui permettent d’affirmer la conclusion.</p>
</div>
<p>Pour résumer, un <em>argument</em> est un ensemble de propositions, parmi lesquelles des <em>prémisses</em> sont utilisées pour affirmer une <em>conclusion</em>. Les propositions qui composent un <em>argument</em> (i.e., les prémisses et la conclusion) peuvent être <em>vraies</em> ou <em>fausses</em> mais l’argument ne peut pas être <em>vrai</em> ou <em>faux</em>. Un argument est seulement <em>valide</em> ou <em>invalide</em>.</p>
<div class="definition">
<p><span id="def:valide" class="definition"><strong>Définition 1.7  </strong></span>Un argument est dit <em>valide</em> si et seulement si il n’existe aucune situation logiquement possible dans laquelle tous les prémisses de l’argument soient vrais et sa conclusion fausse.</p>
</div>
<div class="definition">
<p><span id="def:invalide" class="definition"><strong>Définition 1.8  </strong></span>Un argument est dit <em>invalide</em> si et seulement si il existe aucune situation logiquement possible dans laquelle tous les prémisses de l’argument soient vrais et sa conclusion fausse.</p>
</div>
<p>Pour résumer, un argument est un ensemble de <em>propositions</em>, dont certaines d’entre elles (les prémisses) sont utilisées pour affirmer (ou justifier) une autre (la conclusion). Ces propositions peuvent être vraies ou fausses mais un argument peut seulement être <em>valide</em> ou <em>invalide</em>. Un argument est dit <em>valide</em> lorsqu’il est logiquement <em>impossible</em> pour la conclusion d’être fausse (sachant que les prémisses sont <em>vraies</em>).</p>
</div>
<div id="quelques-syllogismes-connus" class="section level3 hasAnchor" number="1.3.2">
<h3><span class="header-section-number">1.3.2</span> Quelques syllogismes connus<a href="1-introduction.html#quelques-syllogismes-connus" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:penguin"></span>
<img src="figures/penguin.png" alt="Un pingouin s'essayant à la logique. Source : https://www.pinterest.com/pin/465418942711158498/." width="50%" />
<p class="caption">
Figure 1.7: Un pingouin s’essayant à la logique. Source : <a href="https://www.pinterest.com/pin/465418942711158498/" class="uri">https://www.pinterest.com/pin/465418942711158498/</a>.
</p>
</div>
<p>Un syllogisme est un raisonnement logique qui met en relation <em>au moins</em> trois propositions : au moins deux prémisses et une conclusion. Afin d’illustrer les définitions proposées ci-dessus, nous allons maintenant examiner quelques exemples. Savez-vous reconnaître les arguments valides et invalides ?</p>
<p><strong>Argument n°1</strong></p>
<ul>
<li>Prémisse n°1 : Si un suspect ment, il transpire.</li>
<li>Prémisse n°2 : (On observe que) Ce suspect transpire.</li>
<li>Conclusion : Par conséquent, ce suspect ment.</li>
</ul>
<p>Cet argument est <em>invalide</em> car (on applique la définition <a href="1-introduction.html#def:valide">1.7</a>) il existe des situations dans lesquelles à la fois les prémisses 1 et 2 sont vraies, et pourtant la conclusion est fausse. Par exemple, il se peut que le suspect transpire pour d’autres raisons que le mensonge (e.g., la température de la salle d’interrogatoire).</p>
<p><strong>Argument n°2</strong></p>
<ul>
<li>Prémisse n°1 : Si un suspect transpire, il ment.</li>
<li>Prémisse n°2 : (On observe que) Ce suspect ne transpire pas.</li>
<li>Conclusion : Par conséquent, ce suspect ne ment pas.</li>
</ul>
<p>Cet argument est également <em>invalide</em> car il existe des situations dans lesquelles à la fois les prémisses 1 et 2 sont vraies, et pourtant la conclusion est fausse. Par exemple, il se peut que le suspect fasse partie des gens qui ne transpirent pas lorsqu’ils mentent.</p>
<p><strong>Argument n°3</strong></p>
<ul>
<li>Prémisse n°1 : Tous les menteurs transpirent.</li>
<li>Prémisse n°2 : (On observe que) Ce suspect ne transpire pas.</li>
<li>Conclusion : Par conséquent, ce suspect n’est pas un menteur.</li>
</ul>
<p>Cet argument est <em>valide</em> car il n’existe aucune situation dans laquelle à la fois les prémisses 1 et 2 sont vraies et la conclusion serait fausse. Autrement dit, si les prémisses 1 et 2 sont vraies, il est <em>logiquement impossible</em> pour la conclusion d’être fausse. Nous allons maintenant examiner quelques raisonnements valides et invalides connus afin de nous aider à les repérer plus facilement.</p>
<div id="arguments-invalides" class="section level4 hasAnchor" number="1.3.2.1">
<h4><span class="header-section-number">1.3.2.1</span> Arguments invalides<a href="1-introduction.html#arguments-invalides" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Le premier raisonnement fallacieux que nous allons étudier est connu comme le sophisme de l’<strong>affirmation du conséquent</strong>. Ce raisonnement vise à inférer la réalisation d’un <em>antécédent</em> sur la base de la réalisation du <em>conséquent.</em> Considérons l’exemple suivant :</p>
<ul>
<li>Prémisse n°1 : S’il a plu, alors le sol est mouillé (A implique B).</li>
<li>Prémisse n°2 : Le sol est mouillé (B).</li>
<li>Conclusion : Donc il a plu (A).</li>
</ul>
<p>Dans cet argument, le prémisse n°1 nous dit que l’antécédent (A) implique le conséquent (B). Le prémisse n°2 <em>affirme</em> le conséquent B. La conclusion consiste à affirmer l’antécédent A sur la base de ces deux prémisse. Or cet argument est invalide, car (en l’occurrence) le sol pourrait être mouillé pour d’autres raisons que la pluie. Il s’agit du même genre de raisonnement que l’argument n°1 discuté dans la section précédente et il peut s’écrire dans une forme générale de la manière suivante :</p>
<p><span class="math display">\[\dfrac{A \Rightarrow B, \ B}{A}\]</span></p>
<p>où <span class="math inline">\(A \Rightarrow B\)</span> se lit “A implique B” et se comprend comme dans la phrase “Si A, alors B”.</p>
<p>Un deuxième argument fallacieux relativement répandu est connu comme le sophisme de la <strong>négation de l’antécédent</strong> et consiste à affirmer une négation du conséquent (i.e., non B) sur la base d’une négation de l’antécédent (i.e., non A). Considérons l’exemple suivant :</p>
<ul>
<li>Prémisse n°1 : S’il a plu, alors le sol est mouillé (A implique B).</li>
<li>Prémisse n°2 : Il n’a pas plu (non A).</li>
<li>Conclusion : Donc le sol n’est pas mouillé (non B).</li>
</ul>
<p>Dans cet exemple comme dans le précédent, le prémisse n°1 nous dit que l’antécédent (A) implique le conséquent (B). Le prémisse n°2 affirme une négation de l’antécédent (i.e., non A ou <span class="math inline">\(\neg A\)</span>). La conclusion consiste à affirmer une négation du conséquence (i.e., <span class="math inline">\(\neg B\)</span>) sur la base de ces deux prémisses. Cet argument est également invalide car (en l’occurrence) le sol pourrait être mouillé pour d’autres raisons que le pluie. Autrement dit :</p>
<p><span class="math display">\[\dfrac{A \Rightarrow B, \ \neg A}{\neg B}\]</span></p>
<p>où <span class="math inline">\(\neg A\)</span> représente la négation de A (i.e., non A).</p>
</div>
<div id="arguments-valides" class="section level4 hasAnchor" number="1.3.2.2">
<h4><span class="header-section-number">1.3.2.2</span> Arguments valides<a href="1-introduction.html#arguments-valides" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Attardons nous maintenons sur deux des raisonnements valides les plus connus. Le premier est connu comme le <strong>modus ponens</strong> et consiste à déduire un conséquent sur la base d’une implication (e.g., A implique B) et de l’affirmation d’un antécédent. Considérons l’exemple suivant :</p>
<ul>
<li>Prémisse n°1 : Si on est lundi, alors John ira au travail (A implique B).</li>
<li>Prémisse n°2 : On est lundi (A).</li>
<li>Conclusion : Donc John ira au travail (B).</li>
</ul>
<p>Comme dans les deux exemples précédents, le prémisse n°1 nous dit que l’antécédent (A) implique le conséquent (B). Le prémisse n°2 <em>affirme</em> l’antécédent A. La conclusion consiste à affirmer le conséquent B sur la base de ces deux prémisse. Cet argument est <em>valide</em> (cf. définition <a href="1-introduction.html#def:valide">1.7</a>) car il n’existe aucune situation <em>logiquement possible</em> dans laquelle les deux prémisses serait vrais et la conclusion fausse. Autrement dit, cet argument est valide car il est <em>impossible</em> pour la conclusion d’être fausse, sachant que les prémisses sont vrais. Le modus ponens peut s’écrire de la manière suivante :</p>
<p><span class="math display">\[\dfrac{A \Rightarrow B, \ A}{B} \cdot\]</span></p>
<p>Le deuxième argument valide que nous allons discuter est connu comme le <strong>modus tollens</strong>, dont l’importance s’avère capitale dans le raisonnement scientifique, ou du moins dans sa version idéalisée (cf. section suivante). Cet argument consiste à déduire la négation de l’antécédent sur la base d’une implication et de la négation du conséquent. Considérons l’exemple suivant :</p>
<ul>
<li>Prémisse n°1 : Si mon chien détecte un intrus, alors il aboie (A implique B).</li>
<li>Prémisse n°2 : Mon chien n’a pas aboyé (non B).</li>
<li>Conclusion : Donc il n’a pas détecté d’intrus (non A).</li>
</ul>
<p>Comme dans les exemples précédents, le prémisse n°1 nous dit que l’antécédent (A) implique le conséquent (B). Le prémisse n°2 affirme la ngation du conséquent (i.e., non B). La conclusion consiste à affirmer la négation de l’antécédent (i.e., non A) sur la base de ces deux prémisses. Cet argument est <em>valide</em> (cf. définition <a href="1-introduction.html#def:valide">1.7</a>) car il n’existe aucune situation <em>logiquement possible</em> dans laquelle les deux prémisses serait vrais et la conclusion fausse. Autrement dit, cet argument est valide car il est <em>impossible</em> pour la conclusion d’être fausse, sachant que les prémisses sont vrais. Dans notre exemple, si le chien n’a pas aboyé, c’est <em>nécessairement</em> qu’il n’a pas détecté d’intrus. Cependant, cela ne veut pas dire qu’aucun intrus a visité notre maison, seulement que le chien n’a pas détecté d’intrus. Le modus tollens peut s’écrire de la manière suivante :</p>
<p><span class="math display">\[\dfrac{A \Rightarrow B, \ \neg B}{\neg A}\]</span></p>
<p>Ayant défini ce qu’est un argument, ce qui le compose et ce qui fait sa validité, nous disposons maintenant des outils nécessaires afin d’étudier la “logique” du raisonnement scientifique, et d’essayer de voir la place occupée par l’analyse de données dans ce raisonnement.</p>
</div>
</div>
<div id="quest-ce-quune-théorie-scientifique" class="section level3 hasAnchor" number="1.3.3">
<h3><span class="header-section-number">1.3.3</span> Qu’est-ce qu’une théorie scientifique ?<a href="1-introduction.html#quest-ce-quune-théorie-scientifique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Qu’est-ce qu’une théorie scientifique ? D’un point de vue très général, une théorie scientifique peut être définie comme un ensemble de propositions logiques qui postulent des relations causales entre des phénomènes observables. Dans un premier temps, ces propositions sont formulées en termes abstraits et généraux (e.g., “tout objet répond à la force de gravité de manière similaire”), mais mènent ensuite à des propositions concrètes et testable empiriquement (e.g., “la vitesse de chute de deux objets devrait être la même, toute chose étant égale par ailleurs”). Il existe cependant de nombreux “types” de théories scientifiques. Par exemple, <span class="citation">P. E. Meehl (<a href="bibliographie.html#ref-meehl_what_1986" role="doc-biblioref">1986</a>)</span> liste trois types de théories :</p>
<ul>
<li><p><em>Functional-dynamic theories</em> : les théories qui relient “les états aux états” ou “les événements aux événements”. Par exemple, ce type de théorie décrit comment un changement sur une variable affecte une ou plusieurs autres variable(s).</p></li>
<li><p><em>Structural-compositional theories</em> : les théories qui expliquent “de quoi est composé quelque chose”, de quels genres d’objets un plus gros objet est fait (i.e., sa structure), ou comment ces différentes parties sont assemblées.</p></li>
<li><p><em>Evolutionary theories</em> : les théories qui s’intéressent à l’histoire et au développement des choses (e.g., la théorie de l’évolution, la chute de Rome, etc).</p></li>
</ul>
<p>Malgré cette diversité, et sans consensus clair sur ce qui fait une bonne ou une mauvaise théorie, la philosophie des sciences nous offre cependant des outils <em>conceptuels</em> utiles pour <em>évaluer</em> les théories, identifier ce qui les rend plus ou moins “fortes”, et évaluer ce qui fait un <em>test sévère</em> d’une théorie. Mais comment-on pouant nous évaluer les théories et comment créer des test sévères et pertinents ?</p>
<div id="on-ne-peut-pas-les-confirmer" class="section level4 hasAnchor" number="1.3.3.1">
<h4><span class="header-section-number">1.3.3.1</span> On ne peut pas les confirmer<a href="1-introduction.html#on-ne-peut-pas-les-confirmer" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un premier “problème” avec les théories scientifiques est que nous ne pouvons pas les “confirmer”. En effet, selon <span class="citation">Campbell (<a href="bibliographie.html#ref-campbell_meehlian_1990" role="doc-biblioref">1990</a>)</span>, le raisonnement scientifique (naif) aurait la forme logique suivante :</p>
<ul>
<li><p>Prémisse n°1 : Si la théorie de Newton (A) est “vraie”, alors on devrait observer observer que les marées ont la période B, la trajectoire de Mars la forme C, la trajectoire d’une boule de canon la forme D, etc.</p></li>
<li><p>Prémisse n °2 : Nos observations confirment B, C, et D.</p></li>
<li><p>Conclusion : Donc la théorie de Newton est “vraie”.</p></li>
</ul>
<p>Or cet argument est invalide. Comme nous l’avons vu dans la section précédente, il s’agit du raisonnement fallacieux d’affirmation du conséquent. Une manière de s’en rendre compte est de réprésenter visuellement la forme de cet argument (cf. Figure <a href="1-introduction.html#fig:campbell">1.8</a>).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:campbell"></span>
<img src="figures/campbell.png" alt="Relation entre observations et théorie de la gravitation de Newton, selon Campbell (1990)." width="50%" />
<p class="caption">
Figure 1.8: Relation entre observations et théorie de la gravitation de Newton, selon Campbell (1990).
</p>
</div>
<p>L’invalidité de cet argument provient de l’existence de la zone hachurée de la Figure <a href="1-introduction.html#fig:campbell">1.8</a>, qui contient les autres explications possibles pour les observations que nous avons réalisées. En d’autres termes, observer B, C, et D ne nous permet pas de conclure que la théorie de Newton (A) est vraie, car ces observations pourraient avoir été générées par d’autres phénomènes que ceux postulés par la théorie de Newton. Cependant, observer B, C, D peut tout de même être informatif, selon certaines conditions, au regard de la théorie de Newton. Par exemple, si nous n’avions pas observé B, C, et D, alors nous aurions pu conclure que A était fausse. Donc observer B, C, et D fait que A reste “plausiblement vraie”. Une autre manière de le dire est que A a “survécu” au test des observations B, C, et D. Nous verrons un peu plus loin comment la capacité des théories à survivre à un test empirique peut être utilisé comme métrique d’évaluation des théories.</p>
</div>
<div id="on-ne-peut-pas-les-réfuter-au-sens-strict" class="section level4 hasAnchor" number="1.3.3.2">
<h4><span class="header-section-number">1.3.3.2</span> On ne peut pas les réfuter (au sens strict)<a href="1-introduction.html#on-ne-peut-pas-les-réfuter-au-sens-strict" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Armés de nos connaissances en logique, nous avons donc établi qu’une théorie scientifique ne peut pas être <em>confirmée</em>. Peut-être pourrions nous alors les <em>réfuter</em> ? A-t-on des moyens de montrer qu’une théorie est fausse ? Qu’est-ce que cela veut dire pour une théorie d’être “fausse” ? Selon la pensée influente de Popper, une théorie est falsifiable (ou réfutable) si et seulement si il existe au moins un falsificateur potentiel (i.e., au moins une proposition possible qui soit en contradiction logique avec elle). En d’autres termes, une théorie peut être considérée comme réfutable s’il peut être démontré qu’elle est fausse.</p>
<p>Notons au passage que la falsifiabilité de Popper concerne le problème de la <em>démarcation</em> (c’est-à-dire ce qu’est la science et ce qui est la pseudoscience) et définit les pseudosciences comme étant composées de théories non falsifiables (c’est-à-dire des théories qui ne permettent pas d’être réfutées). Mais lorsqu’il s’agit de décrire <em>comment</em> la science fonctionne (visée descriptive) ou comment la science <em>devrait</em> fonctionner (visée prescriptive), le standard falsificationniste ne fonctionne pas vraiment. En fait, il est quasiment unanimement impossible d’appliquer le falsificationnisme déductif dans des contextes scientifiques concrets <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>)</span>. Dans les sections suivantes, nous discutons de quatre problèmes qui nous empêchent de réfuter des théories, à savoir : i) la distinction entre modèle théorique et modèle statistique, ii) le problème de la mesure, iii) la nature probabiliste des hypothèses scientifiques, et enfin iv) le problème de Duhem-Quine.</p>
</div>
<div id="modèles-théoriques-et-modèles-statistiques" class="section level4 hasAnchor" number="1.3.3.3">
<h4><span class="header-section-number">1.3.3.3</span> Modèles théoriques et modèles statistiques<a href="1-introduction.html#modèles-théoriques-et-modèles-statistiques" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un modèle statistique est un appareil utilisé pour relier, pour faire le lien entre un modèle théorique et certaines données. Il peut être défini comme une instanciation d’une théorie en un ensemble d’énoncés ou de propositions probabilistes <span class="citation">(<a href="bibliographie.html#ref-rouder_interplay_2016" role="doc-biblioref">Rouder et al., 2016</a>)</span>. En général, il n’existe pas de relation univoque entre modèles théoriques et modèles statistiques. Autrement dit, un modèle théorique donné peut être représenté (i.e., implémenté) par différents modèles statistiques et réciproquement, différents modèles statistiques peuvent être construits à partir du même modèle théorique. Par conséquent, la confirmation ou réfutation d’un modèle statistique ne permet pas l’induction strict au modèle théorique.</p>
<p>Par exemple, une pratique statistique courante en sciences expérimentales est le test d’hypothèse nulle fréquentiste (<em>Null Hypothesis Significance Testing</em> ou NHST), qui consiste à tester une hypothèse nulle (souvent l’hypothèse d’absence d’effet) afin de confirmer (ou plutôt, corroborer) une hypothèse théorique alternative d’intérêt. Or, le fait de rejeter l’hypothèse d’absence d’effet ne fournit qu’une très faible <em>corroboration</em> de l’hypothèse d’intérêt, comme de nombreuses théories peuvent potentiellement prédire un effet non nul. L’hypothèse d’absence d’effet (i.e., l’hypothèse que l’effet est précisémment égal à <span class="math inline">\(0\)</span>) est beaucoup plus contraignante (restrictive) que l’hypothèse alternative selon laquelle l’effet n’est pas égal à <span class="math inline">\(0\)</span>.</p>
</div>
<div id="le-problème-de-la-mesure" class="section level4 hasAnchor" number="1.3.3.4">
<h4><span class="header-section-number">1.3.3.4</span> Le problème de la mesure<a href="1-introduction.html#le-problème-de-la-mesure" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La logique de la réfutation est assez simple et repose sur la puissance du <em>modus tollens</em>. Appliqué au raisonnement scientifique, cet argument être présenté de la manière suivante :</p>
<ul>
<li><p>Prémisse n °1 : Si ma théorie <span class="math inline">\(T\)</span> est correcte, alors je devrais observer certaines données <span class="math inline">\(D\)</span>.</p></li>
<li><p>Prémisse n°2 : J’observe d’autres données que celles prédites par ma théorie <span class="math inline">\(\lnot D\)</span>.</p></li>
<li><p>Conclusion : Donc, ma théorie est fausse <span class="math inline">\(\lnot T\)</span>.</p></li>
</ul>
<p>Cet argument est parfaitement valide pour les propositions logiques, qui peuvent être soit vraies, soit fausses. Cependant, le premier problème qui apparait lorsqu’on on applique ce raisonnement à des cas concrets de raisonnement scientifique est le problème de l’erreur d’observation (ou erreur de mesure). Toute observation est sujette à de l’erreur, surtout lorsqu’on étudie des phénomènes nouveaux <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>)</span>.</p>
<p>Considérons un instant un exemple qui nous vient de la Physique, lorsqu’a été rapportée l’observation de <a href="https://en.wikipedia.org/wiki/Neutrino">neutrinos</a> plus rapides que la vitesse de la lumière <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>, <a href="bibliographie.html#ref-mcelreath_statistical_2020" role="doc-biblioref">2020</a>)</span>. Selon Einstein, aucun objet ne peut voyager plus vite que la lumière. Par conséquent, l’observation de certaines particules (en l’occurrence des neutrinos) qui voyageraient à une vitesse supérieure à celel de la lumière pourraient être considérée comme une réfutation flagrante de la théorie de la relativité restreinte.</p>
<p>En 2011, une large équipe de physiciens de renommée internationale ont pourtant annoncé la détection de neutrinos voyageant plus rapidement quela vitesse de la lumière. De manière intéressante, la première réaction de la communauté scientifique ne fut pas d’annoncer que la théorie d’Einstein était réfutée. Bien au contraire, la plus grande partie de la communauté s’est demandée “D’où est-ce que vient l’erreur dans les mesures réalisées par cette équipe ?” <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>, <a href="bibliographie.html#ref-mcelreath_statistical_2020" role="doc-biblioref">2020</a>)</span>. L’équipe ayant réalisée ces mesures a de ses voeux appelé à des réplications indépendantes de leurs résultats. Deux ans plus tard et après plusieurs ré-analyses et réplications contradictoires, la communauté était unanime que les résultats qui semblaient contredire la théorie d’Einstein étaient en fait dû à une erreur de mesure (l’équipe ayant réalisé les premières mesures a réalisé plus tard que l’erreur provenait <a href="https://profmattstrassler.com/articles-and-posts/particle-physics-basics/neutrinos/neutrinos-faster-than-light/opera-what-went-wrong/">d’un câble mal branché</a>).</p>
<p>Cette anecdote de l’histoire des sciences nous apprend au moins deux choses. Premièrement, il est intéressant d’analyser la réaction de la communauté de l’annonce de ces résultats. La théorie de la relativité restreinte ayant accumulé de nombreux succès prédictifs au cours du dernier siècle, la survenue d’une observation si dramatiquement incompatible avec la théorie était perçue comme hautement improbable aux yeux des experts. Cela nous renseigne sur la manière dont les théories scientifiques gagnent en “crédence” aux yeux d’une communauté d’expert, et également comme cette crédence ou l’historique d’une théorie affecte ou influence la manière d’interpréter les observations empiriques. Deuxièmement, cela souligne le fait qu’une observation ou un ensemble d’observation peut difficilement compter comme une réfutation stricte d’une théorique, car il existe (presque) toujours une probabilité de se tromper ou une erreur irréductible dans la précision de la mesure. De manière générale, le problème avec l’erreur de mesure est de savoir si la réfutation d’une théorie <span class="math inline">\(T\)</span> par un ensemble d’observations <span class="math inline">\(D\)</span> est véritable ou simplement superficielle. Sachant que toute mesure est sujette à de l’erreur, toute conclusion scientifique qui repose sur une ou des mesure(s) ne peut qu’apporter une réfutation partielle (exprimée en termes probabilistes) d’une théorie, et non une réfutation stricte (comme en logique formelle).</p>
</div>
<div id="hypothèses-probabilistes" class="section level4 hasAnchor" number="1.3.3.5">
<h4><span class="header-section-number">1.3.3.5</span> Hypothèses probabilistes<a href="1-introduction.html#hypothèses-probabilistes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un autre problème émerge lorsqu’on essaye d’appliquer le modus tollens aux hypothèses scientifiques. Ce problème <span class="citation">(désigné comme “illusion permanente” par <a href="bibliographie.html#ref-gigerenzer_superego_1993" role="doc-biblioref">Gigerenzer, 1993</a>)</span> est que la plupart des hypothèses scientifiques ne sont pas vraiment de la forme “tous les cygnes sont blancs” mais sont plutôt de la forme suivante :</p>
<ul>
<li><p>Mon hypothèse est que 90% des cygnes sont blancs.</p></li>
<li><p>Si mon hypothèse est correcte, alors on ne devrait <em>probablement pas</em> observer des cygnes noirs.</p></li>
</ul>
<p>Sachant cette hypothèse, que peut-on conclure si on observe un cygne noir ? Et bien pas grand chose. Un autre exemple classique en sciences expérimentales est celui de la logique du test d’hypothèse nulle <span class="citation">(<a href="bibliographie.html#ref-cohen_earth_1994" role="doc-biblioref">Cohen, 1994</a>)</span> :</p>
<ul>
<li><p>Prémisse n°1 : Si l’hypothèse nulle est vraie, alors ces données sont peu probables.</p></li>
<li><p>Prémisse n °2 : On observe ces données.</p></li>
<li><p>Conclusion : Donc l’hypothèse nulle est improbable.</p></li>
</ul>
<p>Cependant, à cause du prémisse probabiliste (prémisse n°1), cet argument est invalide et sa conclusion est fausse. Pour s’en rendre compte, considérons un autre exemple <span class="citation">(<a href="bibliographie.html#ref-cohen_earth_1994" role="doc-biblioref">Cohen, 1994</a>; <a href="bibliographie.html#ref-pollard_probability_1987" role="doc-biblioref">Pollard &amp; Richardson, 1987</a>)</span> :</p>
<ul>
<li><p>Prémisse n°1 : Si un individu est Américain, il est peu probable qu’il soit membre du Congrès.</p></li>
<li><p>Prémisse n°2 : Cet individu n’est pas membre du Congrès.</p></li>
<li><p>Conclusion : Cet individu n’est probablement pas Américain.</p></li>
</ul>
<p>Cette conclusion est saugrenue est l’argument est invalide, car il oublie de considérer l’alternative, qui est que si cet individu n’était pas Américain, la probabilité qu’il soit membre du Congrès serait de 0. Cet argument est identique au précédent :</p>
<ul>
<li><p>Prémisse n°1 : Si l’hypothèse nulle est vraie, alors ces données sont peu probables.</p></li>
<li><p>Prémisse n °2 : On observe ces données.</p></li>
<li><p>Conclusion : Donc l’hypothèse nulle est improbable.</p></li>
</ul>
<p>Et cet argument est invalide pour les mêmes raisons que le précédent, à savoir i) que le prémisse n°1 est probabiliste (et non discret) et ii) qu’il ne considère pas l’hypothèse alternative. Ainsi, même sans erreur de mesure, on se rend compte que le problème d’hypothèse probabiliste nous empêche de réfuter ce genre d’hypothèse via le modus tollens.</p>
</div>
<div id="forme-logique-du-test-expérimental-dune-théorie" class="section level4 hasAnchor" number="1.3.3.6">
<h4><span class="header-section-number">1.3.3.6</span> Forme logique du test expérimental d’une théorie<a href="1-introduction.html#forme-logique-du-test-expérimental-dune-théorie" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Un dernier (mais non des moindres) problème est connu comme la “thèse de Duhem-Quine” ou le “problème de l’indétermination”. En pratique, lorsqu’une théorie <span class="math inline">\(T\)</span> est testée, il est nécessaire de faire appel à des hypothèses sous-jacentes (i.e., non explicites) ou à d’autres théories. Ces théories “auxiliaires” nous aident à “connecter” la théorie d’intérêt <span class="math inline">\(T\)</span> avec le “monde réel”, afin de faire des préditions concrètes (e.g., “les cygnes blancs et noirs passent la même proportion de leur temps à se ballader, donc la probabilité de les observer dans la nature devrait être égale”). Ces théories auxiliaires sont souvent des théories à propos des outils que nous utilisons (e.g., “le BDI est ou un outil valide pour mesurer le niveau de symptômes dépressifs chez des patients souffrant de dépression chronique”).</p>
<p>Lorsque nous testons une théorie qui prédit que “Si <span class="math inline">\(O_{1}\)</span>” (une manipulation expérimentale), “Alors <span class="math inline">\(O_{2}\)</span>” (une observation prédite), ce que nous voulons dire en fait est que l’on devrait observer cette relation <em>si et seulement si</em> tous les éléments auxiliaires sont corrects. Ainsi, la structure logique du test empirique d’une théorie <span class="math inline">\(T\)</span> peut être décrit de la manière suivante <span class="citation">(<a href="bibliographie.html#ref-meehl_appraising_1990" role="doc-biblioref">Paul E. Meehl, 1990a</a>, <a href="bibliographie.html#ref-meehl_theoretical_1978" role="doc-biblioref">1978</a>, <a href="bibliographie.html#ref-harlow_problem_1997" role="doc-biblioref">1997</a>)</span> :</p>
<p><span class="math display">\[(T \land A_{t} \land C_{p} \land A_{i} \land C_{n}) \to (O_{1} \supset O_{2})\]</span></p>
<p>où “<span class="math inline">\(\land\)</span>” représente une conjonction (“et”), “<span class="math inline">\(\to\)</span>” représente une déduction logique, et “<span class="math inline">\(\supset\)</span>” représente l’implication logique (e.g., “Si <span class="math inline">\(O_{1}\)</span>, Alors <span class="math inline">\(O_{2}\)</span>”). <span class="math inline">\(A_{t}\)</span> est une conjonction de théories auxiliares, <span class="math inline">\(C_{p}\)</span> est connu comme le <em>ceteribus paribus</em> (i.e., on postule qu’il n’existe pas de facteurs extérieurs non pris en compte et qui pourraient “masquer” l’effet d’intérêt) <span class="math inline">\(A_{i}\)</span> est une théorie auxiliaire concernant les outils utilisés pour mesurer l’effet d’intérêt, et <span class="math inline">\(C_{n}\)</span> est un énoncé à propos des conditions particulières de l’expérience réalisée (i.e., on postule qu’il n’existe pas de bruit ou erreur systématique dans le protocole expérimental).</p>
<p>En d’autres termes, une <em>conjonction</em> de tous les éléments du côté gauche de la formule ci-dessus (ce qui inclut notre théorie <span class="math inline">\(T\)</span>) implique la partie droite de la formule, c’est à dire “Si <span class="math inline">\(O_{1}\)</span>, Alors <span class="math inline">\(O_{2}\)</span>”. Si l’expérience réalisée nous révèle que cette relation ne tient pas, alors on aimerait pouvoir conclure que notre hypothèse <span class="math inline">\(T\)</span> est réfutée (en appliquant le modus tollens).</p>
<p>Or, une négation de la partie droite de cette formule nous permet seulement d’affirmer une négation de l’<strong>intégralité</strong> de la partie gauche. Autrement dit, ne pas observer une prédiction empirique d’une théorie nous permet de réfuter l’ensemble <span class="math inline">\(T \land A_{t} \land C_{p} \land A_{i} \land C_{n}\)</span>, ce qui est très différent d’une réfutation de <span class="math inline">\(T\)</span> <span class="citation">(<a href="bibliographie.html#ref-meehl_appraising_1990" role="doc-biblioref">Paul E. Meehl, 1990a</a>)</span>. En termes plus formels, une négation de la conjonction (de gauche) est logiquement équivalent à déclarer une disjonction des conjoints (i.e., soit l’un ou l’autre des composants de la partie gauche est faux).</p>
<p>Pour résumer, ne pas observer quelque chose qui était prédit par une théorie ne permet pas de montrer que cette théorie est fausse, mais cela permet de montrer que la conjonctions de la théorie et des hypothèses auxiliaires est fausse. Une conséquence des quatre problèmes soulevés dans cette section et que la réfutation d’une théorie scientifique n’est jamais logique, mais elle est plutôt <strong>consensuelle</strong> <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>, <a href="bibliographie.html#ref-mcelreath_statistical_2020" role="doc-biblioref">2020</a>)</span>. Une proposition théorique est considérée comme réfutée lorsqu’une communauté d’experts a accumulé un grand nombre de preuves variées, issus de protocoles et de groupes de recherches variés, au fil des décennies. Ce travail d’accumulation des preuves s’accompagne de discussions critiques indissociables du travail de développement théorique. En somme, la réfutation d’une théorie est un résultat social, issue d’une communauté d’experts, et n’est (presque) jamais le résultat d’une déduction logique formelle.</p>
</div>
</div>
<div id="test-dhypothèse-nulle-et-raisonnement-scientifique" class="section level3 hasAnchor" number="1.3.4">
<h3><span class="header-section-number">1.3.4</span> Test d’hypothèse nulle et raisonnement scientifique<a href="1-introduction.html#test-dhypothèse-nulle-et-raisonnement-scientifique" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<!--

#### Est-ce que le test d'hypothèse nulle est falsificationniste ?

-->
<p>Une croyance répandue en sciences expérimentales est que l’utilisation de la procédure NHST est bien alignée avec la philosophie scientifique de Popper (et implicitement, qu’il s’agit là de quelque chose de souhaitable). Cependant, le parallèle entre la procédure NHST et la philosophie Poppérienne est très approximatif. La logique de la procédure NHST peut être résumée de la manière suivante :</p>
<ol style="list-style-type: decimal">
<li>On suppose l’hypothèse d’absence d’effet <span class="math inline">\(\mathcal{H}_{0}\)</span>.</li>
<li>On génère un nombre infini d’échantillons sous cette hypothèse.</li>
<li>On compare les données que nous avons observées dans notre expérience à la distribution contrefactuelle des données sous l’hypothèse nulle <span class="math inline">\(\mathcal{H}_{0}\)</span>.</li>
</ol>
<p>Si les données observées semblent suffisamment invraisemblables conditionnellement à <span class="math inline">\(\mathcal{H}_{0}\)</span> (où “suffisamment” correspond au niveau <span class="math inline">\(\alpha\)</span> du test), nous pouvons rejeter l’hypothèse nulle en toute sécurité et considérer ce rejet comme une corroboration de l’hypothèse alternative <span class="math inline">\(\mathcal{H}_{1}\)</span> (quelle que soit l’hypothèse alternative).</p>
<p>En d’autres termes, la seule hypothèse réellement testée (dans la procédure NHST classique) est l’hypothèse nulle, qui est rarement d’intérêt pour le chercheur en train de la tester. Ainsi, afin de réellement aligner cette procédure avec la méthode falsificationniste, il faudrait tester les prédictions de l’hypothése théorique <span class="math inline">\(\mathcal{T}\)</span> réellement d’intérêt, et non les prédictions d’une hypothèse épouvantail <span class="math inline">\(\mathcal{H}_{0}\)</span>.<a href="#fn3" class="footnote-ref" id="fnref3"><sup>3</sup></a> Comme résumé par <span class="citation">P. E. Meehl (<a href="bibliographie.html#ref-meehl_what_1986" role="doc-biblioref">1986</a>)</span> :</p>
<blockquote>
<p>“[…] we have been brainwashed by Fisherian statistics into thinking that refutation of H0 is a powerful way of testing substantive theories”.</p>
</blockquote>
<!--

Aside from this problem, Fidler et al. (2018) provide four ways in which NHST violates Popperian falsificationism, namely because i) the statistical null model is almost certainly wrong to some degree (the straw-man null hypothesis), ii) substantive hypotheses (our hypotheses of interest) are not put under examination, iii) substantive hypotheses are not developed enough to drive statistical hypotheses and iv) even if all the previous points were solved, we would still need to submit these hypotheses to severe tests, which would require well-powered and well-designed studies, which is not the current norm^[The average statistical power of psychological research has been estimated to be under 50% for the average effect size seen in psychology research (e.g., Szucs & Ioannidis, 2017).].

-->
<p><span class="citation">Fidler et al. (<a href="bibliographie.html#ref-fidler_epistemic_2018" role="doc-biblioref">2018</a>)</span> décrivent quatre raisons de questionner le parallèle entre la procédure NHST et la méthode falficationniste.</p>
<ol style="list-style-type: decimal">
<li><p>L’hypothèse nulle <span class="math inline">\(\mathcal{H}_{0}\)</span> (ou plutôt la <em>nil hypothesis</em>, c’est à dire l’hypothèse que la valeur du paramètre testé est précisément <span class="math inline">\(0\)</span>) est très probablement fausse car en sciences sociales en particulier “tout tend à être associé avec tout”, un phénomène également connu sous le nom de <em>crud factor</em> <span class="citation">(<a href="bibliographie.html#ref-meehl_why_1990" role="doc-biblioref">Paul E. Meehl, 1990b</a>)</span>.</p></li>
<li><p>La procédure NHST ne teste pas réellement l’hypothèse d’intérêt <span class="math inline">\(\mathcal{T}\)</span>, mais seulement l’hypothèse épouvantail <span class="math inline">\(\mathcal{H}_{0}\)</span>.</p></li>
<li><p>De nombreuses hypothèses théories sous-jacentes ne sont pas assez bien développées ou formalisées et ne permettent pas de formuler des hypothèses statistiques.</p></li>
<li><p>Même si tous les points précédents ont été résolus, nous aurions encore besoin de soumettre ces hypothèses à des tests sévères, ce qui nécessiterait des études bien alimentées et bien conçues, ce qui n’est pas la norme actuelle.<a href="#fn4" class="footnote-ref" id="fnref4"><sup>4</sup></a></p></li>
</ol>
<!--

#### Test d'hypothèse fort versus test d'hypothèse faible

-->
<p>Le point n°2 soulevé ci-dessus nous dit que la procédure NHST ne suit pas le falsificationnisme Poppérien car il ne soumet pas la théorie testée à un risque de falification <em>sévère</em>, mais seulement à un danger très faible. En d’autres termes, le test d’hypothèse nulle (tel que pratiqué dans la procédure NHST classique) ne soumet pas la théorie sous-jacente (i.e., celle qu’on vise à évaluer via le test de l’hypothèse statistique dérivée de cette première) à un test fort <span class="citation">(<a href="bibliographie.html#ref-meehl_appraising_1990" role="doc-biblioref">Paul E. Meehl, 1990a</a>, <a href="bibliographie.html#ref-meehl_theory-testing_1967" role="doc-biblioref">1967</a>, <a href="bibliographie.html#ref-harlow_problem_1997" role="doc-biblioref">1997</a>)</span>. Autrement dit, étant donné que l’hypothèse nulle est facilement réfutée, l’hypothèse alternative est facilement corroborée statistiquement, et donc peu corroborée au niveau théorique.</p>
<p>Ceci étant dit, cette critique porte sur une manière d’utiliser la procédure NHST (qui est aujourd’hui la plus répandue en Psychologie), mais ce n’est pas la seule manière d’utiliser cette procédure. On pourrait très bien utiliser cette procédure afin d’essayer de réfuter notre hypothèse d’intérêt <span class="math inline">\(\mathcal{T}\)</span>. <span class="citation">Paul E. Meehl (<a href="bibliographie.html#ref-meehl_theory-testing_1967" role="doc-biblioref">1967</a>)</span> distingue entre l’usage <em>fort</em> et <em>faible</em> du test d’hypothèse nulle en comparant l’usage de la procédure NHST en physique et en psychologie. L’usage <em>faible</em> du test d’hypothèse nulle, décrit ci-dessus, correspond à tenter de réfuter une hypothèse nulle qui ne nous intéresse pas afin de corroborer une hypothèse alternative d’intérêt.</p>
<!--

But NHST can be used in either a *strong* or a *weak* way (Meehl, 1967; 1990), depending on the statistical hypothesis $H$ that is being tested in order to appraise a substantitve theory $T$ (Meehl, 1997). The *weak use* of NHST corresponds to the situation in which we try to corroborate our theory $T$ by rejecting the (highly implausible) null hypothesis. This use of NHST can be described as weak, mostly because of what is known as the **crud factor** (i.e., the fact that, in the social sciences, everything is correlated), then everything could explain a non-null difference. As a consequence, refuting the null does not really corroborate our favourite alternative hypothesis

-->
<p>L’usage fort du test d’hypothèse nulle nécessite cependant d’avoir une théorie suffisamment développée, à même de prédire une valeur numérique précise pour une observation, ou tout du moins un intervalle réduit de valeurs possibles, ou alors certaines formes de fonctions (e.g., quadratique ou cubique) entre les variables d’intérêt <span class="citation">(<a href="bibliographie.html#ref-harlow_problem_1997" role="doc-biblioref">Paul E. Meehl, 1997</a>)</span>. Dans ce genre de situation, le test d’hypothèse nulle pourrait agir comme un test Poppérien <em>risqué</em>, au sens où l’hypothèse testée est soumises à un risque élevé de réfutation <span class="citation">(<a href="bibliographie.html#ref-harlow_problem_1997" role="doc-biblioref">Paul E. Meehl, 1997</a>)</span>. Notons également que la procédure NHST peut être adaptée afin de réfuter des intervalles de valeurs, via les tests d’équivalence <span class="citation">(<a href="bibliographie.html#ref-lakens_equivalence_2018" role="doc-biblioref">Lakens et al., 2018</a>; <a href="bibliographie.html#ref-rogers_using_1993" role="doc-biblioref">Rogers et al., 1993</a>)</span> ou la procédure HDI+ROPE <span class="citation">(<a href="bibliographie.html#ref-kruschke_doing_2015" role="doc-biblioref">Kruschke, 2015</a>)</span>.</p>
<p>Bien entendu, dans certaines (rares) situations, l’hypothèse d’absence d’effet est théoriquement d’intérêt, et donc viser à réfuter cette hypothèse via un test d’hypothèse nulle représenterait une tentative sérieuse de réfutation. Par exemple il existe certaines théories en Psychologie qui prédisent que certains comportement seraient invariants selon certaines situations <span class="citation">(<a href="bibliographie.html#ref-morey_beyond_2018" role="doc-biblioref">Morey et al., 2018</a>)</span>. Ces hypothèses peuvent être testées <em>sévèrement</em> par un test d’hypothèse nul, car ce dernier les exposerait à un haut risque de réfutation.</p>
<!--

Le *modus tollens* est un des raisonnements logiques les plus importants et les plus performants. Dans le cadre de l'inférence statistique, il s'applique parfaitement au cas suivant: "Si $H_{0}$ est vraie, alors $x$ ne devrait pas se produire. On observe $x$. Alors $H_{0}$ est fausse".

Mais nous avons le plus souvent affaire à des hypothèses "continues", probabilistes.

L'inférence fréquentiste (Fishérienne) est elle aussi probabiliste, de la forme "Si $H_{0}$ est vraie, alors $x$ est peu probable. On observe $x$. Alors $H_{0}$ est peu probable."

Or cet argument est invalide, le *modus tollens* ne s'applique pas au monde probabiliste (e.g., [Pollard & Richardson, 1987](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.505.9968&rep=rep1&type=pdf); [Rouder, Morey, Verhagen, Province, & Wagenmakers, 2016](http://www.ejwagenmakers.com/2016/RouderEtAl2016FreeLunch.pdf)). 

Par exemple: *si un individu est un homme, alors il est peu probable qu'il soit pape. François est pape. François n'est donc certainement pas un homme...*

-->
<p>Pour résumer, la vision naïve du falsificationnisme consiste à penser que la science progresse par falsification logique (et que donc la statistique devrait viser la falsification). Cependant, comme discuté dans cette section, cette perspective se retrouve face à plusieurs problèmes difficilement surmontables, que nous résumons ci-dessous.</p>
<ul>
<li><p>Premier problème : Les hypothèses théoriques ne sont pas les modèles (hypothèses statistiques). Un modèle statistique est un appareil utilisé pour relier, pour faire le lien entre un modèle théorique et certaines données. Il peut être défini comme une instanciation d’une théorie en un ensemble d’énoncés ou de propositions probabilistes <span class="citation">(<a href="bibliographie.html#ref-rouder_interplay_2016" role="doc-biblioref">Rouder et al., 2016</a>)</span>.</p></li>
<li><p>Deuxième problème : En général, il n’existe pas de relation univoque entre modèles théoriques et modèles statistiques. Autrement dit, un modèle théorique donné peut être représenté (i.e., implémenté) par différents modèles statistiques et réciproquement, différents modèles statistiques peuvent être construits à partir du même modèle théorique. Par conséquent, la confirmation ou réfutation d’un modèle statistique ne permet pas l’induction strict au modèle théorique.</p></li>
<li><p>Troisième problème : Les hypothèses scientifique sont souvent probabilistes, ce qui invalide l’emploi du modus tollens.</p></li>
<li><p>Quatrième problème : Les mesures permettant de tester une théories sont sujette à des erreurs, ce qui empêche également la réfutation strictes d’hypothèses (cf. l’anecdote des neutrinos).</p></li>
</ul>
<p>Enfin, la falsification concerne le problème de la démarcation, pas celui de la méthode. La science est une technologie sociale, la falsification est <strong>consensuelle</strong>, et non pas logique.</p>
</div>
<div id="lapproche-par-comparaison-de-modèles" class="section level3 hasAnchor" number="1.3.5">
<h3><span class="header-section-number">1.3.5</span> L’approche par comparaison de modèles<a href="1-introduction.html#lapproche-par-comparaison-de-modèles" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En connaissance des limitations de l’approche par test d’hypothèse nulle telle que présentée dans la section précédente, nous adoptons dans ce livre une approche dite par *comparaison de modèles**.</p>
<p>En bref, en place d’une approche mécanique du test d’hypothèse nulle, nous proposons une méthode qui met l’accent sur l’estimation de paramètres, la comparaison de modèles statistiques et théoriques (sensés et d’intérêt), et l’extension (amélioration) continuelle du modèle <span class="citation">(<a href="bibliographie.html#ref-burnham_multimodel_2004" role="doc-biblioref">Burnham &amp; Anderson, 2004</a>; e.g., <a href="bibliographie.html#ref-burnham_model_2002" role="doc-biblioref">Burnham &amp; Anderson, 2002</a>; <a href="bibliographie.html#ref-cumming_new_2014" role="doc-biblioref">Cumming, 2014</a>, <a href="bibliographie.html#ref-Cumming2012" role="doc-biblioref">2012</a>; <a href="bibliographie.html#ref-gelman_bayesian_2013" role="doc-biblioref">Gelman et al., 2013</a>; <a href="bibliographie.html#ref-gelman_data_2006" role="doc-biblioref">Gelman &amp; Hill, 2006</a>; <a href="bibliographie.html#ref-judd_data_2009" role="doc-biblioref">Judd et al., 2009</a>; <a href="bibliographie.html#ref-kruschke_doing_2015" role="doc-biblioref">Kruschke, 2015</a>; <a href="bibliographie.html#ref-kruschke_bayesian_2018" role="doc-biblioref">Kruschke &amp; Liddell, 2018a</a>, <a href="bibliographie.html#ref-kruschke_bayesian_2018-1" role="doc-biblioref">2018b</a>; <a href="bibliographie.html#ref-R-rethinking" role="doc-biblioref">McElreath, 2016a</a>)</span>. En d’autres notre approche est une approche de <strong>modélisation statistique</strong> plutôt qu’une approche de <strong>test statistique</strong> <span class="citation">(e.g., <a href="bibliographie.html#ref-noel_psychologie_2015" role="doc-biblioref">Noël, 2015</a>)</span>. Cette approche vise à modéliser le processus sous-jacent ayant généré les données observées (i.e., le <strong>processus de génération des données</strong> ou PGD) plutôt qu’à tester si la valeur de certains paramètres d’un modèle inapproprié est égal à une valeur arbitraire (e.g., <span class="math inline">\(\theta = 0\)</span>). Cette approche n’est cependant pas incompatible avec l’approche falsificationniste tel que décrite en philosophie des sciences. En effet, certains statisticiens bayésiens comme <span class="citation">Gelman &amp; Shalizi (<a href="bibliographie.html#ref-gelman_philosophy_2013" role="doc-biblioref">2013</a>)</span> suggèrent que la réfutation des modèles statistiques joue un rôle important dans le processus de modélisation et d’amélioration des modèles (nous y reviendrons à plusieurs reprises, en particulier lorsque nous discuterons l’utilisation des <em>prior</em> et <em>posterior predictive checks</em>).</p>
<p>Afin d’illustrer l’approche par comparaison de modèles, considérons l’exemple suivant. On s’intéresse au lien entre deux variables aléatoires continues <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span>. On réalise une expérience et on collecte 10 observations nous permettant d’étudier cette relation. L’hypothèse de modélisation la plus classique est de postuler une relation linéaire entre <span class="math inline">\(x\)</span> et <span class="math inline">\(y\)</span>. La droite minimisant la somme des erreurs au carré est représentée par la Figure <a href="1-introduction.html#fig:modelcomp2">1.9</a>.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:modelcomp2"></span>
<img src="IMSB_files/figure-html/modelcomp2-1.svg" alt="Scatterplot des 10 observations obtenues dans notre expérience et droite des moindres carrés décrivant la relation entre x et y estimée sur la base de ces 10 observations." width="75%" />
<p class="caption">
Figure 1.9: Scatterplot des 10 observations obtenues dans notre expérience et droite des moindres carrés décrivant la relation entre x et y estimée sur la base de ces 10 observations.
</p>
</div>
<p>Cette description peut-être <em>améliorée</em> (où “améliorer” consiste à réduire l’erreur) pour mieux prendre en compte les données qui s’écartent de la prédiction linéaire. La figure <a href="1-introduction.html#fig:modelcomp3">1.10</a> représente la prédiction d’un modèle polynomial (quadratique).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:modelcomp3"></span>
<img src="IMSB_files/figure-html/modelcomp3-1.svg" alt="Prédiction quadratique décrivant la relation entre x et y estimée sur la base des 10 observations collectées pour notre expérience." width="75%" />
<p class="caption">
Figure 1.10: Prédiction quadratique décrivant la relation entre x et y estimée sur la base des 10 observations collectées pour notre expérience.
</p>
</div>
<p>Cette “amélioration” du modèle statistique via une augmentation de la complexité de ce dernier peut être poursuivi. On sait qu’un ensemble de <span class="math inline">\(N\)</span> points peut être <em>exhaustivement</em> (i.e., sans erreur) décrit par une fonction polynomiale d’ordre <span class="math inline">\(N - 1\)</span> (cf. Figure <a href="1-introduction.html#fig:modelcomp4">1.11</a>). Augmenter la complexité du modèle améliore donc la précision de notre description des données mais réduit également la généralisabilité de ses prédictions (il s’agit du dilemme classique entre biais et variance).</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:modelcomp4"></span>
<img src="IMSB_files/figure-html/modelcomp4-1.svg" alt="Différentes prédictions de complexité croissante estimées sur la base des 10 observations collectées pour notre expérience." width="75%" />
<p class="caption">
Figure 1.11: Différentes prédictions de complexité croissante estimées sur la base des 10 observations collectées pour notre expérience.
</p>
</div>
<p>Nous avons donc besoin d’outils qui prennent en compte le rapport entre la qualité de la description des données et la complexité du modèle, c’est à dire qui évaluent la parcimonie du modèle. Dans cette perspective, nous ferons au Chapitre 6 un détour par la théorie de l’information, qui nous permettra introduire des outils comme l’AIC (et ses différentes extensions).</p>
<p>Pour résumer, notre approche consistera donc à construire des modèles statistiques comme des implémentations mathématiques (probabilistes) de modèles théoriques que nous souhaitons comparer. L’inférence statistique bayésienne consistera à mettre à jour notre état de connaissance concernant les valeur des paramètres de ces modèles (mais également notre état de connaissance vis à vis de la validité relative de ces modèles) en fonction des données observées. Ces modèles seront comparés en fonction de i) leur puissance prédictive et ii) leur complexité. Au lieu d’essayer de réfuter un modèle épouvantail (i.e., l’hypothèse nulle), on comparera des modèles intrinsèquement intéressants, qu’on essayera de réfuter afin de les améliorer. La section suivante présente un premier exemple permettant de saisir l’idée centrale de l’inférence bayésienne.</p>
</div>
</div>
<div id="problème-du-sac-de-billes-mcelreath_statistical_2016" class="section level2 hasAnchor" number="1.4">
<h2><span class="header-section-number">1.4</span> Problème du sac de billes <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>)</span><a href="1-introduction.html#problème-du-sac-de-billes-mcelreath_statistical_2016" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Imaginons que nous disposions d’un sac contenant 4 billes. Ces billes peuvent être soit blanches, soit bleues. Nous savons qu’il y a précisément 4 billes, mais nous ne connaissons pas le nombre de billes de chaque couleur. Nous savons cependant qu’il existe cinq possibilités (que nous considérons comme nos <em>hypothèses</em>) :</p>
<p><span class="math display">\[
\begin{aligned}
&amp;\text{Hypothèse n°1 : } \LARGE \circ \circ \circ \circ \\
&amp;\text{Hypothèse n°2 : } \LARGE \color{steelblue}{\bullet} \color{black}{\circ} \circ \circ \\
&amp;\text{Hypothèse n°3 : } \LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{black}{\circ} \circ \\
&amp;\text{Hypothèse n°4 : } \LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{black}{\circ} \\
&amp;\text{Hypothèse n°5 : } \LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \\
\end{aligned}
\]</span></p>
<p>Le but est de déterminer quelle combinaison est la plus probable, <strong>sachant certaines observations</strong>. Imaginons que l’on tire trois billes à la suite, avec remise, et que l’on obtienne la séquence suivante : <span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{black}{\circ} \color{steelblue}{\bullet}\)</span>.</p>
<p>Cette séquence représente nos données. À partir de ces données, quelle <strong>inférence</strong> peut-on faire sur le contenu du sac ? En d’autres termes, que peut-on dire de la probabilité de chaque hypothèse ?</p>
<div id="énumérer-les-possibilités" class="section level3 hasAnchor" number="1.4.1">
<h3><span class="header-section-number">1.4.1</span> Énumérer les possibilités<a href="1-introduction.html#énumérer-les-possibilités" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Une stratégie consiste à compter le nombre de possibilités menant aux données obtenues à chaque tirage. Par exemple, si nous considérons l’hypothèse n°2 (i.e., on se place dans un cadre dans lequel cette hypothèse est “vraie”), on peut représenter l’arbre des issues possibles. La Figure <a href="1-introduction.html#fig:garden1">1.12</a> représente ces différentes possibilités. Au premier tirage, selon l’hypothèse n°2, nous avions une chance sur 4 d’obtenir une bille bleue.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:garden1"></span>
<img src="IMSB_files/figure-html/garden1-1.svg" alt="Représentation de l'ensemble des issues possibles au premier tirage selon l'hypothèse n°2." width="75%" />
<p class="caption">
Figure 1.12: Représentation de l’ensemble des issues possibles au premier tirage selon l’hypothèse n°2.
</p>
</div>
<p>La Figure <a href="1-introduction.html#fig:garden2">1.13</a> représente l’ensemble des résultats possibles aux tirages 1 et 2 selon l’hypothèse n°2. On réalise qu’au deuxième comme au premier tirage, on avait une chance sur quatre d’obtenir une bille bleue. Par conséquent on avait <span class="math inline">\(1 \times (4 \times 1) = 4\)</span> chances sur <span class="math inline">\(4^2 = 16\)</span> d’obtenir deux billes bleues. De la même manière, on peut calculer qu’on avait <span class="math inline">\(1 \times 3\)</span> chances sur <span class="math inline">\(4^2 = 16\)</span> d’obtenir une bille bleue et une bille blanche. Autrement dit, 3 chemins mènent à la suite “bille bleue puis bille blanche”.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:garden2"></span>
<img src="IMSB_files/figure-html/garden2-1.svg" alt="Représentation de l'ensemble des issues possibles aux premier et deuxième tirages selon l'hypothèse n°2." width="75%" />
<p class="caption">
Figure 1.13: Représentation de l’ensemble des issues possibles aux premier et deuxième tirages selon l’hypothèse n°2.
</p>
</div>
<p>La Figure <a href="1-introduction.html#fig:garden3">1.14</a> représente l’ensemble des résultats possibles aux tirages 1, 2, et 3 selon l’hypothèse n°2. On réalise qu’à chaque tirage on avait une chance sur quatre d’obtenir une bille bleue. Par conséquent on avait <span class="math inline">\(1 \times (4 \times 1) \times (4 \times 1) = 16\)</span> chances sur <span class="math inline">\(4^3 = 64\)</span> d’obtenir trois billes bleues. De la même manière, on peut calculer qu’on avait <span class="math inline">\(1 \times 3 \times 1\)</span> chances sur <span class="math inline">\(4^3 = 64\)</span> d’obtenir une bille bleue et une bille blanche. Autrement dit, 3 chemins mènent à la suite “bille bleue puis bille blanche puis bille bleue”.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:garden3"></span>
<img src="IMSB_files/figure-html/garden3-1.svg" alt="Représentation de l'ensemble des issues possibles selon l'hypothèse n°2 sur l'ensemble des tirages." width="75%" />
<p class="caption">
Figure 1.14: Représentation de l’ensemble des issues possibles selon l’hypothèse n°2 sur l’ensemble des tirages.
</p>
</div>
<p>La Figure <a href="1-introduction.html#fig:garden4">1.15</a> représente le nombre de “chemins” qui mènent au résultat obtenu et confirme que sous l’hypothèse n°2, <span class="math inline">\(3\)</span> chemins sur <span class="math inline">\(4^{3} = 64\)</span> conduisent au résultat obtenu. Qu’en est-il des autres hypothèses?</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:garden4"></span>
<img src="IMSB_files/figure-html/garden4-1.svg" alt="Représentation de l'ensemble des issues possibles selon l'hypothèse n°2 sur l'ensemble des tirages. Les chemins menant aux données observées sont mis en avant." width="75%" />
<p class="caption">
Figure 1.15: Représentation de l’ensemble des issues possibles selon l’hypothèse n°2 sur l’ensemble des tirages. Les chemins menant aux données observées sont mis en avant.
</p>
</div>
<p>La Figure <a href="1-introduction.html#fig:garden5">1.16</a> représente le nombre de chemins menant aux données observées pour les hypothèse n°2, n°3, et n°4.</p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:garden5"></span>
<img src="IMSB_files/figure-html/garden5-1.svg" alt="Représentation de l'ensemble des issues possibles selon les hypothèses n°2, n°3, et n°4 sur l'ensemble des tirages. Les chemins menant aux données observées sont mis en avant." width="75%" />
<p class="caption">
Figure 1.16: Représentation de l’ensemble des issues possibles selon les hypothèses n°2, n°3, et n°4 sur l’ensemble des tirages. Les chemins menant aux données observées sont mis en avant.
</p>
</div>
<p>On peut ensuite comparer les hypothèses par leur <em>propension</em> à mener aux données observées. Plus précisément, on peut comparer les hypothèses entre elles en comparant le nombre de chemins menant aux données pour chaque hypothèse (cf. Tableau <a href="1-introduction.html#tab:hypothesis-comparison">1.1</a>).</p>
<caption>
<span id="tab:hypothesis-comparison">Tableau 1.1: </span>
</caption>
<div custom-style="Table Caption">
<em>Comparer des hypothèses en comparant le nombre de manières qu’elles ont de produire les données observées.</em>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Hypothèse</th>
<th align="center">Façons d’obtenir les données</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \circ \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0 \times 4 \times 0 = 0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(1 \times 3 \times 1 = 3\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(2 \times 2 \times 2 = 8\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ\)</span></td>
<td align="center"><span class="math inline">\(3 \times 1 \times 3 = 9\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet}\)</span></td>
<td align="center"><span class="math inline">\(4 \times 0 \times 4 = 0\)</span></td>
</tr>
</tbody>
</table>
<p>On pourra conclure, au vu des données, que l’hypothèse n°4 est la plus <em>plausible</em> car c’est l’hypothèse qui <strong>maximise le nombre de manières possibles d’obtenir les données obtenues</strong>.</p>
</div>
<div id="accumulation-dévidence" class="section level3 hasAnchor" number="1.4.2">
<h3><span class="header-section-number">1.4.2</span> Accumulation d’évidence<a href="1-introduction.html#accumulation-dévidence" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Jusque là, nous avons considéré que toutes les hypothèses étaient équiprobables a priori (suivant le <a href="https://en.wikipedia.org/wiki/Principle_of_indifference">principe d’indifférence</a>). Cependant, on pourrait avoir de l’information a priori, provenant de nos connaissances (e.g., concernant les particularités des sacs de billes) ou de données antérieures. Imaginons que nous tirions une nouvelle bille du sac. Comment pouvons-nous incorporer cette nouvelle donnée ?</p>
<p>Il suffit d’appliquer la même stratégie que précédemment, et de mettre à jour le dernier compte en le multipliant par ces nouvelles données (cf. Tableau <a href="1-introduction.html#tab:accumulation">1.2</a>). Cette procédure illustre un mécanisme central de l’inférence bayésienne qui concerne l’accumulation d’information. Dans le cadre bayésien, cette accumulation se déroule naturellement, où le résultat de nouvelles analyses peut être naturellement incorporé au résultat d’analyses précédentes, pour mener à un état de connaissance mis à jour.</p>
<caption>
<span id="tab:accumulation">Tableau 1.2: </span>
</caption>
<div custom-style="Table Caption">
<em>Illustration de l’accumulation d’information dans le cadre bayésien.</em>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Hypothèse</th>
<th align="center">Façons de produire <span class="math inline">\(\color{steelblue}{\bullet}\)</span></th>
<th align="center">Compte précédent</th>
<th align="center">Nouveau compte</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \circ \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0 \times 0 = 0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(3\)</span></td>
<td align="center"><span class="math inline">\(3 \times 1 = 3\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(2\)</span></td>
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(8 \times 2 = 16\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ\)</span></td>
<td align="center"><span class="math inline">\(3\)</span></td>
<td align="center"><span class="math inline">\(9\)</span></td>
<td align="center"><span class="math inline">\(9 \times 3 = 27\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet}\)</span></td>
<td align="center"><span class="math inline">\(4\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0 \times 4 = 0\)</span></td>
</tr>
</tbody>
</table>
</div>
<div id="incorporer-un-prior" class="section level3 hasAnchor" number="1.4.3">
<h3><span class="header-section-number">1.4.3</span> Incorporer un prior<a href="1-introduction.html#incorporer-un-prior" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Supposons maintenant qu’un employé de l’usine de fabrication des billes nous dise que les billes bleues sont rares. Plus précisément, cet employé nous dit que pour chaque sac contenant 3 billes bleues, ils fabriquent deux sacs en contenant seulement deux, et trois sacs en contenant seulement une. Il nous apprend également que tous les sacs contiennent au moins une bille bleue et une bille blanche. On peut traduire ces informations en langage mathématique, en attribuant un poids de <span class="math inline">\(0\)</span> pour les hypothèses n°1 et n°5, et en rendant l’hypothèse n°2 trois fois plus probable que l’hypothèses n°4, et l’hypothèse n°3 deux fois plus probable que l’hypothèse n°4 (cf. Tableau <a href="1-introduction.html#tab:prior-table">1.3</a>).</p>
<caption>
<span id="tab:prior-table">Tableau 1.3: </span>
</caption>
<div custom-style="Table Caption">
<em>Illustration de l’intégration d’information a priori dans le cadre bayésien.</em>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Hypothèse</th>
<th align="center">Compte précédent</th>
<th align="center">Prior usine</th>
<th align="center">Nouveau compte</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \circ \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0 \times 0 = 0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(3\)</span></td>
<td align="center"><span class="math inline">\(3\)</span></td>
<td align="center"><span class="math inline">\(3 \times 3 = 9\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(16\)</span></td>
<td align="center"><span class="math inline">\(2\)</span></td>
<td align="center"><span class="math inline">\(16 \times 2 = 32\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ\)</span></td>
<td align="center"><span class="math inline">\(27\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(27 \times 1 = 27\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet}\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0 \times 4 = 0\)</span></td>
</tr>
</tbody>
</table>
<p>Cette procédure illustre encore une fois l’intégration d’information antérieure (on dira également <em>a priori</em>), que ce soit empirique ou théorique, dans l’analyse de nouvelles données. Ce mécanisme est résumé par le célèbre dicton bayésien : <em>Yesterday’s posterior is today’s prior</em> <span class="citation">(<a href="bibliographie.html#ref-lindley_philosophy_2001" role="doc-biblioref">Lindley, 2001</a>)</span>.</p>
</div>
<div id="des-énumérations-aux-probabilités" class="section level3 hasAnchor" number="1.4.4">
<h3><span class="header-section-number">1.4.4</span> Des énumérations aux probabilités<a href="1-introduction.html#des-énumérations-aux-probabilités" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Le théorème de Bayes (que nous présenterons formellement un peu plus tard) nous dit que la probabilité d’une hypothèse après avoir observé certaines données est proportionnelle au nombre de façons qu’a cette hypothèse de produire les données observées, multiplié par sa probabilité a priori.</p>
<p><span class="math display">\[
\Pr(\text{hypothèse} \ | \ \text{données}) \propto \Pr(\text{données} \ | \ \text{hypothèse}) \times \Pr(\text{hypothèse})
\]</span></p>
<p>Si l’on considère toutes les hypothèses comme étant équiprobables a priori (e.g., on leur accorde toutes une probabilité de 1), la <strong>probabilité postérieure</strong> de l’hypothèse <strong>sachant les données observées et le prior</strong> est obtenue en normalisant le produit <span class="math inline">\(\Pr(\text{données} \ | \ \text{hypothèse}) \times \Pr(\text{hypothèse})\)</span> de la manière suivante :</p>
<p><span class="math display">\[
\Pr(\text{hypothèse} \ | \ \text{données}) = \frac{\Pr(\text{données} \ | \ \text{hypothèse}) \times \Pr(\text{hypothèse})}{\text{Somme des produits}}
\]</span></p>
<p>Où la somme des produits consiste à calculer le produit <span class="math inline">\(\Pr(\text{données} \ | \ \text{hypothèse}) \times \Pr(\text{hypothèse})\)</span> pour toutes les hypothèses considérées et à calculer la somme de ces valeurs. Cette manipulation nous assure que la probabilité postérieure (i.e., <span class="math inline">\(\Pr(\text{hypothèse} \ | \ \text{données})\)</span>) est bien une probabilité, c’est à dire une valeur numérique bornée entre <span class="math inline">\(0\)</span> et <span class="math inline">\(1\)</span>.</p>
<p>Par exemple, si l’on définit <span class="math inline">\(p\)</span> comme étant la proportion de billes bleues dans chaque hypothèse, alors on peut ré-exprimer chaque hypothèse en fonction de <span class="math inline">\(p\)</span> (cf. Tableau <a href="1-introduction.html#tab:enumeration-table">1.4</a>).</p>
<caption>
<span id="tab:enumeration-table">Tableau 1.4: </span>
</caption>
<div custom-style="Table Caption">
<em>Calcul de la probabilité postérieure d’une hypothèse.</em>
</div>
<table>
<thead>
<tr class="header">
<th align="center">Hypothèse</th>
<th align="center"><span class="math inline">\(p\)</span></th>
<th align="center">Manières de produire les données</th>
<th align="center">Probabilité postérieure</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \circ \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \circ \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0.25\)</span></td>
<td align="center"><span class="math inline">\(3\)</span></td>
<td align="center"><span class="math inline">\(0.15\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ \circ\)</span></td>
<td align="center"><span class="math inline">\(0.5\)</span></td>
<td align="center"><span class="math inline">\(8\)</span></td>
<td align="center"><span class="math inline">\(0.40\)</span></td>
</tr>
<tr class="even">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \circ\)</span></td>
<td align="center"><span class="math inline">\(0.75\)</span></td>
<td align="center"><span class="math inline">\(9\)</span></td>
<td align="center"><span class="math inline">\(0.45\)</span></td>
</tr>
<tr class="odd">
<td align="center"><span class="math inline">\(\LARGE \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet} \color{steelblue}{\bullet}\)</span></td>
<td align="center"><span class="math inline">\(1\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
<td align="center"><span class="math inline">\(0\)</span></td>
</tr>
</tbody>
</table>
<p>Où la probabilité est calculée en divisant chaque valeur de la troisième colonne par la somme des valeurs de cette colonne. Autrement dit, en <code>R</code> :</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="1-introduction.html#cb17-1" aria-hidden="true" tabindex="-1"></a>ways <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">3</span>, <span class="dv">8</span>, <span class="dv">9</span>, <span class="dv">0</span>)</span>
<span id="cb17-2"><a href="1-introduction.html#cb17-2" aria-hidden="true" tabindex="-1"></a>ways <span class="sc">/</span> <span class="fu">sum</span>(ways)</span></code></pre></div>
<pre><code>## [1] 0.00 0.15 0.40 0.45 0.00</code></pre>
<p>Pour résumer, la probabilité postérieure représente la probabilité d’une hypothèse, <strong>sachant</strong> certaines données observées et certaines connaissances a priori. Cette probabilité postérieure est proportionnelle au produit de la probabilité des données sachant l’hypothèse (i.e., le nombre de manières qu’a l’hypothèse de produire les données) et de la probabilité a priori de l’hypothèse. Autrement dit et comme résumé par <span class="citation">McElreath (<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">2016b</a>)</span>, “<em>Bayesian inference is really just counting and comparing of possibilities</em>”.</p>
</div>
</div>
<div id="quelques-exemples-dapplication" class="section level2 hasAnchor" number="1.5">
<h2><span class="header-section-number">1.5</span> Quelques exemples d’application<a href="1-introduction.html#quelques-exemples-dapplication" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="diagnostique-médical-gigerenzer-2002" class="section level3 hasAnchor" number="1.5.1">
<h3><span class="header-section-number">1.5.1</span> Diagnostique médical (Gigerenzer, 2002)<a href="1-introduction.html#diagnostique-médical-gigerenzer-2002" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Chez les femmes âgées de 40-50 ans, sans antécédents familiaux et sans symptômes, la probabilité d’avoir un cancer du sein est de .008.</p></li>
<li><p>Propriétés de la mammographie:</p>
<ul>
<li>Si une femme a un cancer du sein, la probabilité d’avoir un résultat positif est de .90</li>
<li>Si une femme n’a pas de cancer du sein, la probabilité d’avoir un résultat positif est de .07</li>
</ul></li>
<li><p>Imaginons qu’une femme passe une mammographie, et que le test est positif. Que doit-on <strong>inférer</strong> ? Quelle est la probabilité que cette femme ait un cancer du sein ?</p></li>
</ul>
<div id="logique-du-maximum-likelihood" class="section level4 hasAnchor" number="1.5.1.1">
<h4><span class="header-section-number">1.5.1.1</span> Logique du Maximum Likelihood<a href="1-introduction.html#logique-du-maximum-likelihood" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li><p>Une approche générale de l’estimation de paramètre</p></li>
<li><p>Les paramètres <strong>gouvernent</strong> les données, les données <strong>dépendent</strong> des paramètres</p>
<ul>
<li>Sachant certaines valeurs des paramètres, nous pouvons calculer la <strong>probabilité conditionnelle</strong> des données observées</li>
<li>Le résultat de la mammographie (i.e., les données) dépend de la présence / absence d’un cancer du sein (i.e., le paramètre)</li>
</ul></li>
<li><p>L’approche par <em>maximum de vraisemblance</em> pose la question: “<em>Quelles sont les valeurs du paramètre qui rendent les données observées les plus probables ?</em>”</p></li>
<li><p>Spécifier la probabilité conditionnelle des données <span class="math inline">\(p(x|\theta)\)</span></p></li>
<li><p>Quand on le considère comme fonction de <span class="math inline">\(\theta\)</span>, on parle de <strong>likelihood</strong>: <span class="math inline">\(L(\theta|x) = p(X = x|\theta)\)</span></p></li>
<li><p>L’approche par maximum de vraisemblance consiste donc à maximiser cette fonction, en utilisant les valeurs (connues) de <span class="math inline">\(x\)</span></p></li>
<li><p>Si une femme a un cancer du sein, la probabilité d’obtenir un résultat positif est de .90</p>
<ul>
<li><span class="math inline">\(p(Mam=+|Cancer=+)=.90\)</span></li>
<li><span class="math inline">\(p(Mam=-|Cancer=+)=.10\)</span></li>
</ul></li>
<li><p>Si une femme n’a pas de cancer du sein, la probabilité d’obtenir un résultat positif est de .07</p>
<ul>
<li><span class="math inline">\(p(Mam=+|Cancer=-)=.07\)</span></li>
<li><span class="math inline">\(p(Mam=-|Cancer=-)=.93\)</span></li>
</ul></li>
<li><p>Une femme passe une mammographie, le résultat est positif…</p>
<ul>
<li><span class="math inline">\(p(Mam=+|Cancer=+)=.90\)</span></li>
<li><span class="math inline">\(p(Mam=+|Cancer=-)=.07\)</span></li>
</ul></li>
<li><p>Maximum de vraisemblance: quelle est la valeur de <em>Cancer</em> qui <strong>maximise</strong> <span class="math inline">\(Mam=+\)</span> ?</p>
<ul>
<li><span class="math inline">\(p(Mam=+|Cancer=+)=.90\)</span></li>
<li><del><span class="math inline">\(p(Mam=+|Cancer=-)=.07\)</span></del></li>
</ul></li>
</ul>
<p>Wait a minute…</p>
</div>
<div id="diagnostique-médical-fréquences-naturelles" class="section level4 hasAnchor" number="1.5.1.2">
<h4><span class="header-section-number">1.5.1.2</span> Diagnostique médical, fréquences naturelles<a href="1-introduction.html#diagnostique-médical-fréquences-naturelles" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<ul>
<li>Considérons 1000 femmes âgées de 40 à 50 ans, sans antécédents familiaux et sans symptômes de cancer
<ul>
<li>8 femmes sur 1000 ont un cancer</li>
</ul></li>
<li>On réalise une mammographie
<ul>
<li>Sur les 8 femmes ayant un cancer, 7 auront un résultat positif</li>
<li>Sur les 992 femmes restantes, 69 auront un résultat positif</li>
</ul></li>
<li>Une femme passe une mammographie, le résultat est positif</li>
<li>Que devrait-on inférer ?</li>
</ul>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:diagram"></span>
<img src="figures/diagram.png" alt="Diagram..." width="50%" />
<p class="caption">
Figure 1.17: Diagram…
</p>
</div>
<p><br></p>
<p><span class="math display">\[ p(Cancer = + | Mam = +) = \frac{7}{7 + 69} = \frac{7}{76} \approx .09\]</span></p>
</div>
<div id="diagnostique-médical-théorème-de-bayes" class="section level4 hasAnchor" number="1.5.1.3">
<h4><span class="header-section-number">1.5.1.3</span> Diagnostique médical, théorème de Bayes<a href="1-introduction.html#diagnostique-médical-théorème-de-bayes" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><span class="math display">\[
\color{purple}{p(\theta \ | \ x)} = \dfrac{\color{orangered}{p(x \ | \ \theta)} \color{steelblue}{p(\theta)}}{\color{green}{p(x)}}
\]</span></p>
<p><span class="math inline">\(\color{steelblue}{p(\theta)}\)</span> <span style="color:steelblue"> la probabilité <em>a priori</em> de <span class="math inline">\(\theta\)</span>: tout ce qu’on sait de <span class="math inline">\(\theta\)</span> avant d’observer les données. Par exemple: <span class="math inline">\(p(Cancer=+)=.008\)</span> et <span class="math inline">\(p(Cancer=-)=.992\)</span>.</span></p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="1-introduction.html#cb19-1" aria-hidden="true" tabindex="-1"></a>prior <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="fl">0.008</span>, <span class="fl">0.992</span>)</span></code></pre></div>
<p><span class="math display">\[
\color{purple}{p(\theta \vert x)} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{p(x)}}
\]</span></p>
<p><span class="math inline">\(\color{orangered}{p(x\vert \theta)}\)</span> <span style="color:orangered"> probabilité conditionnelle des données (<span class="math inline">\(x\)</span>) sachant le paramètre (<span class="math inline">\(\theta\)</span>), qu’on appelle aussi la <em>likelihood</em> (<em>ou fonction de vraisemblance</em>) du paramètre (<span class="math inline">\(\theta\)</span>).</span></p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="1-introduction.html#cb20-1" aria-hidden="true" tabindex="-1"></a>like <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(<span class="fl">0.9</span>, <span class="fl">0.1</span>), <span class="fu">c</span>(<span class="fl">0.07</span>, <span class="fl">0.93</span>) ) <span class="sc">%&gt;%</span> data.frame</span>
<span id="cb20-2"><a href="1-introduction.html#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(like) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Mam+&quot;</span>, <span class="st">&quot;Mam-&quot;</span>)</span>
<span id="cb20-3"><a href="1-introduction.html#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="fu">rownames</span>(like) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Cancer+&quot;</span>, <span class="st">&quot;Cancer-&quot;</span>)</span>
<span id="cb20-4"><a href="1-introduction.html#cb20-4" aria-hidden="true" tabindex="-1"></a>like</span></code></pre></div>
<pre><code>##         Mam+ Mam-
## Cancer+ 0.90 0.10
## Cancer- 0.07 0.93</code></pre>
<p><span class="math display">\[
\color{purple}{p(\theta \vert x)} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{p(x)}}
\]</span></p>
<p><span style="color:green"> <span class="math inline">\(p(x)\)</span> la probabilité marginale de <span class="math inline">\(x\)</span> (sur <span class="math inline">\(\theta\)</span>). Sert à normaliser la distribution.</span></p>
<p><span class="math display">\[\color{green}{p(x)=\sum\limits_{\theta}p(x|\theta)p(\theta)}\]</span></p>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="1-introduction.html#cb22-1" aria-hidden="true" tabindex="-1"></a>(marginal <span class="ot">&lt;-</span> <span class="fu">sum</span>(like<span class="sc">$</span><span class="st">&quot;Mam+&quot;</span> <span class="sc">*</span> prior) )</span></code></pre></div>
<pre><code>## [1] 0.07664</code></pre>
<p><span class="math display">\[
\color{purple}{p(\theta \vert x)} = \dfrac{\color{orangered}{p(x\vert \theta)} \color{steelblue}{p(\theta)}}{\color{green}{p(x)}}
\]</span></p>
<p><span class="math inline">\(\color{purple}{p(\theta \vert x)}\)</span> <span style="color:purple"> la probabilité a posteriori de <span class="math inline">\(\theta\)</span> sachant <span class="math inline">\(x\)</span>, c’est à dire ce qu’on sait de <span class="math inline">\(\theta\)</span> après avoir pris connaissance de <span class="math inline">\(x\)</span>.</span></p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="1-introduction.html#cb24-1" aria-hidden="true" tabindex="-1"></a>(posterior <span class="ot">&lt;-</span> (like<span class="sc">$</span><span class="st">&quot;Mam+&quot;</span> <span class="sc">*</span> prior ) <span class="sc">/</span> marginal )</span></code></pre></div>
<pre><code>## [1] 0.09394572 0.90605428</code></pre>
</div>
<div id="linférence-bayésienne-comme-mise-à-jour-probabiliste-des-connaissances" class="section level4 hasAnchor" number="1.5.1.4">
<h4><span class="header-section-number">1.5.1.4</span> L’inférence bayésienne comme mise à jour probabiliste des connaissances<a href="1-introduction.html#linférence-bayésienne-comme-mise-à-jour-probabiliste-des-connaissances" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Avant de passer le mammogramme, la probabilité qu’une femme tirée au sort ait un cancer du sein était de <span class="math inline">\(p(Cancer)=.008\)</span> (<em>prior</em>). Après un résultat positif, cette probabilité est devenue <span class="math inline">\(p(Cancer|Mam+)=.09\)</span> (<em>posterior</em>). Ces probabilités sont des expressions de nos <em>connaissances</em>. Après un mammogramme positif, on pense toujours que c’est “très improbable” d’avoir un cancer, mais cette probabilité a considérablement évolué relativement à “avant le test”.</p>
<blockquote>
<p><em>A Bayesianly justifiable analysis is one that treats known values as observed values of random variables, treats unknown values as unobserved random variables, and calculates the conditional distribution of unknowns given knowns and model specifications using Bayes’ theorem</em> (<a href="https://projecteuclid.org/euclid.aos/1176346785">Rubin, 1984</a>).</p>
</blockquote>
</div>
</div>
<div id="problème-de-monty-hall" class="section level3 hasAnchor" number="1.5.2">
<h3><span class="header-section-number">1.5.2</span> Problème de Monty Hall<a href="1-introduction.html#problème-de-monty-hall" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:monty1"></span>
<img src="figures/monty1.png" alt="A syllogistic penguin... Figure from..." width="50%" />
<p class="caption">
Figure 1.18: A syllogistic penguin… Figure from…
</p>
</div>
<p>Que-feriez-vous (intuitivement) ? Analysez ensuite la situation en utilisant le théorème de Bayes.</p>
<div id="monty-hall---proposition-de-solution" class="section level4 hasAnchor" number="1.5.2.1">
<h4><span class="header-section-number">1.5.2.1</span> Monty Hall - proposition de solution<a href="1-introduction.html#monty-hall---proposition-de-solution" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Il s’agit d’un problème de probabilités conditionnelles… Définissons les événements suivants:</p>
<p>P1: l’animateur ouvre la porte 1 <br>
P2: l’animateur ouvre la porte 2 <br>
P3: l’animateur ouvre la porte 3 <br></p>
<p>V1: la voiture se trouve derrière la porte 1 <br>
V2: la voiture se trouve derrière la porte 2 <br>
V3: la voiture se trouve derrière la porte 3 <br></p>
<p>Si on a choisi la porte n°1 et que l’animateur a choisi la porte n°3 (<em>et qu’il sait où se trouve la voiture</em>), il s’ensuit que:</p>
<p><span class="math inline">\(p(P3|V1)=\dfrac{1}{2}\)</span>, <span class="math inline">\(p(P3|V2)=1\)</span>, <span class="math inline">\(p(P3|V3)=0\)</span></p>
<p>On sait que <span class="math inline">\(p(V3|P3)=0\)</span>, on veut connaître <span class="math inline">\(p(V1|P3)\)</span> et <span class="math inline">\(p(V2|P3)\)</span> afin de pouvoir choisir. Résolution par le théorème de Bayes.</p>
<p><span class="math inline">\(p(V1|P3)=\dfrac{p(P3|V1) \times p(V1)}{p(P3)}=\dfrac{\dfrac{1}{2} \times \dfrac{1}{3}}{\dfrac{1}{2}}=\dfrac{1}{3}\)</span></p>
<p><span class="math inline">\(p(V2|P3)=\dfrac{p(P3|V2) \times p(V2)}{p(P3)}=\dfrac{1 \times \dfrac{1}{3}}{\dfrac{1}{2}}=\dfrac{2}{3}\)</span></p>
<div class="figure" style="text-align: center"><span style="display:block;" id="fig:monty2"></span>
<img src="figures/monty2.png" alt="A syllogistic penguin... Figure from..." width="50%" />
<p class="caption">
Figure 1.19: A syllogistic penguin… Figure from…
</p>
</div>
<p>Nos intuitions probabilistes sont, dans la grande majorité des cas, très mauvaises. Au lieu de compter sur elles, il est plus sage de se reposer sur des règles logiques (<em>modus ponens</em> et <em>modus tollens</em>) et probabilistes simples (règle du produit, règle de la somme, théorème de Bayes), nous assurant de réaliser l’inférence logique la plus juste. Autrement dit, “<em>Don’t be clever</em>” <span class="citation">(<a href="bibliographie.html#ref-mcelreath_statistical_2016" role="doc-biblioref">McElreath, 2016b</a>)</span>.</p>

</div>
</div>
</div>
</div>



<div class="footnotes">
<hr />
<ol start="1">
<li id="fn1"><p>On notera au passage que les axiomes de Kolmogorov représentent un exemple parmi d’autres d’ensemble de règles permettant de définir ce qu’est une probabilité, mais que ce n’est pas le seul (bien que ce soit le plus communément utilisé). Par exemple, les <a href="https://en.wikipedia.org/wiki/Cox%27s_theorem">axiomes de Cox</a> offrent un cadre alternatif.<a href="1-introduction.html#fnref1" class="footnote-back">↩︎</a></p></li>
<li id="fn2"><p>Deux événements <span class="math inline">\(A_{1}\)</span> et <span class="math inline">\(A_{2}\)</span> sont dits <em>incompatibles</em> si l’on ne peut avoir les deux en même temps, c’est à dire si la probabilité de leur intersection est nulle : <span class="math inline">\(\Pr(A_{1} \cap A_{2}) = 0\)</span>.<a href="1-introduction.html#fnref2" class="footnote-back">↩︎</a></p></li>
<li id="fn3"><p>À ce propos, et comme nous le verrons un peu plus tard, il est possible et relativement facile de généraliser la procédure de calcul des p-valeurs à n’importe quel modèle statistique dans le cadre bayésien, voir par exemple cet article de blog : <a href="http://www.barelysignificant.com/post/ppc/" class="uri">http://www.barelysignificant.com/post/ppc/</a>.<a href="1-introduction.html#fnref3" class="footnote-back">↩︎</a></p></li>
<li id="fn4"><p>La puissance statistique moyenne des tests d’hypothèse réalisés en Psychologie est estimée à moins de 50% <span class="citation">(e.g., <a href="bibliographie.html#ref-szucs_empirical_2017-1" role="doc-biblioref">Szucs &amp; Ioannidis, 2017</a>)</span>.<a href="1-introduction.html#fnref4" class="footnote-back">↩︎</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="A-glossaire.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": false
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/lnalborczyk/IMSB2022/tree/master/_notes/01-introduction.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["IMSB.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"scroll_highlight": true
},
"info": false
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
