# Modèle de régression linéaire, suite {#linear-regression2}

```{r setup-ch4, include = FALSE, message = FALSE}
library(tidyverse)
library(knitr)

# setting up knitr options
opts_chunk$set(
  cache = TRUE, echo = TRUE, warning = FALSE, message = FALSE,
  fig.align = "center", out.width = "75%", fig.pos = "!htb"
  )
```

\definecolor{steelblue}{RGB}{70, 130, 180}
\definecolor{green}{RGB}{0, 153, 0}
\definecolor{purple}{RGB}{153, 0, 153}
\definecolor{orangered}{cmyk}{0, 73, 100, 0}

Introduction au chapitre blah blah...

## Régression multiple

On va étendre le modèle précédent en ajoutant plusieurs prédicteurs, continus et/ou catégoriels. Pourquoi faire ?

+ *Contrôle* des facteurs de confusion (e.g., [spurious correlations](http://www.tylervigen.com/spurious-correlations), [simpson's paradox](https://en.wikipedia.org/wiki/Simpson%27s_paradox)). Un facteur de confusion est une variable aléatoire qui influence à la fois la variable dépendante et les variables explicatives. Une approche multivariée peut nous aider à démêler les influences causales de différents prédicteurs.

+ Multiples causes : un phénomène peut émerger sous l'influence de multiples causes.

+ Interactions : l'influence d'un prédicteur  sur la variable observée peut dépendre de la valeur d'un autre prédicteur.

### Associations fortuites

```{r import-waffle, eval = TRUE, echo = TRUE}
library(rethinking)
library(tidyverse)

data(WaffleDivorce) # import des données
df1 <- WaffleDivorce # import dans une dataframe nommée df1

str(df1) # structure des données
```

On observe un lien positif entre le nombre de "waffle houses" et le taux de divorce...

```{r waffle-divorce, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
df1 %>%
  ggplot(aes(x = WaffleHouses, y = Divorce) ) +
  geom_text(aes(label = Loc) ) +
  geom_smooth(method = "lm", color = "black", se = TRUE) +
  theme_bw(base_size = 20) +
  labs(x = "Waffle Houses per million", y = "Divorce rate")
```

On observe un lien positif entre le taux de mariage et le taux de divorce, mais est-ce qu'on peut vraiment dire que le mariage "cause" le divorce ?

```{r waffle-divorce-mariage, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
df1$Marriage.s <- (df1$Marriage - mean(df1$Marriage) ) / sd(df1$Marriage)

df1 %>%
  ggplot(aes(x = Marriage.s, y = Divorce) ) +
  geom_point(pch = 21, color = "white", fill = "black", size = 5, alpha = 0.8) +
  geom_smooth(method = "lm", color = "black", se = TRUE) +
  theme_bw(base_size = 20)
```

On observe l'association inverse entre le taux de divorce et l'âge médian de mariage.

```{r waffle-divorce-median, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
df1$MedianAgeMarriage.s <- (df1$MedianAgeMarriage - mean(df1$MedianAgeMarriage) ) /
  sd(df1$MedianAgeMarriage)

df1 %>%
  ggplot(aes(x = MedianAgeMarriage.s, y = Divorce) ) +
  geom_point(pch = 21, color = "white", fill = "black", size = 5, alpha = 0.8) +
  geom_smooth(method = "lm", color = "black", se = TRUE) +
  theme_bw(base_size = 20)
```

On peut représenter nos trois variables principales sur une carte des 50 états.

```{r waffle-divorce-map, eval = TRUE, echo = FALSE, fig.width = 15, fig.height = 5}
# plot from
# https://bookdown.org/ajkurz/Statistical_Rethinking_recoded/multivariate-linear-models.html
# devtools::install_github("wmurphyrd/fiftystater")

library(fiftystater)

df1 %>% 
  # first we'll standardize the three variables to put them all on the same scale
  mutate(
    Divorce_z = (Divorce - mean(Divorce) )/ sd(Divorce),
    MedianAgeMarriage_z = (MedianAgeMarriage - mean(MedianAgeMarriage) ) / sd(MedianAgeMarriage),
    Marriage_z = (Marriage - mean(Marriage) ) / sd(Marriage),
    # need to make the state names lowercase to match with the map data
    Location = str_to_lower(Location)
    ) %>% 
  # here we select the relevant variables and put them in the long format to
  # facet with `facet_wrap()`
  dplyr::select(Divorce_z:Marriage_z, Location) %>% 
  gather(key, value, -Location) %>%
  # plotting it
  ggplot(aes(map_id = Location)) +
  geom_map(
    aes(fill = value), map = fifty_states,
    # color = "firebrick",
    size = 1 / 15, show.legend = FALSE
    ) +
  expand_limits(x = fifty_states$long, y = fifty_states$lat) +
  scale_x_continuous(NULL, breaks = NULL) +
  scale_y_continuous(NULL, breaks = NULL) +
  # scale_fill_gradient(low = "#f8eaea", high = "firebrick4") +
  coord_map() +
  facet_wrap(~key) +
  theme_bw(base_size = 20)
```

#### Influence du taux de mariage

$$
\begin{aligned}
\color{orangered}{D_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{R} R_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(10, 10)} \\
\color{steelblue}{\beta_{R}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)} \\
\end{aligned}
$$

```{r mod1-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(10, 10), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod1 <- brm(
  Divorce ~ 1 + Marriage.s,
  family = gaussian(),
  prior = priors,
  data = df1
  )
```

...

```{r summary-mod1-ch4, eval = TRUE, echo = TRUE}
summary(mod1)
```

#### Influence de l'âge médian de mariage

$$
\begin{aligned}
\color{orangered}{D_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{A} A_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(10, 10)} \\
\color{steelblue}{\beta_{A}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)} \\
\end{aligned}
$$

```{r mod2-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(10, 10), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod2 <- brm(
  Divorce ~ 1 + MedianAgeMarriage.s,
  family = gaussian(),
  prior = priors,
  data = df1
  )
```

...

```{r summary-mod2-ch4, eval = TRUE, echo = TRUE}
summary(mod2)
```

### Régression multiple

Quelle est la valeur prédictive d'une variable, une fois que je connais tous les autres prédicteurs ?

$$
\begin{aligned}
\color{orangered}{D_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{R}R_{i} + \beta_{A} A_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(10, 10)} \\
\color{steelblue}{\beta_{R}, \beta_{A}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)} \\
\end{aligned}
$$

Ce modèle répond à deux questions :

+ Une fois connue le taux de mariage, quelle valeur ajoutée apporte la connaissance de l'âge médian du mariage ?
+ Une fois connu l'âge médian du mariage, quelle valeur ajoutée apporte la connaissance de le taux de mariage ?

```{r mod3-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(10, 10), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod3 <- brm(
  Divorce ~ 1 + Marriage.s + MedianAgeMarriage.s,
  family = gaussian(),
  prior = priors,
  data = df1
  )
```

Interprétation : Une fois qu'on connait l'âge median de mariage dans un état, connaître le taux de mariage de cet état n'apporte pas vraiment d'information supplémentaire...

```{r summary-mod3-ch4, eval = TRUE, echo = TRUE}
summary(mod3)
```

#### Visualiser les prédictions du modèle

On peut comparer le taux de divorce observé dans chaque état au taux de divorce prédit par notre modèle (la ligne diagonale représente une prédiction parfaite).

```{r predictions-mod3-ch4, eval = TRUE, echo = FALSE, fig.width = 7, fig.height = 7}
data.frame(fitted(mod3) ) %>%
  transmute(mu = Estimate, lb = Q2.5, ub = Q97.5) %>%
  bind_cols(predict(mod3) %>% data.frame() ) %>%
  bind_cols(df1) %>%
  ggplot(aes(x = Divorce, y = mu) ) +
  geom_pointrange(
    aes(ymin = lb, ymax = ub, y = mu),
    size = 1, shape = 1, col = "steelblue"
    ) +
  geom_text(
    data = . %>% filter(Loc %in% c("ID", "UT") ),
    aes(label = Loc),
    size = 5, nudge_x = 0.3, nudge_y = 0.3, col = "steelblue"
    ) +
  geom_abline(intercept = 0, slope = 1, lty = 2, lwd = 1) +
  theme_bw(base_size = 20) +
  labs(x = "Taux de divorce observé", y = "Taux de divorce prédit")
```

En plus de l'interprétation des paramètres, il est important d'évaluer les prédictions du modèle en les comparant aux données observées. Cela nous permet de savoir si le modèle rend bien compte des données et (surtout) où est-ce que le modèle échoue.

```{r ppc-mod3-ch4-1, eval = TRUE, echo = TRUE, fig.width = 12, fig.height = 6}
pp_check(mod3, type = "intervals", nsamples = 1e2, prob = 0.5, prob_outer = 0.95) +
  theme_bw(base_size = 20) + labs(x = "État", y = "Taux de divorce")
```

...

```{r ppc-mod3-ch4-2, eval = TRUE, echo = FALSE, fig.width = 20, fig.height = 10}
mod3 %>%
  # adds the prediction intervals
  predict(., probs = c(0.025, 0.975) ) %>%
  data.frame %>%
  transmute(ll = Q2.5, ul = Q97.5) %>%
  # adds the fitted intervals
  bind_cols(fitted(mod3, probs = c(0.025, 0.975) ) %>% data.frame() ) %>%
  # adds the data
  bind_cols(mod3$data) %>%
  mutate(case = 1:nrow(.) ) %>%
  # plotting it
  ggplot(aes(x = case) ) +
  geom_linerange(
    aes(ymin = ll, ymax = ul),
    size = 4, alpha = 0.2
    ) +
  geom_pointrange(
    aes(ymin = Q2.5, ymax = Q97.5, y = Estimate),
    size = 1, shape = 1
  ) +
  geom_point(
    aes(
      y = Divorce,
      color = ifelse(Divorce > ll & Divorce < ul, "black", "orangered") ),
    size = 4, show.legend = FALSE
    ) +
  scale_x_continuous(breaks = 1:50, labels = df1$Loc, limits = c(1, 50) ) +
  scale_color_identity() +
  theme_bw(base_size = 20) +
  labs(x = "État", y = "Taux de divorce")
```

### Toujours plus de prédicteurs

Pourquoi ne pas simplement construire un modèle incluant tous les prédicteurs et regarder ce qu'il se passe ?

+ Raison n°1 : Multicolinéarité
+ Raison n°2 : Post-treatment bias
+ Raison n°3 : Overfitting (cf. Cours n°07)

#### Multicolinéarité

Situation dans laquelle certains prédicteurs sont très fortement corrêlés. Par exemple, essayons de prédire la taille d'un individu par la taille de ses jambes.

```{r leg-height, eval = TRUE, echo = TRUE}
set.seed(666) # afin de pouvoir reproduire les résultats

N <- 100 # nombre d'individus
height <- rnorm(N, 179, 5) # génère N observations
leg_prop <- runif(N, 0.4, 0.5) # taille des jambes (proportion taille totale)
leg_left <- leg_prop * height + rnorm(N, 0, 0.5) # taille jambe gauche (+ erreur)
leg_right <- leg_prop * height + rnorm(N, 0, 0.5) # taille jambe droite (+ erreur)
df2 <- data.frame(height, leg_left, leg_right) # création d'une dataframe

head(df2) # affiche les six première lignes
```

On fit un modèle avec deux prédicteurs : un pour la taille de chaque jambe.

```{r mod4-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(174, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod4 <- brm(
  height ~ 1 + leg_left + leg_right,
  prior = priors,
  family = gaussian,
  data = df2
  )
```

Les estimations semblent étranges... mais le modèle ne fait que répondre à la question qu'on lui pose : Une fois que je connais la taille de la jambe gauche, quelle est la valeur prédictive de la taille de la jambe droite (et vice versa) ?

```{r summary-mod4-ch4, eval = TRUE, echo = TRUE}
summary(mod4) # look at the SE...
```

Comment traquer la colinéarité de deux prédicteurs ? En représentant la distribution postérieure de ces deux paramètres.

```{r pairs-mod4-ch4, eval = TRUE, echo = TRUE, fig.width = 9, fig.height = 6}
pairs(mod4, pars = parnames(mod4)[1:3])
```

Comment traquer la colinéarité de deux prédicteurs ? En représentant la distribution postérieure de ces deux paramètres.

```{r post-plot-mod4-ch4, eval = TRUE, echo = TRUE, fig.width = 7.5, fig.height = 5}
post <- posterior_samples(mod4)

post %>%
  ggplot(aes(x = b_leg_left, y = b_leg_right) ) +
  geom_point(pch = 21, size = 4, color = "white", fill = "black", alpha = 0.5) +
  theme_bw(base_size = 20) +
  labs(x = expression(beta[gauche]), y = expression(beta[droite]) )
```

Le modèle précédent peut se réécrire en faisant apparaitre la somme des deux prédicteurs $\beta_{1}$ et $\beta_{2}$.

$$
\begin{aligned}
y_{i} &\sim \mathrm{Normal}(\mu_{i}, \sigma) \\
\mu_{i} &= \alpha + (\beta_{1} + \beta_{2}) x_{i}
\end{aligned}
$$

```{r plotpost-legs, eval = TRUE, echo = TRUE, fig.width = 7.5, fig.height = 5}
library(BEST)
sum_legs <- post$b_leg_left + post$b_leg_right
plotPost(sum_legs, xlab = expression(beta[1] + beta[2]), compVal = 0)
```

On crée un nouveau modèle avec seulement une jambe.

```{r mod5-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(174, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod5 <- brm(
  height ~ 1 + leg_left,
  prior = priors,
  family = gaussian,
  data = df2
  )
```

En utilisant comme prédicteur une seule jambe, on retrouve l'estimation qui correspondait à la somme des deux pentes dans le modèle précédent.

```{r summary-mod5-ch4, eval = TRUE, echo = TRUE}
summary(mod5)
```

#### Post-treatment bias

Problèmes qui arrivent lorsqu'on inclut des prédicteurs qui sont eux-mêmes définis directement ou indirectement par d'autres prédicteurs inclus dans le modèle.

Supposons par exemple qu'on s'intéresse à la pousse des plantes en serre. On voudrait savoir quel traitement permettant de réduire la présence de champignons améliore la pousse des plantes.

On commence donc par planter et laisser germer des graines, mesurer la taille initiale des pousses, puis appliquer différents traitements.

Enfin, on mesure à la fin de l'expérience la taille finale de chaque plante et la présence de champignons.

```{r fungus-data, eval = TRUE, echo = TRUE}
# nombre de plantes
N <- 100

# on simule différentes tailles à l'origine
h0 <- rnorm(N, mean = 10, sd = 2)

# on assigne différents traitements et on
# simule la présence de funguns et la pousse des plantes
treatment <- rep(0:1, each = N / 2)
fungus <- rbinom(N, size = 1, prob = 0.5 - treatment * 0.4)
h1 <- h0 + rnorm(N, mean = 5 - 3 * fungus)

# on rassemble les données dans une dataframe
df3 <- data.frame(h0, h1, treatment, fungus)

head(df3)
```

...

$$
\begin{aligned}
\color{orangered}{h_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{1} h0_{i} + \beta_{2} T_{i} + \beta_{3} F_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 10)} \\
\color{steelblue}{\beta_{1}, \beta_{2}, \beta_{3}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 10)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)}
\end{aligned}
$$

```{r mod6-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0, 10), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod6 <- brm(
  h1 ~ 1 + h0 + treatment + fungus,
  prior = priors,
  family = gaussian,
  data = df3
  )
```

On remarque que l'effet du traitement est négligeable. La présence des champignons (`fungus`) est une conséquence de l'application du `treatment`. On demande au modèle si le traitement a une influence sachant que la plante a (ou n'a pas) développé de champignons...

```{r summary-mo6-ch4, eval = TRUE, echo = TRUE}
summary(mod6)
```

Nous nous intéressons plutôt à l'influence du traitement sur la pousse. Il suffit de fitter un modèle sans la variable `fungus`. Remarque : il fait sens de prendre en compte $h0$, la taille initiale, car les différences observées pourraient masquer l'effet du traitement.

```{r mod7-ch4, eval = TRUE, echo = TRUE, results = "hide"}
mod7 <- brm(
  h1 ~ 1 + h0 + treatment,
  prior = priors,
  family = gaussian,
  data = df3
  )
```

Note : on pourrait également utiliser la méthode `update()`...

```{r mod7bis-ch4, eval = FALSE, echo = TRUE, results = "hide"}
mod7 <- update(mod6, formula = h1 ~ 1 + h0 + treatment)
```

```{r summary-mod7-ch4, eval = TRUE, echo = TRUE}
summary(mod7)
```

L'influence du traitement est maintenant forte et positive...

### Prédicteurs catégoriels

```{r data-categ, eval = TRUE, echo = TRUE}
data(Howell1)
df4 <- Howell1

str(df4)
```

Le **genre** est codé comme une **dummy variable**, c'est à dire une variable où chaque modalité est représentée soit par $0$ soit par $1$. On peut imaginer que cette nouvelle variable *active* le paramètre uniquement pour la catégorie codée $1$, et le *désactive* pour la catégorie codée $0$.

$$
\begin{aligned}
\color{orangered}{h_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{m}m_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(178, 100)} \\
\color{steelblue}{\beta_{m}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 10)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Uniform}(0, 50)}
\end{aligned}
$$

```{r mod8-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(178, 100), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod8 <- brm(
  height ~ 1 + male,
  prior = priors,
  family = gaussian,
  data = df4
  )
```

L'intercept $\alpha$ représente la taille moyenne des femmes (car $\mu_{i} = \beta_{m}(0) = \alpha$).

```{r summary-mod8-ch4, eval = TRUE, echo = TRUE}
fixef(mod8) # retrieves fixed effects
```

La pente $\beta$ nous indique la différence de taille moyenne entre les hommes et les femmes. Pour obtenir la taille moyenne des hommes, il suffit donc d'ajouter $\alpha$ et $\beta$.

```{r summary-female, eval = TRUE, echo = TRUE}
post <- posterior_samples(mod8)
mu.male <- post$b_Intercept + post$b_male
quantile(x = mu.male, probs = c(0.025, 0.5, 0.975) )
```

Au lieu d'utiliser un paramètre pour la différence entre les deux catégories, on pourrait estimer un paramètre par catégorie...

$$
\begin{aligned}
h_{i} &\sim \mathrm{Normal}(\mu_{i}, \sigma) \\
\mu_{i} &= \alpha_{f}(1 - m_{i}) + \alpha_{h} m_{i} \\
\end{aligned}
$$

Cette formulation est strictement équivalente à la précedente car :

$$
\begin{aligned}
\mu_{i} &= \alpha_{f}(1 - m_{i}) + \alpha_{h} m_{i} \\
&= \alpha_{f} + (\alpha_{m} - \alpha_{f}) m_{i} \\
\end{aligned}
$$

où $(\alpha_{m} - \alpha_{f})$ est égal à la différence entre la moyenne des hommes et la moyenne des femmes (i.e., $\beta_{m}$).

```{r mod9-ch4, eval = TRUE, echo = TRUE, results = "hide"}
# on crée une nouvelle colonne pour les femmes
df4 <- df4 %>% mutate(female = 1 - male)

priors <- c(
  # il n'y a plus d'intercept dans ce modèle
  # prior(normal(178, 100), class = Intercept),
  prior(normal(0, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod9 <- brm(
  height ~ 0 + female + male,
  prior = priors,
  family = gaussian,
  data = df4
  )
```

```{r summary-mod9-ch4, eval = TRUE, echo = TRUE}
summary(mod9)
```

#### Prédicteurs catégoriels, taille d'effet

$$
\rho^{2} = \dfrac{\sum_{i=1}^{n} \pi_{i}(\beta_{i} - \beta)^{2}}{\sigma^{2} + \sum_{i = 1}^{n} \pi_{i}(\beta_{i} - \beta)^{2}}
$$

```{r rho, eval = TRUE, echo = TRUE}
post <- posterior_samples(mod9)
pi <- sum(df4$male) / length(df4$male) # proportion of males

beta <- post$b_male # posterior samples for beta
sigma <- post$sigma # posterior samples for sigma

f1 <- pi * (beta - beta * pi)^2
rho <- f1 / (f1 + sigma^2)
```

$$
\rho^{2} = \dfrac{\sum_{i=1}^{n} \pi_{i}(\beta_{i} - \beta)^{2}}{\sigma^{2} + \sum_{i=1}^{n} \pi_{i}(\beta_{i} - \beta)^{2}}
$$

```{r plotpost-rho, eval = TRUE, echo = TRUE, fig.width = 7.5, fig.height = 5}
plotPost(rho, showMode = TRUE, cex = 2, xlab = expression(rho) )
```

...

$$
\text{Cohen's d} = \frac{\text{différence des moyennes}}{\text{écart-type}}
$$

```{r cohen, eval = TRUE, echo = TRUE, fig.width = 7.5, fig.height = 5}
plotPost((post$b_male - post$b_female) / post$sigma, cex = 2, xlab = expression(delta) )
```

### Prédicteurs catégoriels, nombre de catégories > 3

```{r milk-data, eval = TRUE, echo = TRUE}
data(milk)
df5 <- milk
str(df5)
```

Règle : pour $k$ catégories, nous aurons besoin de $k - 1$ *dummy variables*. Pas la peine de créer une variable pour `ape`, qui sera notre *intercept*.

```{r categories, eval = TRUE, echo = TRUE}
df5$clade.NWM <- ifelse(df5$clade == "New World Monkey", 1, 0)
df5$clade.OWM <- ifelse(df5$clade == "Old World Monkey", 1, 0)
df5$clade.S <- ifelse(df5$clade == "Strepsirrhine", 1, 0)
```

...

$$
\begin{aligned}
\color{orangered}{k_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha + \beta_{NWM}NWM_{i} + \beta_{OWM}OWM_{i} + \beta_{S}S_{i}} \\
\color{steelblue}{\alpha} \ &\color{steelblue}{\sim \mathrm{Normal}(0.6, 10)} \\
\color{steelblue}{\beta_{NWM}, \beta_{OWM}, \beta_{S}} \ &\color{steelblue}{\sim \mathrm{Normal}(0, 1)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)}
\end{aligned}
$$

...

```{r figure-table, eval = TRUE, echo = FALSE, out.width = "66%"}
knitr::include_graphics("figures/table.png")
```

...

```{r mod10-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0.6, 10), class = Intercept),
  prior(normal(0, 1), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod10 <- brm(
  kcal.per.g ~ 1 + clade.NWM + clade.OWM + clade.S,
  prior = priors,
  family = gaussian,
  data = df5
  )
```

```{r summary-mod10-ch4, eval = TRUE, echo = TRUE}
summary(mod10)
```

...

```{r pairs-mod10-ch4, eval = TRUE, echo = TRUE}
# retrieves posterior samples
post <- posterior_samples(mod10)

# retrieves posterior samples for each category
mu.ape <- post$b_Intercept
mu.NWM <- post$b_Intercept + post$b_clade.NWM
mu.OWM <- post$b_Intercept + post$b_clade.OWM
mu.S <- post$b_Intercept + post$b_clade.S
```

```{r precis-mod10-ch4, eval = TRUE, echo = TRUE}
precis(data.frame(mu.ape, mu.NWM, mu.OWM, mu.S), prob = 0.95)
```

Si on s'intéresse à la différence entre deux groupes, on peut calculer la distribution postérieure de cette différence.

```{r quantiles-mod10-ch4, eval = TRUE, echo = TRUE}
diff.NWM.OWM <- mu.NWM - mu.OWM
quantile(diff.NWM.OWM, probs = c(0.025, 0.5, 0.975) )
```

```{r plotpost-mod10-ch4, eval = TRUE, echo = TRUE, fig.width = 10, fig.height = 5}
plotPost(diff.NWM.OWM, compVal = 0, ROPE = c(-0.1, 0.1) )
```

Une autre manière de considérer les variables catégorielles consiste à construire un vecteur d'intercepts, avec un intercept par catégorie.

$$
\begin{aligned}
\color{orangered}{k_{i}} \ &\color{orangered}{\sim \mathrm{Normal}(\mu_{i}, \sigma)} \\
\color{black}{\mu_{i}} \ &\color{black}{= \alpha_{\text{clade}[i]}} \\
\color{steelblue}{\alpha_{\text{clade}[i]}} \ &\color{steelblue}{\sim \mathrm{Normal}(0.6, 10)} \\
\color{steelblue}{\sigma} \ &\color{steelblue}{\sim \mathrm{Exponential}(0.01)}
\end{aligned}
$$

Comme on a vu avec l'exemple du genre, `brms` "comprend" automatiquement que c'est ce qu'on veut faire lorsqu'on fit un modèle sans intercept et avec un prédicteur catégoriel (codé en facteur).

```{r mod11-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(0.6, 10), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod11 <- brm(
  # modèle sans intercept avec seulement un prédicteur catégoriel (facteur)
  kcal.per.g ~ 0 + clade,
  prior = priors,
  family = gaussian,
  data = df5
  )
```

```{r summary-mod11-ch4, eval = TRUE, echo = TRUE}
summary(mod11)
```

### Interaction

Jusque là, les prédicteurs du modèle entretenaientt des relations mutuellement indépendantes. Et si nous souhaitions que ces relations soient **conditionnelles**, ou **dépendantes** les unes des autres ?

Par exempl e: on s'intéresse à la pousse des tulipes selon la quantité de lumière reçue et l'humidité du sol. Il se pourrait que la relation entre quantité de lumière reçue et pousse des tulipes soit différente selon l'humidité du sol. En d'autres termes, il se pourrait que la relation entre quantité de lumière reçue et pousse des tulipe soit **conditionnelle** à l'humidité du sol...

```{r data-tulips, eval = TRUE, echo = TRUE}
data(tulips)
df6 <- tulips

head(df6, 10)
```

Modèle sans interaction :

$$
\begin{aligned}
B_{i} &\sim \mathrm{Normal}(\mu, \sigma) \\
\mu_{i} &= \alpha + \beta_{W} W_{i} + \beta_{S} S_{i} \\
\end{aligned}
$$

Modèle avec interaction :

$$
\begin{aligned}
B_{i} &\sim \mathrm{Normal}(\mu, \sigma) \\
\mu_{i} &= \alpha + \beta_{W} W_{i} + \beta_{S} S_{i} + \beta_{WS} W_{i} S_{i}\\
\end{aligned}
$$

On centre les prédicteurs (pour faciliter l'interprétation des paramètres).

```{r centering, eval = TRUE, echo = TRUE}
df6$shade.c <- df6$shade - mean(df6$shade)
df6$water.c <- df6$water - mean(df6$water)
```

```{r mod12-ch4, eval = TRUE, echo = TRUE, results = "hide"}
priors <- c(
  prior(normal(130, 100), class = Intercept),
  prior(normal(0, 100), class = b),
  prior(exponential(0.01), class = sigma)
  )

mod12 <- brm(
  blooms ~ 1 + water.c + shade.c,
  prior = priors,
  family = gaussian,
  data = df6
  )
```

```{r mod13-ch4, eval = TRUE, echo = TRUE, results = "hide"}
mod13 <- brm(
  blooms ~ 1 + water.c * shade.c,
  # equivalent to blooms ~ 1 + water.c + shade.c + water.c:shade.c
  prior = priors,
  family = gaussian,
  data = df6
  )
```

...

```{r model-comp-ch4, eval = TRUE, echo = FALSE}
posterior_summary(mod12) %>%
  data.frame %>%
  rownames_to_column("term") %>%
  dplyr::select(term, Estimate) %>%
  mutate(model = "mod12") %>%
  filter(term != "lp__") %>%
  bind_rows(
    posterior_summary(mod13) %>%
      data.frame %>%
      rownames_to_column("term") %>%
      dplyr::select(term, Estimate) %>%
      mutate(model = "mod13") %>%
      filter(term != "lp__")
    ) %>%
  pivot_wider(names_from = model, values_from = Estimate) %>%
  data.frame
```

+ L'intercept $\alpha$ représente la valeur attendue de `blooms` quand `water` et `shade` sont à 0 (i.e., la moyenne générale de la variable dépendante).

+ La pente $\beta_{W}$ nous donne la valeur attendue de changement de `blooms` quand `water` augmente d'une unité et `shade` est à sa valeur moyenne. On voit qu'augmenter la quantité d'eau est très bénéfique.

+ La pente $\beta_{S}$ nous donne la valeur attendue de changement de `blooms` quand `shade` augmente d'une unité et `water` est à sa valeur moyenne. On voit qu'augmenter la "quantité d'ombre" (diminuer l'exposition à la lumière) est plutôt délétère.

+ La pente $\beta_{WS}$ nous renseigne sur l'effet attendu de `water` sur `blooms` quand `shade` augment d'une unité (et réciproquement).

Dans un modèle qui inclut un effet d'interaction, l'effet d'un prédicteur sur la mesure va dépendre de la valeur de l'autre prédicteur. La meilleure manière de représenter cette dépendance est de plotter la relation entre un prédicteur et la mesure, à différentes valeurs de l'autre prédicteur.

```{r plot-models-ch4, eval = TRUE, echo = FALSE, fig.height = 6, fig.width = 12}
# `fitted()` for model b7.8
fitted(mod12) %>%
  as_tibble() %>%
  # add `fitted()` for model b7.9
  bind_rows(
    fitted(mod13) %>% 
      as_tibble()
  ) %>% 
  # we'll want to index the models
  mutate(fit = rep(c("mod12", "mod13"), each = 27) ) %>%
  # here we add the data, `d`
  bind_cols(bind_rows(df6, df6) ) %>%
  
  # these will come in handy for `ggplot2::facet_grid()`
  mutate(
    x_grid = paste("Water.c =", water.c),
    y_grid = paste("Modèle : ", fit)
    ) %>%
  # plot!
  ggplot(aes(x = shade.c) ) +
  geom_point(
    aes(y = blooms, group = x_grid), 
    shape = 21, color = "white", fill = "black", size = 3
    ) +
  geom_smooth(
    aes(y = Estimate, ymin = Q2.5, ymax = Q97.5),
    stat = "identity",
    color = "black",
    alpha = 0.25, size = 1
    ) +
  scale_x_continuous("Shade (centered)", breaks = c(-1, 0, 1) ) +
  ylab("Blooms") +
  facet_grid(y_grid ~ x_grid) +
  theme_bw(base_size = 20)
```

L'effet d'interaction nous indique que les tulipes ont besoin à la fois d'eau et de lumière pour pousser, mais aussi qu'à de faibles niveaux d'humidité, la luminosité a peu d'effet, tandis que cet effet est plus important à haut niveau d'humidité.

Cette explication vaut de manière **symétrique** pour l'effet de l'humidité sur la relation entre la luminosité et la pousse des plantes.
